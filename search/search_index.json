{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Vaibhav Yadav's Wiki","text":"<p>Built with Material for MkDocs, served with GitHub Actions. More about me here.</p>"},{"location":"#articles-and-content","title":"Articles and Content","text":""},{"location":"0-Information-Technology/aws-amazon-web-services/","title":"Amazon Web Services","text":"<p>Web application system design architecture can vary based on vairous requirements. Some of the ways are</p> <ul> <li>Static Sites - optional backend in serverless lambda - jekyll site.</li> <li>Containers - using docker images, or Heroku.</li> <li>VMs - fully available OS.</li> <li>3 tier web app, monolithic app, modular app or a group of webserives.</li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-overview-infra-and-access","title":"AWS Overview, Infra and Access","text":"<p>AWS Global Infrastructure - AWS provides various services on cloud which can be used to build these systems. Is is PaaS. AWS Global Infrastructure has multiple <code>servers</code>, in multiple <code>data centers</code>, in multiple <code>availability zones</code>, in multiple <code>regions</code>. This is how AWS makes data available and disaster proof. Regions are geo bound. Pick a region based on</p> <ul> <li>Compliance - app might be restricted to region or global</li> <li>Latency - server should be close to end user or business</li> <li>Pricing - due to tax price vary in different regions.</li> <li>Availability - not all services are in all regions.</li> </ul> <p></p> <p>Interacting with AWS - as it is Virtual, on cloud, hence you need API to manage services. API is available as:</p> <ul> <li>AWS Console - a GUI, web based to login and manage the serives. Click based. Region based. Interactive forms to use services.</li> <li>AWS CLI - a Command Line Interface that is scriptable.</li> <li>AWS SDKs - a Software Development Kits, eg Python, Java etc. Useful if you want to stay in dev language env. Eg, if you app is using Python and Flask, then you can use Python to interact with AWS services and host the app.</li> </ul> <p>Security and the AWS Shared Responsibility Model - AWS secure the cloud, you secure in the cloud. You secure your data, firewalls, access by users, encryption etc. Each AWS service has its own security model. It has followig credentials types:</p> <ul> <li>One is username and password, that can be used on web</li> <li>The second set of credentials is called access <code>keys</code>, which allow you to make programmatic requests from the AWS Command Line Interface (AWS CLI) or AWS API. Access keys consist of two parts:<ul> <li>Access key ID, for example, A2lAl5EXAMPLE</li> <li>Secret access key, for example, wJalrFE/KbEKxE</li> </ul> </li> </ul> <p>As best practice, do not use root user (AWS email ID) for day to day task. Protect the AWS Root User as it has unrestricted access to everything in account. Also add <code>Multi Factor Authentication</code> MFA, which enables added security like RSA.</p> <p>Use <code>IMA Account</code> to do actions as it has restricted access.</p> <p>AWS Identity and Access Management</p> <ul> <li>EC2 needs access and permission to talk to S3, so all services need authentication and signed api calls in each request.</li> <li>Each developer can have <code>IAM account</code>, this <code>authenticates</code> (access). Then each user needs <code>authorization</code> (permission) to different services.</li> <li><code>IAM policies</code> can be used to grant or deny permissions to users to take actions. Actions are basically API calls, everything in AWS is API calls.</li> <li>Policies are JSON documents. JSON defines which service has, what level of access with some conditions. Basically you can control every single thing by creating this policy. Policy is basically rule. Policy must have effect, action and resouce.</li> <li><code>Policy</code> can then be attached to a IAM identities, <code>User</code> or <code>Group</code> to inherit.</li> <li>Policy JSON Example:<pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [{\n\"Effect\": \"Allow\",\n\"Action\": \"*\",\n\"Resource\": \"*\"\n}]\n}\n</code></pre> </li> </ul> <p>Role-Based Access in AWS</p> <ul> <li>IAM Roles are like IAM users that have association with IAM Policies and have auth tokes.</li> <li>Roles are used by services to talk to each other. Eg, you can give a role to EC2 machine to read and write to S3 bucket and to RDS and DynamoDB.</li> <li>Role can be associated to policy.</li> <li>For Corps, you have SSO and Identity.</li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-compute","title":"AWS COMPUTE","text":"<p>Compute as a Service</p> <ul> <li>web server, batch job, ML; all need compute. Compute mainenaince needs time.</li> <li>AWS offers compute as:<ul> <li>Virtual Machines</li> <li>Containers</li> <li>Serverless</li> </ul> </li> </ul> <p>Amazon Elastic Compute Cloud</p> <ul> <li>EC2 provides various types of instances which are for different purpose, like web server, graphics server.</li> <li>Amazon Machine Image - AMIs can be installed on EC2 machines.</li> <li>EC2 machines can be scaled up in no time.</li> </ul> <p>Amazon EC2 Instance Lifecycle</p> <ul> <li>EC2 is charged when running or rebooting. Once terminated, they are deleted forever.</li> <li>To update the VM, duplicate the VMv1.0, make updates to clone, the switch the app to VMv2.0, terminate v1.0</li> </ul> <p>Container Services</p> <ul> <li>containers provide efficiency and portability<ul> <li><code>ECS Elastic Container Service</code></li> <li><code>EKS Elastic Kubernetes Service</code></li> </ul> </li> <li>They both run on top of EC2, henc use EC2 as a service.</li> <li>Container orchestration tool help us manage 100s of containers easily</li> </ul> <p>Serverless</p> <ul> <li>You will not manage the updates and patches to the server os. Instead server is completely abastracted from you. You need not care about scalability, updates or other server management.</li> <li><code>AWS Fargate</code> is used for this. No need to worry about underlying OS or Env.</li> <li>EC2 gives more control while Fargate gives more conveniece but less control.</li> </ul> <p>AWS Lambda</p> <ul> <li>Serverless compute. Package and upload code as lambda function</li> <li>Not running all time. runs when triggered.</li> <li>List of triggers exit, like HTTP, upload of file, events from other AWS services or inbonile activity.</li> <li>Runs on managed service, it is scalable.</li> <li>You can choose, env, os, size memory etc.</li> <li>all lambda runs in their own env.</li> <li>Not for Wordpress site, but for smaller web services or task, eg, resize photo to thumbnail. Lambda is billed only when function runs, upto 100ms interval. So you don't need image resize service to always run, but only when photo is uploaded.</li> <li>Create a lambda function, add a role to it, if it needs to access other AWS service.</li> <li>Add a trigger to invoke lambda function.</li> <li>Upload code to lambda function.</li> <li>See it invoked in CloudWatch</li> <li>AWS Lambda</li> </ul> <p>Choose the Right Compute Service</p> <ul> <li>Prototype on permise app - EC2</li> <li>One a quarter or month file data wrangling - Lambda</li> <li>Micro services that need regular updates - ECS or EKS</li> </ul> <p>For compute in AWS, the three most commonly used services are as follows:</p> <ul> <li>Compute on instances - EC2</li> <li>Container services</li> <li>Serverless services</li> </ul> <p><code>Amazon EC2</code> are virtual server instances in the cloud. Amazon EC2 gives you complete control over the instance, down to the root level. You can manage the instance as you would manage a physical server. You can use instances for long-running applications, especially those with state information and long-running computation cycles.</p> <p><code>Amazon ECS, Amazon EKS</code> Container management services that can run containers on either customer managed Amazon EC2 instances OR as an AWS managed serverless offering running containers on AWS Fargate. Before software is released, it must be tested, packaged, and installed. Containers provide a standard way to package your application's code, configurations, and dependencies into a single object. Containers run on top of the host OS and share the host's kernel. Each container running on a host runs its own isolated root file system in a separate namespace that may include it\u2019s own OS. They are designed to help ensure quick, reliable, and consistent deployments, regardless of the environment. Containers are useful when taking a large traditional application and breaking it down into small parts, or microservices, to make the application more scaleable and resilient. When not to use containers? When applications need persistent data storage.</p> <p><code>AWS Lambda</code> is Serverless compute for running stateless code in response to triggers. Using AWS Lambda, you can run code without provisioning or managing servers. You pay only for the compute time you consume. There is no charge when your code is not running. With Lambda, you can run code for virtually any type of application or backend service without provisioning or managing servers. Upload your code, and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to be automatically invoked from other AWS services or call it directly from any web or mobile app. Lambda is a suitable choice for any short-lived application that can finish running in under 15 minutes.</p> <p>What AWS Compute service to choose?</p> <ul> <li>something that can build fast and let you hit the market so you can analyze and see if it works</li> <li>put time in - business logic and data processing logic.</li> <li>do not waste time on infra concern like load balancing, scaling, networking; or plumin code like logging, authenticaiton, caching exceptions so on.</li> <li>use serverless architecture using lambda, s3, cloudfront, step functions, congnito, appsync, dynamodb. They are all scaled, available and charged per request basis.</li> <li>just define logic as lambda function, and invoke it via a respond to api call or an event.</li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-networking","title":"AWS NETWORKING","text":"<p>Networking</p> <ul> <li>Amazon <code>VPC - Virtual Private Cloud</code> is network configuration, same as modem and router in physical world. In EC2, instead of default config, we can use custom VPC configuration<ul> <li>to add <code>more security</code>, like only allow HTTP on a certain port. Hence, no SSH on 22.</li> <li>to give different <code>access control</code> to different resources, like public/intranet/private.</li> <li>to achieve <code>high-availability</code> and fault tolerance by associating different AZs. Compute is replicated. we will have more than one EC2 hence more than one VM.</li> </ul> </li> </ul> <p>Amazon VPC</p> <ul> <li>CIDR notation is used to provide variable IP address or range of IP addressess. Eg, <code>192.168.1.0/24</code>. /16 is more, /24 is less.</li> <li><code>VPC</code> gives you range of IPs. <code>10.1.0.0/16</code>. You need to create VPC in AWS management console - GUI.</li> <li>Then you can use these IPs to create <code>subnets</code>, which uses some IPs of VPC-IPs to make private or public network. Subnets are associated to AZs - Availability Zones. Say in Zone-A<ul> <li>Public resources, or internet facing resources, are added to <code>public subnet</code> with a sub-range of the VPC IP range, eg, <code>10.1.1.0/24</code>. like web-app</li> <li>Private resources are kept in <code>private subnet</code> with a sub-range of the VPC IP range, eg <code>10.1.3.0/24</code>. like database.</li> </ul> </li> <li>To expose public subnet to internet, we need <code>IGW - Internet GateWay</code>, this is just like a modem. Create internet gateway and attach it to your VPC.</li> <li>To only expose the subnet to corporate intranet or VPN, create <code>VGW - Virtual Private GateWay</code>. This will expose the AWS to on-premise data center.</li> <li>to make it always available, duplicate the subnets and add to another AZ.<ul> <li></li> </ul> </li> </ul> <p>Amazon VPC Routing</p> <ul> <li>When a user reached Internet Gateway, it needs to be routed to correct subnet. For this we need routing table.</li> <li>AWS create default <code>main route table</code>. This provides local trafic only.</li> <li>GUI - each VPC have routes.</li> <li>We have called subnet public/private however, that is implemented by routes, which controls the exposure of the subnets.</li> <li>Edit route table, add new route and add destinatoion <code>0.0.0.0/0</code> that takes and servers all IPs. then add internet gateway to it. finally, associate it to public subnets.</li> <li>Later add firewall for extra security.</li> <li></li> </ul> <p>Amazon VPC Security</p> <ul> <li>Subnets can be made more secure, like only allow HTTPs to inbound and outbound traffics on port 443.</li> <li>To do this create rules in <code>Network ACLs - access control lists</code>. Like firewalls.</li> <li>Secondly, <code>security groups</code> can provide more security to EC2instances.</li> <li></li> </ul> <p>Creating EC2 with VPC configuration</p> <ul> <li>to implement this we need to do following<ul> <li>create <code>elastic IP</code> address for NAT Gateway, NAT gives connectivity to private resources not exposed to internet.</li> <li>create a <code>VPC</code></li> <li>then make <code>subnets</code> pub/pvt, and associate them with different AZs.</li> <li>add <code>NAT gateway</code> for connectivity to pvt resources.</li> <li>add Internet Gateway to expose public subnet to internet.</li> <li>create <code>route-table</code> to route IP traffic to specified gateway NAT/IGW. To associate pub/pvt with NAT/Internet-GateWay. Create two route-tables. then add NAT/Internet gateway. then associate with subnets.</li> <li><code>associate subnets</code> to route tables.</li> <li>create <code>security group</code> to allow/block certain protocols (HTTP/SSH) and ports(22/8080).</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-storage","title":"AWS STORAGE","text":"<p>Storage Types</p> <ul> <li>we need to store<ul> <li>OS - application files, ubuntu</li> <li>Static Data - files - employee photo - write once, read many WORM</li> <li>Structured Data - database tables</li> </ul> </li> </ul> <ul> <li>Block Storage - splitted into chunks - one char change in 1gb file is simple - System File, Log File.</li> <li>Object Storage - single unit - one char change in 1gb file, whole file si rewritten - WORM, Video</li> </ul> <p>Amazon EC2 Instance Storage and Amazon Elastic Block Store EBS</p> <ul> <li>EC2 has <code>instance</code> storage like internal HDD. This is block-level storage. attached physically, hence fast but tied to lifecycle of EC2.</li> <li>EBS is like external HDD</li> <li>EBS can be linked to one EC2 or multiple EC2 can read-write.</li> <li>EBS can be HHD or SSD</li> <li>EBS can be snapshotted to keep backup.</li> </ul> <p>Object Storage with Amazon Simple Storage Service S3</p> <ul> <li>EBS is not fit for all as<ul> <li>they are mostly 1-1 with EC2</li> <li>have size limit.</li> </ul> </li> <li>S3 is scalable, standalone, not tied to EC2, not mounted</li> <li>access by URL</li> <li>max 5TB file</li> <li>is object storage</li> <li>has flat structure</li> <li>unique bucket name</li> <li>it is region constrained</li> <li>is durable and available as it is auto distributed in a region</li> <li>objects are: buckets/folders/files</li> <li>Demo<ul> <li>search s3 - create bucket - region specific - bucket has a URL</li> <li>upload objects - files</li> <li>files have URL</li> </ul> </li> </ul> <ul> <li>bucket/folder/files are private and not public to world.</li> <li>can be made public using actions, but only in public bucket</li> <li>for access control use<ul> <li>IAM, and</li> <li><code>S3 bucket policies</code>, it has same json format and attached to buckets</li> </ul> </li> <li>actions allowed or deny. can be read only, another acct write.</li> <li>Uses: static websites, data lakes, media, backup and storage.</li> <li>AWS S3 permissions</li> </ul> <p>Choose the Right Storage Service</p> <ul> <li>EC2 Instance store is generally well-suited for temporary storage of information that is constantly changing, such as buffers, caches, and scratch data</li> <li>Amazon EBS, block storage, is meant for data that changes frequently and needs to persist through instance stops, terminations, or hardware failures.</li> <li>If your data doesn\u2019t change that often, Amazon S3 might be a cost-effective and scalable storage solution for you. Amazon S3 is ideal for storing static web content and media, backups and archiving, and data for analytics. It can also host entire static websites with custom domain names.</li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-databases","title":"AWS DATABASES","text":"<p>Databases on AWS</p> <ul> <li>RDS for data.</li> <li>App can connect to DB on your on-premise server. you manage everything. Or</li> <li>DB on ec2, then have to install DB s/w, manage updates, backups and replicate it on instances for high-availabiility. Or</li> <li>Managed AWS database service, you only code. AWS manages everything else.</li> </ul> <p>Amazon Relational Database Service RDS</p> <ul> <li>RDS &gt; create database &gt; easy create<ul> <li>select engine &gt; mysql/mssqlserver/postgres</li> <li>BD instace size &gt; free</li> <li>identifier name</li> <li>username</li> <li>password</li> <li>create db.</li> </ul> </li> <li>RDS is in one pvt subnet. to make high-availability, create secondary RDS in another AZ subnet, using <code>RDS Multi-AZ deployment</code>. RDS will manage replication.</li> <li>oneis primary another secondary. fail overs handeled by rds.</li> </ul> <p>Purpose-Built Databases</p> <ul> <li>Relational databases ae good to manage complex schemas, which have joins and complex queries and stored procs. However, this adds overhead in engine.</li> <li>There are other DBs which work best to query single records.</li> <li>Also RDS is charged per hour, you query or not. weekedn</li> <li>dynamo, key value, docs, non relatin, ms larency, usage charge and amount.</li> <li>amazon docDB - content</li> <li>social n/w - graph db - az neptune, recommendation, fraud detection ??? todo</li> <li>finance, ledger, aamzon qldb, immutable, audit , compliance</li> <li>these are purpose built.</li> </ul> <p>Amazon DynamoDB</p> <ul> <li>fully managed NoSQL database, serverless</li> <li>no relations</li> <li>scalable, performant, under ms time</li> <li>tables, items, and attributes are the core component.  A table is a collection of items, and each item is a collection of attributes.</li> <li>access via dynamo db api</li> <li>search dynamo</li> <li>create table</li> <li>unique identifiedr</li> <li>table name, primary kry</li> <li>items to view items</li> </ul> <p>Choose the Right Database Service</p> Database Type Use Cases AWS Service Relational Traditional applications, ERP, CRM, e-commerce Amazon RDS, Amazon Aurora, Amazon Redshift Key-value High-traffic web apps, e-commerce systems, gaming applications Amazon DynamoDB In-memory Caching, session management, gaming leaderboards, geospatial applications Amazon ElastiCache for Memcached, Amazon ElastiCache for Redis Document Content management, catalogs, user profiles Amazon DocumentDB (with MongoDB compatibility) Wide column High-scale industrial apps for equipment maintenance, fleet management, and route optimization Amazon Keyspaces (for Apache Cassandra) Graph Fraud detection, social networking, recommendation engines Amazon Neptune Time series IoT applications, DevOps, industrial telemetry Amazon Timestream Ledger Systems of record, supply chain, registrations, banking transactions Amazon QLDB"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-monitoring-optimization-scaling","title":"AWS MONITORING, OPTIMIZATION, SCALING","text":"<p>Application Management</p> <ul> <li>how is app performinh, how is it usitilizing resoirces</li> <li>sacalability - demand not constand, add and reducse esources</li> <li>balance traffic</li> </ul> <p>Monitoring</p> <ul> <li>important to see how services are being used</li> <li>monday morning latency, not good to take tickets</li> <li>proactive before end user notify</li> <li>and where is the problem? recent code change, db or ec2?</li> <li>metrics, logs, traffic, db connections, cpu usage; need to be monitored</li> <li>monitoring tool help in this by analyzing, metrics over time, called statistics. Based on stats there can be triggers.</li> <li>all info need to be on centrol console, hence cloudwatch</li> <li>all in one place</li> </ul> <p>Amazon CloudWatch</p> <ul> <li>users can create <code>dashabord</code> from various granular metrics available</li> <li>can create <code>alarms</code> to be raised on crossing a basevalue over a time<ul> <li>this can trigger <code>SNS</code>, Simple Notification Serive, which cretes a topic. Any one subscribed to the <code>topic</code> will get notified.</li> <li>can trigger a EC2 boot action,</li> <li>can sacle up resources</li> </ul> </li> <li>user can also send custom app metric, like 'page load time' which not aws metric but app specific, but can be seen on CloudWatch and can trigger alarms.</li> </ul> <p>Solution Optimization</p> <ul> <li>we need to optimize infra<ul> <li>capacity - storage - s3 - mostly autoscaled</li> <li>peformance - ec2 and db, db mostly autoscales, but ec2 has capacity</li> <li>availablility - manage traffic and make all services available.</li> </ul> </li> <li>prevent or repond so as to avoid bottle neck.</li> <li>to increase availability increase redundancy, or replication of services</li> <li><code>AutoScaling</code> lets you automatically add and remove instances.</li> <li>in horizontal scaling the problem is that each EC2 has its own public IP address and the traffic needs to be sent to one available. To solve this issue, we use a <code>load balancer</code>. It removes need of public ip addresses for each EC2.</li> </ul> <p>Traffic Routing with Amazon Elastic Load Balancing</p> <ul> <li>now we have multiple ec2 in public subnets.</li> <li>request from browser - goes to load balancer - sends to ec2.</li> <li>ELB, <code>Elastic Load Balancer</code> does the traffic management. Highly available in each zone.</li> <li>ALB - <code>application load balancer</code>, hanfles Http or Https.</li> <li>ALB needs, <code>listener</code>, port and protocaol<ul> <li><code>target</code> group - which backend resource to send to, ec2 s3 dynamo<ul> <li>it sends the trffic based on helath of backend</li> </ul> </li> <li><code>rules</code> - how to divert a traffic. it is default as well as we can define rules for pages, apps etc.</li> </ul> </li> <li>Other is <code>Network Load Balancer</code> supports TCP, UDP, and TLS protocols.</li> <li></li> </ul> <p>Amazon EC2 Auto Scaling</p> <ul> <li>we have 2 instances, but demand may inc.</li> <li>instead of adding instances manually, use EC2 autoscaling, more capacity based on threshold in cliudwatch.</li> <li>ec2 cpu goes up, cloudwatch triggers alarm, autoscale is asked to give more ec2 instances. each is added to ALB with health checks amd thus high horizontal scalability. hecnce CPU down across fleet.</li> <li>Three main components of EC2 Auto Scaling are as follows:<ul> <li>Launch template or configuration: What resource should be automatically scaled?</li> <li>EC2 Auto Scaling Group: Where should the resources be deployed?</li> <li>'Scaling policies: When should the resources be added or removed?</li> </ul> </li> </ul> <ul> <li></li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#aws-other-services","title":"AWS Other Services","text":"<p><code>AWS Lighsail</code>  - easy VPS hosting. Quickly launch and manage OS with configued Dev Stack (like Ubuntu with LAMP). Add load balance, firewall and dns. Once requirements increase, easily move to EC2 or Lambda. Lightsail provides low-cost, pre-configured cloud resources for simple workloads just starting on AWS. Amazon EC2 is a compute web service that provides secure, resizable compute in the cloud. It has far greater scale and optimization capabilities than Lightsail.</p> <p><code>AWS Batch</code> lets you do batch jobs, by giving right cpu gpu and memory.</p> <p><code>AWS Elastic Beanstalk</code> - easy devops for 3 tier app easy devops. gives url for app. free, only pay for aws services. api, web app etc.</p> <p><code>AWS CodeStar</code> is development tool to develop, build and deploy app on AWS.</p> <p><code>AWS Amplify Console</code> provides continuous deployment and hosting of the static web resources including HTML, CSS, JavaScript, and image files which are loaded in the user's browser.</p>"},{"location":"0-Information-Technology/aws-amazon-web-services/#demo-handson-implementaion-build-employee-directory-app","title":"DEMO - Handson Implementaion - Build Employee Directory App","text":"<p>We will create basic CRUD app, employee directory app on AWS.</p> <p>Architecture:</p> <ul> <li>App is hosted on Private Network using, <code>VPC - Virtual Private Cloud</code>.</li> <li>Backend on <code>EC2 - Elastic Compute</code>, which is VM on AWS. App code is here without the data or files. hence this can be replicated to achieve high availability.</li> <li>Data is stored in database in same NW, either <code>RDS - relational data service</code> or <code>DynamoDB - key value</code>.</li> <li>Images in <code>S3 - simple storage service</code>.</li> <li>Monitoring using <code>CloudWatch</code> for health monitoring.</li> <li>Scalability using <code>ELB - Elastic Load Balancer</code>. This will distribute load on the available servers (instances). Also <code>EC2 AutoScaling</code> will help scale out or in based on demand.</li> <li><code>IAM - Identity and Access Management</code> for security and access amangement.</li> <li><code>AWS Management Console</code> - to build all this.</li> </ul> <p>Demonstration: Implement security with AWS Identity and Access Management (IAM)</p> <ul> <li>Create Groups, then add Policies to it.</li> <li>Add Users to the Groups.</li> <li>Eg, create group to read-only ec2 state, or read-only s3.</li> </ul> <p>Employee Directory Application Hosting</p> <ul> <li>Create a EC2 machine<ul> <li>Use default VPC, this is network. each ec2 has to be in a network</li> <li>Choose Role for this machine, eg, EC2 to have full access to S3 and Dynamo DB.</li> <li>User Data: Add script to run when this machine boots. This is basically linux 'profile/env' info, like exporting variables and setting paths. Additionally it can have, download code, unzip, install requirements, set flask app path, run the app.</li> <li>Configure Security Group - this is to allow HTTP requests to your machine, by adding security groups.</li> <li>Finally launch. Once launced, you will get a public IP address, this will let you access the app.</li> </ul> </li> </ul> <p>EC2</p> <ul> <li>Use <code>Amazon Linux 2 AMI</code>, select <code>t2.micro</code> free tier insatance.</li> <li>Add script, that will:<ul> <li>update all</li> <li>install node</li> <li>create app dir</li> <li>download and unzip app code</li> <li>install dependencies</li> <li>run the app, <code>npm start</code></li> </ul> </li> <li>add storage, 8gb is enough.</li> <li>securty group, acts as virtual firewaal that controls tha ccess. we need web traffic for app and ssh for management. HTTP allows inbound traffic on port 80.</li> <li>Connect to instance, select instance and click connect and then agian connect. you are connect to EC2 machine from browser shell ssh.</li> </ul> <p>Networking</p> <ul> <li>Doing this on the AWS Console<ul> <li>Login to Console &gt; EC2 &gt; <code>Elastic IPs</code><ul> <li>Allocate Elastic IP for EC2.</li> </ul> </li> <li>Search VPC &gt; Wizard &gt; Pub &amp; Pvt <code>subnets</code><ul> <li>Add VPC Name &gt; Then add AZs to subnets. Here one zone, AZ-a is selected.</li> </ul> </li> <li>VPC &gt; Subnets - you can add <code>more subnets</code> by<ul> <li>Create Subnet</li> <li>Select VPC ID &gt; Subnet Name &gt; AZ-b &gt; CIDR in range &gt; create.</li> <li>Similarly, create private too.</li> </ul> </li> <li>Now <code>Routing-Tables</code><ul> <li>Click Route table</li> <li>select route-table for VPC ID</li> <li>click routes - see that internet traffic is goint to NAT Gateway.<ul> <li>click <code>subnet-associations</code> tab</li> </ul> </li> <li>Similarly do for public.</li> </ul> </li> <li>Create <code>Security Group</code> for more security<ul> <li>add name</li> <li>add to vpc</li> <li>inbound: http, source: anywhere. Outbound added auto.</li> </ul> </li> <li>Create <code>EC2</code> &gt; configuration<ul> <li>Network: Lab VPC</li> <li>Subnet: public 1</li> <li>auto assign public IP: enable</li> <li>Config security group, pick the one created</li> </ul> </li> <li>Create second EC2 similarly and add second public subnet.</li> </ul> </li> <li>Now the app should work with added security, high-availability and resource restriction.</li> </ul> <p>Storage Demonstration: Create an Amazon S3 Bucket</p> <ul> <li>S3 bucket is created in region, not tied to subnet</li> <li>Open Console &gt; search S3 &gt; Create <code>Bucket</code></li> <li>Bucket Name: emp-photo-bucket-012</li> <li>Region: place in same region as of ec2</li> <li>create bucket</li> <li>Open Bucket</li> <li>Click <code>Permission</code> tab</li> <li>Bucket Policy &gt; edit &gt; enter new Policy JOSN, <code>IAM</code> role to allow app access to bucket.</li> <li>Add files as objects - click <code>upload</code></li> <li>Bucket should be accessible via app.</li> </ul> <p>Scaling</p> <ul> <li>demo<ul> <li>make <code>launch template</code>, what to launch when scaling</li> <li>console - ec2 - sidebar launch template - create - give name and desc - check autoscaling</li> <li>AMI - create mirror image of web server, select AMI AND t2 MICRO.</li> <li>SELECT SAME KEY-PAIR, same security group, expand advance</li> <li>IAM same role</li> <li>pase user data.</li> <li>This completes 'what to launch'</li> <li>Now, 'when to launch'<ul> <li>sidebar - 'autoscaling group' - create - select template - same vpc, select public subnets</li> <li>attach to load balancer.</li> <li>define group size.</li> </ul> </li> </ul> </li> </ul> <ul> <li>demo: ec2 - sidebar - load balancers - create - ALB - give a name<ul> <li>scheme<ul> <li>internet facing - to manage client req</li> <li>internal load balancer (pvt IP to pvt IP) - for 3 tier apps</li> </ul> </li> <li>listeners - default + HTTPs</li> <li>availability zones - choose vpc, check both availability zone and public subnets</li> <li>security group - all port 80 from anywhere</li> <li>routing - give name - next - chosse instances - next - create.</li> <li>find the DNS name in detais, open it.</li> <li>this is app being server from two availablity zones and the traffic is managed by the load balancer.</li> </ul> </li> </ul> <p>Demonstration: Configure High Availability for Your Application</p> <ul> <li>Database Dynamo and file server S3 are both highly available and scalabel within a region. Only EC2 will limit. So we make it available by using load balancer and scalable using autoscaling, which adds and removes instances based on load.</li> </ul> <p>Employee Directory Application Redesign</p> <ul> <li>The Architecture<ul> <li>the app is hosted across ec2 instances inside VPC, in private subnets.</li> <li>ec2 part of autoscaling, traffic is managed by app load balancer</li> <li>db on dynamo</li> <li>file in s3</li> </ul> </li> <li>to ensure this all works, analyse that auto scaling policy is working as expected. may need some tweaking to work over time. Also install security patched and updates for EC2 as they come out.</li> <li>Now, we can redisgn the app to make it completely serverless using Cloud Native service like AWS Lambda. and explore other architectures possible.</li> <li>As of now, the app is a 3 tier app<ul> <li>presentation Layer - UI - HTML, CSS, JS or Mobile</li> <li>application Layer - Business/Application Logic</li> <li>data layer - database</li> </ul> </li> <li>EC2 is being used for both, presentation layer and application. To improve this we can separate, these layers.</li> <li>Presentation on S3, as static website. Not all sites are static, but JS can help with this, React sites are static and make the content dynamic by using JS to make HTTP requests.</li> <li>Application Layer to be hosted as Lambda, each of CRUD as separate Lambda function.</li> <li>Amazon API Gateway, can be used to make front end to talk to lambda functions serving different events in backend.<ul> <li>API on API Gateway acts as a front door to trigger the backend code on lambda. We can have one labda function for all events or separate for each.</li> </ul> </li> <li>Dynamo for database, s3 for files.</li> <li>alla ccess handeled by RBAC via IAM.</li> <li>This way we can make the app modular. this can help make changes quickly without making whole infra to change and test. untouched DB, but can update code.</li> <li>Futher, Amazon RT53 can be used to manage domains name calls</li> <li>CloudFront can be used to catch static content and make it available close to end users using global infra of AWS</li> <li>With this serverless architecture, compared to EC2 solution, we have made the app scalable, available and thus can reduce cost. VPC and networking is msanged.</li> <li>Another option is using container services. All service in AWS is API based, thus we can use any of them</li> </ul>"},{"location":"0-Information-Technology/aws-amazon-web-services/#demo-build-a-serverless-web-application","title":"DEMO - Build a Serverless Web Application","text":"<p>with AWS Lambda, Amazon API Gateway, AWS Amplify, Amazon DynamoDB, and Amazon Cognito</p> <p>Amplify Console provides continuous deployment and hosting of the static web resources including HTML, CSS, JavaScript, and image files which are loaded in the user's browser. JavaScript executed in the browser sends and receives data from a public backend API built using Lambda and API Gateway. Amazon Cognito provides user management and authentication functions to secure the backend API. Finally, DynamoDB provides a persistence layer where data can be stored by the API's Lambda function.</p> <p></p> <p>Static Web Hosting - AWS Amplify hosts static web resources including HTML, CSS, JavaScript, and image files which are loaded in the user's browser.</p> <p>User Management - Amazon Cognito provides user management and authentication functions to secure the backend API.</p> <p>Serverless Backend - Amazon DynamoDB provides a persistence layer where data can be stored by the API's Lambda function.</p> <p>RESTful API - JavaScript executed in the browser sends and receives data from a public backend API built using Lambda and API Gateway.</p>"},{"location":"0-Information-Technology/aws-amazon-web-services/#links","title":"Links","text":"<ul> <li>https://explore.skillbuilder.aws/learn/course/1851/play/45289/aws-technical-essentials-104</li> <li>More about compute, how to select between ec2, labda and container - 40 mins - https://explore.skillbuilder.aws/learn/course/internal/view/elearning/199/aws-compute-services-overview?dt=tile&amp;tile=fdt</li> <li>Data Analytics, volume, variety, velocity, veracity ETL, value VIZ - 4hr - https://explore.skillbuilder.aws/learn/course/internal/view/elearning/44/data-analytics-fundamentals?dt=tile&amp;tile=fdt</li> <li><code>Heroku</code> is and alternative PaaS for deploying container-based apps on cloud.</li> <li>Build a Serverless Web Application with AWS Lambda, Amazon API Gateway, AWS Amplify, Amazon DynamoDB, and Amazon Cognito. Links:</li> <li>https://aws.amazon.com/getting-started/hands-on/build-serverless-web-app-lambda-apigateway-s3-dynamodb-cognito/</li> <li>https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-dynamo-db.html</li> <li>https://medium.com/rahasak/build-serverless-application-with-aws-amplify-aws-api-gateway-aws-lambda-and-cognito-auth-a8606b9cb025</li> <li>https://trackit.io/aws-api-gateway-create-api-python-cognito-serverless/</li> </ul> <p>You don't necessarily need a static server in order to run a Create React App project in production. Static web app allows you to host static pages written on frameworks such as Angular, react, vuejs, etc.</p>"},{"location":"0-Information-Technology/flask/","title":"Flask","text":"<p>Flask is a microframework in Python. It is used to create a webapp. It can start a python web server. It can handle HTTP requests. It can also be used to make a webapp API.</p>"},{"location":"0-Information-Technology/flask/#flask-hello-world","title":"Flask Hello World","text":"<ul> <li> <p>Create a python file <code>main.py</code>:</p> <pre><code>#!venv_app/bin/python3\nfrom flask import Flask\napp = Flask(__name__)\n@app.route('/')\ndef index():\nreturn \"Hello from Flask App!\"\nif __name__ == '__main__':\napp.run(debug=True)\n</code></pre> </li> </ul> <ul> <li>run using <code>python main.py</code></li> </ul> <ul> <li>access at <code>http://localhost:5000</code> in browser.</li> </ul>"},{"location":"0-Information-Technology/flask/#run-a-flask-app-ways","title":"Run a Flask App - Ways","text":"<ul> <li>python<ul> <li><code>python main.py</code></li> </ul> </li> </ul> <ul> <li>executable<ul> <li><code>chmod a+x main.py</code> to make app executable.</li> <li><code>./main.py</code> runs app.</li> </ul> </li> </ul> <ul> <li>Flask CLI<ul> <li><code>flask --app main.py run</code>   or</li> <li><code>export FLASK_APP=main.py</code> will make an variable that tells python which app to run.</li> <li><code>flask run</code> executes the app or if flask is not in path then do <code>python -m flask run</code></li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#flask-native-modules","title":"Flask native modules","text":"<p>flask basics, request-response handling, contexts</p> <ul> <li>Application Instance<ul> <li><code>Flask()</code> - is a class.</li> <li>All Flask applications must create an application instance (object of class <code>Flask</code>). The web server passes all requests it receives from clients to this object for handling, using a protocol called Web Server Gateway Interface (WSGI).</li> <li><code>app = Flask(__name__)</code> name is passed to <code>Flask</code> class constructor so it knows the location of app and hence can locate static and template.</li> </ul> </li> </ul> <ul> <li>Requests<ul> <li>Request from client has lot of information in it, like header, user-agent, data etc. This information is available in <code>request object</code> and is made available to a <code>view-route function</code> to handle it. This object is not passed as an argument to function, rather it is made available using <code>contexts</code>.</li> <li><code>request</code> Object has methods and attributes having info on method, form, args, cookies, files, remote_addr, get_data().</li> </ul> </li> </ul> <ul> <li>Contexts<ul> <li>Code needs data to be processed, that data can be configurations, input data or data from file/database. Context is used to keep track of this data.</li> <li>It let certain objects to be globally accessible, but are not global variable. They are globally accessible to only one thread. There can be multiple threads serving multiple requests from multiple client.</li> <li>Context is simply data that is specific to something. Eg<ul> <li>App-context is specific to app, like its mail server, its database location, or other configurations. Keeps track of application-level data. Objects: <code>current_app</code>, <code>g</code>.</li> <li>Request-context is specific to request, like its browser, its client, its form data, its headers, all that is request-level. Objects: <code>request</code>, <code>session</code>.</li> </ul> </li> <li>this data is stored in object, in attribute such as <code>config</code></li> <li>this data is used by extensions in flask, hence they do not run if context is not available.</li> <li>context is automatically made available once app is initialized.</li> <li>context can be made explicitly available by calling <code>with app.app_context():</code></li> </ul> </li> </ul> <ul> <li>Request Handling<ul> <li> <p>when there is request, web server activates a thread that initializes app and this app context is pushed with data that is available globally, similarly request context is also pushed.</p> <pre><code>graph LR;\nWeb_Browser --&gt; request --&gt; web_server --&gt; Flask_app_instance --&gt; route --&gt; function_to_execute</code></pre> </li> </ul> </li> </ul> <ul> <li>Flask variables for Request Handling<ul> <li><code>current_app</code> variable in Application context, has info of active application.</li> <li><code>g</code> variable in Application context, it is object that is unique for each request, temp access during handling of a request. It resets once request is served. Holds app info hence app context. Can be used to load user on each request. show logged in user on templates.</li> <li><code>request</code>, in request context, obj having client req data.</li> <li><code>session</code>, in request context, stores data across requests, i.e., a dictionary to store values that can be accessed in different requests from same session.</li> <li>Flask, in backend, makes these available to thread before dispatching a request and removes after request is handled. Explicitly, <code>current_app</code> can be made available by invoking <code>app.app_context()</code></li> <li> How does flask differentiate requests and clients?</li> </ul> </li> </ul> <ul> <li>Request Hooks<ul> <li>They are deocrators that register functions that can execute code before or after each request is processed. They are implemented as decorators  (functions that execute on event). These are the four hooks supported by Flask:</li> <li><code>before_request</code> - like authenticate</li> <li><code>before_first_request</code> - only before the first request is handled. Eg, to add server initialization tasks.</li> <li><code>after_request</code> - after each request, but only if no unhandled exceptions occurred.</li> <li><code>teardown_request</code> - after each request, even if unhandled exceptions occurred.</li> <li><code>g</code> context global storage can be used to share data between hook and view functions.</li> </ul> </li> </ul> <ul> <li>Routes or View Functions<ul> <li>They handle application URLs.</li> <li>URL-maps can be seen using <code>app.url_map</code></li> <li>redirect to url<ul> <li><code>redirect</code> - takes URL to redirect to.</li> <li><code>redirect(url_for(\"profile\"))</code></li> <li><code>url_for()</code> utility builds URL for view-function giving route from app-url-map. takes function name as str and gives its URL. Eg:<ul> <li><code>url_for('user', name='john', page=2, version=1)</code> would return <code>/user/john?page=2&amp;version=1</code>, they are good to build dynamic URLs that can be used in templates.</li> <li><code>url_for('user', name='john', _external=True)</code> would return <code>http://localhost:5000/user/john</code>.</li> <li><code>url_for('static', filename='css/styles.css', _external=True)</code> would return <code>http://localhost:5000/static/css/styles.css</code>.</li> <li><code>/static/&lt;filename&gt;</code> is special route added by Flask to serve static files.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>Response Object</p> <ul> <li> <p>Response is returned by view-function as a string (usually HTML) along with status code but can also contain headers. So rather than sending comma separated tuple values, flask lets create response object using <code>make_response()</code>.</p> <pre><code>from flask import make_response\n@app.route('/')\ndef index():\nresponse = make_response('&lt;h1&gt;Some response with a cookie!&lt;/h1&gt;')\nresponse.set_cookie('message', '51')\nreturn response\n</code></pre> </li> </ul> <ul> <li><code>return redirect('http://www.example.com')</code> is a response with URL and status code 302, however Flask lets it do easily using <code>redirect()</code> method. Another such is <code>abort(404)</code> which is treated as exception.</li> </ul> <ul> <li>session - can be used to store values, specific to current session, it is server side. Helps to pass values from one function to another.<ul> <li><code>session[\"username\"] = username</code></li> <li>permanent sessions store session data for a time period</li> </ul> </li> </ul> <ul> <li>flash - lets send extra messages to frontend<ul> <li><code>flash(\"The message\", \"info\")</code> message and level.</li> <li><code>get_flashed_messages()</code> to get messages</li> <li>it lets record a message at the end of a request and access it next request and only next request.<pre><code>{% for message in get_flashed_messages() %}\n    &lt;div class=\"flash\"&gt;{{ message }}&lt;/div&gt;\n{% endfor %}\n</code></pre> </li> </ul> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#templates-in-flask","title":"Templates in Flask","text":"<p>Templates can be used to build responses.</p> <ul> <li>render_template()<ul> <li>it makes use of template</li> <li><code>return render_template('user.html', name=name)</code></li> </ul> </li> </ul> <ul> <li> <p>Jinja Templates</p> <ul> <li>Templates are HTML file having additional Python like code in placeholders.</li> <li>Placeholders can have variables and expressions.</li> <li>They get replaced with value when template is rendered by JinJa2, the template engine.</li> <li>This lets build dynamic content on execution.</li> <li>It lets inherit, extend and import templates.</li> <li>More documentation on template design and tips and tricks</li> <li> <p>Example template is below.</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n&lt;title&gt;My Webpage&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;ul id=\"navigation\"&gt;\n    {% for item in navigation %}\n        &lt;li&gt;&lt;a href=\"{{ item.href }}\"&gt;{{ item.caption }}&lt;/a&gt;&lt;/li&gt;\n    {% endfor %}\n    &lt;/ul&gt;\n    {% if kenny.sick %}\n      Kenny is sick.\n    {% elif kenny.dead %}\n      You killed Kenny!  You bastard!!!\n    {% else %}\n      Kenny looks okay --- so far\n    {% endif %}\n\n&lt;h1&gt;My Webpage&lt;/h1&gt;\n    {{ a_variable }}\n\n    {# a comment #}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> </li> </ul> <ul> <li>Filters<ul> <li>pass value over pipe to filter functions like upper, lower, title, trim, safe.</li> <li>eg, <code>Hello, {{ name|capitalize }}</code></li> <li>Full list of filters here</li> </ul> </li> </ul> <ul> <li>Delimiters<ul> <li>{% ... %} for Statements</li> <li>{{ ... }} for Expressions to print</li> <li>{# ... #} for Comments, not included in the template output.</li> </ul> </li> </ul> <ul> <li>Assignments<ul> <li> <p>lets set a value to var and use it for logic building. We have to use namespace.</p> <pre><code>{% set ns = namespace(index=0) %}\n{% for nav_item in nav %} \n  {% if ns.index !=0 %}\n    --- some stuff ---\n  {% endif %}\n  {% set ns.index = ns.index + 1 %}\n{% endfor %}\n</code></pre> </li> </ul> </li> </ul> <ul> <li>{{ super() }}, includes code from parent block, if overriding a block.</li> </ul> </li> </ul> <ul> <li>Error Handlers<ul> <li> <p><code>@app.errorhandler</code> is decorator that lets return a view from template for error responses like 404 and 500.</p> <pre><code>@app.errorhandler(404)\ndef page_not_found(e):\nreturn render_template('404.html'), 404\n@app.errorhandler(500)\ndef internal_server_error(e):\nreturn render_template('500.html'), 500\n</code></pre> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#flask-extensions","title":"Flask Extensions","text":"<p>Most extensions use app context to initialize themselves, eg:</p> <pre><code>from flask_bootstrap import Bootstrap\napp = Flask(__name__)\nbootstrap = Bootstrap(app)\n</code></pre>"},{"location":"0-Information-Technology/flask/#bootstrap-in-flask","title":"Bootstrap in Flask","text":"<ul> <li> <p>Bootstrap - provides templates and blocks that can be used in Jinja2 Templates</p> <ul> <li>installation <code>pip install flask-bootstrap</code></li> <li>eg, <code>{% extends \"bootstrap/base.html\" %}</code> - base.html does not exist but is available via extension. Others are <code>navbar</code>, <code>content</code>, <code>script</code></li> </ul> <pre><code>{% block scripts %}\n{{ super() }} &lt;!--includes base scripts too, else overrides--&gt;\n&lt;script type=\"text/javascript\" src=\"my-script.js\"&gt;&lt;/script&gt;\n{% endblock %}\n</code></pre> </li> </ul>"},{"location":"0-Information-Technology/flask/#moment-js-in-flask","title":"Moment JS in Flask","text":"<ul> <li>Moment.js Flask-Moment - Localization of Dates and Times<ul> <li>server should send UTC, client should present in local time and formatted to region using JavaScript.</li> <li><code>Moment.js</code> is perfect for this and is available as flask extension. It can be used in Jinja2 template.</li> <li><code>pip install flask-moment</code></li> <li> <p>include the script, <code>jQuery</code> is already attached as part of bootstrap</p> <pre><code>{% block scripts %}\n  {{ super() }}\n  {{ moment.include_moment() }}\n{% endblock %}\n</code></pre> <pre><code>from flask_moment import Moment\nmoment = Moment(app)\nreturn moment(datetime.utcnow()).format('LLL') # local time\nreturn moment(datetime.utcnow()).fromNow(refresh=True) # a few seconds ago..\n</code></pre> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#forms-in-flask","title":"Forms in Flask","text":"<ul> <li> <p>WTForms - Object Oriented Form building, rendering and validations.</p> <ul> <li>supports forms validation, CSRF protection, internationalization (I18N), rendering form and more for any Python framework, its generic. WTForms.</li> <li>Cons - It lets you build form in python and help validate it. It adds a extra learning curve than using HTML for the same. It same as ORM that you define things as class variables.</li> <li>You have to build a template but can use <code>Form.field</code></li> <li>It lets you extend forms.</li> <li>lets you show error easily without using <code>flash</code>.</li> </ul> <ul> <li> <p>Model Building</p> <pre><code>from wtforms import Form, BooleanField, StringField, validators\nclass RegistrationForm(Form):\nusername     = StringField('Username', [validators.Length(min=4, max=25)])\nemail        = StringField('Email Address', [validators.Length(min=6, max=35)])\naccept_rules = BooleanField('I accept the site rules', [validators.InputRequired()])\n</code></pre> <ul> <li>Form Class - in main <code>app.py</code> or in module <code>forms.py</code> make class with fields and validate functions.</li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>Flask-WTF integration of Flask and WTForms</p> <ul> <li>Includes CSRF, file upload, and reCAPTCHA. You mostly have to use formats of WTForms but write less as few things are done automatically that are related to Flask patter.</li> <li>Form fields are Class variables with different field type</li> <li>validator functions can help validate, like <code>Email()</code>.</li> <li>Link to Flask-WTF</li> </ul> <ul> <li> <p>Validation &amp; Prefill controller</p> <pre><code>from flask import Flask, render_template, session, redirect, url_for\n@app.route('/', methods=['GET', 'POST'])\ndef index():\nform = NameForm() # defined as OOP model\nif form.validate_on_submit(): # cheks POST and validates\nsession['name'] = form.name.data\nreturn redirect(url_for('index')) # POST -&gt; back to this function as GET\nreturn render_template('index.html', form=form, name=session.get('name')) # When GET\n</code></pre> <ul> <li>Route - define new route, import form class and use. On submit, create object of model class to save/query data.</li> </ul> </li> </ul> <ul> <li> <p>Rendering view</p> <pre><code>&lt;form method=\"POST\"&gt;\n{{ form.hidden_tag() }}\n{{ form.name.label }} {{ form.name() }}\n{{ form.submit() }}\n&lt;/form&gt;\n</code></pre> <ul> <li>HTML template - in <code>templates</code> folder, rendered from route with form passed as data. Display form elements, errors and hidden_tag.</li> </ul> <ul> <li> <p>You can use bootstrap and flask-wtf combine to avoid writing template code and just use</p> <pre><code>{% import \"bootstrap/wtf.html\" as wtf %}\n{{ wtf.quick_form(form) }}\n</code></pre> </li> </ul> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#databases-in-flask","title":"Databases in Flask","text":"<p>DB_package or ORM - Python has packages for most database engines like MySQL, Postgres, SQLite, MongoDb etc. If not, you can use ORM that lets you use Python objects to do SQL operations, SQLAlchemy or MongoEngine are such packages.</p> <ul> <li> <p>Flask-SQLAlchemy is wrapper on SQLAlchemy. You have to use SQLAlchemy pattern but it helps by making things tied to Flask way like session of SQLAlchemy is tied to web-request of flask.</p> <ul> <li>It is an design for Flask that adds support for SQLAlchemy to your application.</li> <li>You can define table as a class, called model, with member variables as column names.</li> </ul> <ul> <li>Installation <code>pip install flask-sqlalchemy</code></li> </ul> <ul> <li> <p>Initiation</p> <ul> <li>create <code>SQLAlchemy()</code> class object and pass <code>app</code> for context.</li> </ul> <pre><code>from flask_sqlalchemy import SQLAlchemy\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + os.path.join(basedir, 'data.sqlite')\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\ndb = SQLAlchemy(app) # Object for all ops\nclass User(db.Model):\n__tablename__ = 'users'\nid = db.Column(db.Integer, primary_key = True)\nusername = db.Column(db.String(50), unique=True)\nadmin = db.Column(db.Boolean)\ncreated_on = db.Column(db.DateTime(), default=datetime.now)\nupdated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.now)\ndb.session.add(obj)     # insert new record to database\ndb.session.delete(obj)  # delete a record from database\ndb.session.commit()     # updates modifications in object if any\n# where clause\nuser = User.query.filter_by(username=data['username']).first() # or .all()\n# select * from users\nusers = User.query.all()\n</code></pre> </li> </ul> <ul> <li> <p>DB Model</p> <ul> <li>It is a Class which represents application entities, like, User, Task, Author, Book etc.</li> <li>We can define, table, its columns, data types, keys and relationships.</li> <li><code>__tablename__ = 'users'</code></li> <li>It has attributes that represent column name. <code>name = db.Column(db.String(64), unique=True)</code></li> </ul> <ul> <li>Relationships To create ER in OOPs way <code>users = db.relationship('User', backref='role')</code><ul> <li><code>backref</code> adds a back-reference to other models</li> <li><code>lazy</code> does not execute until you add executor.<ul> <li>add <code>lazy='dynamic'</code> to prevent query execution.</li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>Create</p> <ul> <li>Once you have created a db model in flask app, you can create db and tables using following steps:<ul> <li><code>python</code></li> <li><code>from main import db</code> main is filename of flask app</li> <li><code>db.create_all()</code> creates all tables from model class, if they don't exist</li> </ul> </li> </ul> <ul> <li> <p>Now you can check SQL for tables created. You can do:</p> <ul> <li><code>sqlite3 filename.db</code></li> <li><code>.tables</code></li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li>Insert a new row<ul> <li>Create an Object of Class to build a new row. <code>user_john = User(username='john', role=admin_role)</code></li> <li>add - <code>db.session.add(user_john)</code></li> <li><code>id</code> is added to object after <code>db.session.commit()commit()</code></li> </ul> </li> <li>Update - <code>db.session.add()</code> also edits.</li> <li>Delete - <code>db.session.delete(obj_name)</code></li> <li>Read - <code>query</code> object is available to all model class. It has filter-options and executors that build a SQL Query statement.<ul> <li>Filter-Options - <code>filter()</code>, <code>filter_by()</code>, <code>limit()</code>, <code>offset()</code>, <code>order_by()</code>, <code>group_by()</code></li> <li>Executors - <code>all()</code>, <code>first()</code>, <code>first_or_404()</code>, <code>get()</code>, <code>get_or_404()</code>, <code>count()</code>, <code>paginate()</code></li> <li>Examples<ul> <li><code>User.query.all()</code> reads all records</li> <li><code>User.query.filter_by(role=user_role).all()</code></li> </ul> </li> <li><code>str(User.query.filter_by(role=user_role))</code> returns SQL query</li> </ul> </li> </ul> <ul> <li>RAW SQL - give your SQL statements<ul> <li><code>db.session.execute(SQL)</code> returns cursor</li> <li><code>db.session.execute(SQL).all()</code> - returns List result set</li> </ul> </li> </ul> <ul> <li>Shell Operations - CRUD from Flask Shell<ul> <li><code>flask --app hello.py shell</code> start shell with app_context, python shell will not have that.</li> <li><code>db.cratte_all()</code> creates SQLite file.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Py ORM Model from SQL<ul> <li>Generate SQLAlchemy class model from database table - <code>sqlacodegen mssql+pyodbc://&lt;servername&gt;\\&lt;schema&gt;/&lt;database&gt;/&lt;table_name&gt;?driver=SQL+Server --outfile db.py</code></li> </ul> </li> </ul> <ul> <li> <p>Migrations DB changes version controlled</p> <ul> <li>Why? - When DB is handled using ORM, all changes to DB is done via ORM. If you have to add a column it is added by ORM so it will delete the table and create new but to prevent data loss in table it will create a migration script to create and populate again.</li> </ul> <ul> <li>What? - <code>Flask-Migrate</code> is wrapper on <code>Alembic</code> a SQLAlchemy migration framework. It generates Py script to keep the database schema updated with the models defined. It help upgrade and roll back the schemas.</li> </ul> <ul> <li>Installation - <code>pip install flask-migrate</code></li> </ul> <ul> <li>Initiation<ul> <li><code>from flask_migrate import Migrate</code></li> <li><code>migrate = Migrate(app, db)</code></li> <li><code>flask --app hello.py db init</code> migration directory, script is generated</li> </ul> </li> </ul> <ul> <li>Execution<ul> <li><code>upgrade()</code> has data changes to be done in this migration</li> <li><code>downgrade()</code> rolls back to previous state</li> <li>Example: Steps to make a migration<ul> <li>Make changes to model classes</li> <li><code>flask --app hello.py db migrate -m \"initial migration\"</code> to generate script</li> <li>review for accurate changes. add to source control</li> <li><code>flask--app hello.py db upgrade</code> to do migration in database</li> </ul> </li> </ul> </li> </ul> <ul> <li>Reference<ul> <li>How To Make a Web Application Using Flask in Python 3</li> <li>SQLite explorer</li> </ul> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#emails-in-flask","title":"Emails in Flask","text":"<ul> <li>Why password reset, confirmations</li> </ul> <ul> <li>How?<ul> <li>Emails can be sent using <code>smtplib</code> package from Python standard library.</li> <li>Email is sent by connecting to SMTP Server which takes request to send email to recipient.</li> <li>Localhost on port 25 is local server that can send email.</li> <li>External SMTP server like <code>mail.googlemail.com</code> on <code>587</code> port can be used to send emails through Google Gmail account.</li> </ul> </li> </ul> <ul> <li>Flask-Mail is a extension that wraps <code>smtplib</code><ul> <li>Installation <code>pip install flask-mail</code></li> <li>import <code>from flask_mail import Mail, Message</code></li> <li>instantiate and initialize <code>mail = Mail(app)</code></li> <li>build obj <code>msg_obj = Message('sub','sender','to')</code></li> <li>add body and html to obj, may use template for it <code>msg.body = render_template(template + '.txt', **kwargs)</code></li> <li>send <code>mail.send(msg_obj)</code></li> </ul> </li> </ul> <ul> <li>Sending Asynchronous Email<ul> <li>Message() object can be build in mail python file but Mail() object, which sends the email using msg_obj, should run in separate thread to avoid lags.</li> <li>use python Thread() class from threading package to make new thread that runs the send_async_email(app,msg) functions. this functions has<ul> <li>app object of FLask() for context</li> <li>msg object of Message() for content</li> <li>uses mail object of Mail() to send.</li> </ul> </li> <li><code>from threading import Thread</code></li> <li>The function which build Message(), add line<ul> <li><code>thr = Thread(target=send_async_email, args=[app, msg])</code> - build thread obj</li> <li><code>thr.start()</code> execute thread separately</li> <li><code>return thr</code> [ ] why this is added</li> </ul> </li> </ul> </li> </ul> <ul> <li>Local Email Server<ul> <li><code>(venv) $ python -m smtpd -n -c DebuggingServer localhost:8025</code> this command starts emulated email server.</li> </ul> </li> </ul> <ul> <li> <p>Variables that we might need to export:</p> <pre><code>export MAIL_SERVER=smtp.googlemail.com\nexport MAIL_PORT=587\nexport MAIL_USE_TLS=1\nexport MAIL_USERNAME=email_id@domain.com\nexport MAIL_PASSWORD=\"password\"\n</code></pre> </li> </ul> <ul> <li> <p>Sending errors via Email</p> <ul> <li>Errors can be sent via email using Logs.</li> </ul> <ul> <li>Links<ul> <li>Flask docs - Email errors to admin</li> <li>MG's microblog - email errors</li> </ul> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#blueprint-large-app-structure-in-flask","title":"Blueprint - Large App Structure in Flask","text":"<p>needs improvements after hands-on</p> <ul> <li>simply, module is file, package is folder. Blueprint can be implemented in both.</li> </ul> <ul> <li>single module - link<ul> <li> <p>here, one file has everything defined</p> <pre><code>/prj\n    my-app.py # imports, app, db, orm_class, form_class, route_view_functions, run\n/static\n    /templates\n</code></pre> </li> </ul> </li> </ul> <ul> <li> no package, Blueprints as modules?</li> </ul> <ul> <li>single package, Blueprints as modules - link<ul> <li>here all ORM &amp; FORM classes are in one module</li> <li> <p>more complex, app-factory, no ORM, installable example with same structure, here</p> <pre><code>/prj\n    run.py          # import app, db. then run. What parts to run?\nconfig.py       # module. config vars. With which configurations?\n/my-app         # package\n__init__.py # app, register BP\nforms.py    # module. has form classes\nmodels.py   # module. DB setup. has ORM classes.\nauth.py     # module BP. import db, form, model. route-view-functions. login, register, logout. @login_required.\nblog.py     # module BP. import db, form, model. route-view-functions. CRUD.\n/template\n        /static\n</code></pre> </li> </ul> </li> </ul> <ul> <li>multi-packages, Blueprints as sub-packages - link<ul> <li>here ORM &amp; FORM classes are in separate module for each Blueprint.</li> <li>DB is top-level as it is shared by all sub-packages</li> <li> <p>auth is top-level to avoid circular dependencies.</p> <pre><code>/prj\n    run.py              # same. import app, db. then run\nconfig.py           # same. module. config vars\n/my-app             # package\n__init__.py     # app, register BP\nauth.py         # login init. login_manager\ndata.py         # db setup, init, open, close. crud helpers\n/users\n            __init__.py # blank\nforms.py    # module. has form classes. LoginForm, RegisterForm\nmodels.py   # module. has ORM classes. User.\nviews.py    # BP Module. imports form, model. defines route-view-functions\n/blog\n            __init__.py # blank\nforms.py    # module. has form classes. CreateBlogForm, EditBlogForm\nmodels.py   # module. has ORM classes. Post, Follower.\nviews.py    # BP Module. imports form, model. defines route-view-functions\ngeodata.py  # module. helper functions.\n/template\n        /static\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Example - Miguel Grinbers's Flasky<ul> <li>app-factory using <code>create_app()</code> in init.</li> <li>models are all in one module, not in blueprint package. [ ] why? probably all BP use models</li> <li>blueprint as sub-package's <code>__init__.py</code>, not views. [ ] why?</li> <li> <p>api package has multiple modules, all have route-view-functions.</p> <pre><code>prj/\n    run.py      # imports create_app, db, ORM-models. app init. flasky.py\nconfig.py   # module. config class with vars. EnvDict\n/app\n        __init__.py # import config, extensions. add extensions. def create_app.\nmodels.py   # import db, login_manager. def all ORM and Mixin classes\n/auth\n            __init.py # define BP. import views\nforms.py  # import ORM. Form classes\nviews.py  # import db, Forms, ORMs. def route-view-functions login, logout, register, reset\n/main\n            __init.py # define BP. import routes\nforms.py  # import ORM. Form classes\nviews.py  # import db, Forms, ORMs. def route-view-functions\n/api\n            __init.py         # define BP. import each routes\nauthentication.py # import ORM, api. def route-view-functions tokens\ncomments.py       # import db, ORM, api. def route-view-functions tokens\nposts.py          # import db, ORM, api. def route-view-functions tokens\nusers.py          # import ORMs, api. def route-view-functions users, follower\n/static\n        /templates\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Example - Miguel Grinbers's microblog<ul> <li>same as above, flasky</li> <li> <p>in sub-packages, views.py is routes.py</p> <pre><code>prj/\n    run.py      # imports create_app, db, ORM-models. app init.\nconfig.py   # module. config class with vars\n/app\n        __init__.py # import config. add extensions. def create_app. import models.\nmodels.py   # all ORM and Mixin classes\n/auth\n            __init.py # define BP. import routes\nforms.py  # import ORM. Form classes\nroutes.py # import db, bp, Forms, ORMs. def route-view-functions login, logout, register, reset\n/main\n            __init.py # define BP. import routes\nforms.py  # import ORM. Form classes\nroutes.py # import db, bp, Forms, ORMs. def route-view-functions\n/api\n            __init.py # define BP. import routes\ntokens.py # import db, bp. def route-view-functions tokens\nusers.py  # import db, bp, ORMs. def route-view-functions users, follower\n/static\n        /templates\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Example - Miguel Grinbers's microblog-api<ul> <li>app-factory using create_app in app.py</li> <li>Blueprints as modules</li> <li> <p>single package</p> <pre><code>/prj\n    run.py\n    config.py\n    api/\n        __init__.py # imports create_app, db\napp.py      # create_app, db init, registers BP\nauth.py     # import db, model. login functions\nmodels.py   # import db. ORM classes\nposts.py    # BP. imports db, ORM. route-view-functions posts, feed\ntokens.py   # BP. imports db, ORM. route-view-functions tokens, reset_token\nusers.py    # BP. imports db, ORM. route-view-functions users, me, followers\ntemplates/  # only email reset html\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Example - Miguel Grinbers's microblog-2012<ul> <li>separate module for model, form, email and view.</li> <li>no blueprint, no app-factory, no sub-package</li> </ul> </li> </ul> <ul> <li>what looks good - why?<ul> <li>app-factory - gives flexibility</li> <li>config - for env separation<ul> <li>use config class for defaults and different envs</li> <li>use YAML file to read secrets and keep it out of git</li> <li>more on config best practice</li> </ul> </li> <li>blueprints as modules.</li> <li>links<ul> <li>Another good tutorial</li> </ul> </li> </ul> </li> </ul> <ul> <li>Why? - App needs to be structured into modules as it starts growing. It also helps reuse modules.</li> </ul> <ul> <li> <p>Without Blueprint</p> <ul> <li>Single py file app structure<ul> <li>import flask modules and extensions</li> <li>instantiate flask app <code>app = Flask(__name__)</code></li> <li>configure app with all configs, eg, <code>app.config['MAIL_PORT'] = 587</code></li> <li>initialize extensions, eg, <code>mail = Mail(app)</code>. Not all extensions are initialized, eg, FlaskForm</li> <li>DB ORM Classes</li> <li>Email functions - may use templates</li> <li>Form Classes</li> <li>error handlers functions - may use templates</li> <li>routes, they may use use<ul> <li>above extensions, eg - checks Form, sends email, writes to db, or returns an error</li> <li>native - session, flash, g</li> <li>templates.</li> </ul> </li> </ul> </li> </ul> <ul> <li>templates and static files structure<ul> <li>base template is HTML, it has blocks. Block-content can be replaced or appended</li> <li>base-template is used to build different pages which put dynamic content in blocks.</li> <li>static files can be used from static folder.</li> <li>example flow<ul> <li><code>base.html</code> has blocks, title, nav, page_content</li> <li>index or profile have <code>{% extends \"base.html\" %}</code>, it tells Jinja to use base.</li> <li>block-content can be replaced or appended using <code>{{ super() }}</code></li> <li>files from <code>static</code> folder using <code>{{ url_for('static', 'favicon.ico') }}</code></li> <li>external packages can be imported as py_var to build content as py_var and use in content. eg - wtf template can be imported from bootstrap to build content from form_object using <code>{{ wtf.quick_form(form) }}</code>.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li>Blueprint lets us divide app into mini apps. It is a collection of views, templates, static files that can be applied to an application. Blueprints are a great way to organize your application.</li> </ul> <ul> <li>Application Factory is way of initializing app<ul> <li>to serve a request, when single file app in invoked, app gets initialized with configs to serve the request. You do not have flexibility to make changes to config dynamically</li> <li>app initialization can be delayed (or controlled) by making a function to do it, called <code>factory function</code>. This can be explicitly controlled.</li> </ul> </li> </ul> <ul> <li> <p>How?</p> <ul> <li>choice - you can simply keep templates and static in one folder or can split them too and keep in blueprint sub-folders.</li> </ul> </li> </ul> <ul> <li> <p>single file split</p> <ul> <li>in single file, you can move view-routes-functions.</li> <li> <p>in <code>second.py</code></p> <pre><code>from flask import Blueprint\nsecond = Blueprint(\"second\", __name__)\n@second.route(\"/home\")\ndef home():\nreturn (\"from second\")\n</code></pre> </li> </ul> <ul> <li> <p>and in <code>app.py</code></p> <pre><code>from flask import Flask\nfrom second import second\napp = Flask(__name__)\napp.register_blueprint(second, url_prefix=\"\")\n@app.route(\"/\")\ndef home():\nreturn \"Hi\"\nif __name__ == \"__main__\":\napp.run(debug=True)\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>multiple files split</p> <ul> <li>make a sub-folder and add<ul> <li>constructor</li> <li>error-route functions</li> <li>form classes</li> <li>views-route functions</li> </ul> </li> <li> <p>db models and other functions still remain in main file.</p> <pre><code>|-app_name      # 0 top level dir - any name\n|-app/          # 2 package having flask application\n|-templates/\n|-static/\n|-__init__.py   # 2.1 app pkg constructor, factory\n|-models.py     # 2.2 db models\n|-email.py      # 2.3 email \n|-main/         # 5 BP sub pkg\n|-__init__.py   # 5.1 pkg const defines BP\n|-errors.py     # 5.2 err handlers\n|-forms.py      # 5.3 form classes\n|-views.py      # 5.4 routes functions\n|-config.py     # 3 configuration variables as OOPs\n|-flasky.py     # 4 factory is invoked\n</code></pre> </li> </ul> <ul> <li>3 - <code>config.py</code> config as OOPs<ul> <li>the config variables like secret-key and mail-server, are now attributes of <code>Config</code> class.</li> <li><code>Config</code> class has <code>@staticmethod</code> as <code>init_app(app)</code> which can be used to do things once app is available, i.e. initialize app and more.</li> <li>This Config base class has common vars but can be extended to build different environment classes like dev, test, prod. that can have env specific vars like dev db-location.</li> <li>add a dictionary <code>conf_env</code> to pick the correct env class.</li> </ul> </li> <li>2 - <code>app/</code> App Package<ul> <li>dir having code, template and static files.</li> <li>2.1 - <code>app/__init__.py</code> App Pkg Constructor<ul> <li>this is where we build the <code>factory function</code> to initialize app explicitly and controlled.</li> <li>import Flask modules (only Flask)</li> <li>import Flask-Extensions (only those that need app init)</li> <li>instantiate extensions without <code>app</code></li> <li>factory function <code>def create_app(conf_env):</code> function to have<ul> <li>arg <code>conf_env</code> is dictionary key name (str) to pick required Env_Config_Class from <code>config.py</code> so that we have correct config vars.</li> <li>instantiate app</li> <li>add configs from object <code>app.config.from_object()</code></li> <li>add configs to extensions using <code>ext_obj.init_app(app)</code></li> <li>return app</li> </ul> </li> <li>while this makes config available in controlled way, however, it missing <code>@app.routes()</code> and other decorators associated to <code>@app</code> like error handles. This is handled using <code>Blueprint</code>.</li> <li> <p>import BP file and register it with app using <code>register_blueprint()</code> method. When a blueprint is registered, any view functions, templates, static files, error handlers, etc. are connected to the application.</p> <pre><code>from flask import Flask\nfrom flask_bootstrap import Bootstrap\nfrom flask_sqlalchemy import SQLAlchemy\nfrom config import config\nbootstrap = Bootstrap()\ndb = SQLAlchemy()\ndef create_app(config_name):\napp = Flask(__name__)\napp.config.from_object(config[config_name])\nconfig[config_name].init_app(app)\nbootstrap.init_app(app)\ndb.init_app(app)\n# Routes or blueprints\nfrom .main import main as main_blueprint\napp.register_blueprint(main_blueprint)\nreturn app\n</code></pre> </li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>5 Blueprint - sub pkg</p> <ul> <li>Blueprint is like app having routes but in dormant state until registered with an application which gives it a context.</li> <li>Blueprint can be a single file, or structured as a sub-package having multiple modules and the package constructor creates blueprint.</li> <li>5.1 <code>app/main/__init__.py</code> main bp creation<ul> <li>Blueprint is native flask module</li> <li>create object of <code>Blueprint()</code> class and pass it a name and location.</li> <li> <p>import associated modules</p> <pre><code>from flask import Blueprint\nmain = Blueprint('main', __name__)\nfrom . import views, errors \n# last line to avoid circular dependency\n</code></pre> </li> </ul> </li> </ul> <ul> <li>5.4 <code>app/main/views.py</code> view routes<ul> <li>route function name now has namespace with BP name as prefix, so <code>url_for('main.index')</code> should be used so that 'index' of any other BP is not picked.</li> </ul> </li> <li>5.2 <code>app/main/errors.py</code> error handlers  <ul> <li>they respond to only BP route error, for app wide use <code>app_errorhandler</code> decorator instead of <code>errorhandler</code>.</li> </ul> </li> <li>5.3 <code>app/main/forms.py</code> has form objects.</li> </ul> </li> </ul> <ul> <li>4 <code>flasky.py</code> module where app instance is denied<ul> <li><code>create_app()</code> function is called.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Link - http://exploreflask.com/en/latest/blueprints.html</li> </ul>"},{"location":"0-Information-Technology/flask/#testing-in-flask","title":"Testing in Flask","text":"<ul> <li>Why<ul> <li>function code only runs when it is called.</li> <li>if else code is only called when condition is met.</li> <li>ensure code for all branch and function is run by changing scenarios.</li> <li>100% coverage is when you run all functions and code in all if else try catch is tested.</li> <li>do test as you develop.</li> <li><code>pytest</code> to test</li> <li><code>coverage</code> to measure</li> </ul> </li> </ul> <ul> <li> <p>PyTest</p> <ul> <li>modules and functions both start with <code>test_</code></li> <li>Fixtures are setup functions, that setup how app should behave<ul> <li>You can build different fixtures to have different app instances or to test different interactions like client requests or CLI commands.</li> <li>fixtures call app-factory with test configs to make app separate from dev config.</li> <li><code>conftest.py</code> - sample below.<ul> <li>here fixure creates app, which is then passed to other fixture for specific testing.</li> <li><code>app.test_client()</code> lets make request to app without server. Available in <code>client</code> fixture.</li> <li><code>app.test_cli_runner()</code> lets test CLI commands registered with app. Available in <code>runner</code> fixture.</li> <li>these fixture names (client or runner) are passed in test_functions to use them.</li> </ul> </li> <li> <p>You can keep building fixture on top of other fixture to add predefined functionalities. Eg, on top of client add another class that can help login and logout.</p> <pre><code>@pytest.fixture\ndef app():\napp = create_app(...)\nwith app.app_context():\ninit_db()\nyield app\n@pytest.fixture\ndef client(app):\nreturn app.test_client()\n@pytest.fixture\ndef runner(app):\nreturn app.test_cli_runner()\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Test Cases<ul> <li>start with <code>test_</code> in both module and function name.</li> <li> <p>use <code>assert</code></p> <pre><code>from app import create_app\ndef test_hello(client):\nresponse = client.get('/hello')   # sends this URL request\nassert response.data == b'Hello, World!'\n</code></pre> </li> </ul> </li> </ul> <ul> <li><code>pytest.mark.parametrize</code> lets run the test with different params</li> <li>to test context variables like <code>session</code> or <code>g</code> use <code>with client:</code> Otherwise it raises an error.</li> <li><code>setup.cfg</code> can have extra configs (not mandatory).</li> </ul> <ul> <li>Run - Pytest<ul> <li><code>pytest</code> runs test</li> <li><code>pytest -v</code> runs and shows all files</li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>Report - Coverage</p> <ul> <li><code>coverage run -m pytest</code> runs tests and measures coverage</li> <li><code>coverage run -m unittest</code> runs tests using unittest and measures coverage</li> <li><code>coverage report</code> shows coverage report on CLI</li> <li><code>coverage html</code> builds dir for detailed report<ul> <li><code>htmlcov/index.html</code> has detailed report.</li> <li>shows code covered and not covered.</li> </ul> </li> <li>To exempt a code block from coverage, add <code># pragma: no cover</code> after code block. Make this a tough decision to skip code from testing.</li> </ul> <ul> <li>more here</li> </ul> </li> </ul> <ul> <li>Manual Testing<ul> <li>Basic testing can be done using flask shell and executing functions <code>flask --app flasky.py shell</code></li> <li>do things similar to as you do in wrinting code, like import module, create objects, call functions etc.</li> <li>use <code>current_app</code> to use <code>app_context</code>, or</li> <li><code>with app.app_context():</code> when using factory</li> <li>What you test in shell should be automated by making test cases.</li> </ul> </li> </ul> <ul> <li> <p>UnitTest - test small units</p> <ul> <li>use py native <code>import unittest</code></li> <li>in <code>tests/test_basics.py</code><ul> <li>import modules you need for test, <code>create_app</code>, <code>db</code></li> <li>import modules you want to test, <code>User</code>, <code>current_app</code></li> <li>define class <code>class BasicsTestCase(unittest.TestCase):</code><ul> <li>build functions<ul> <li><code>setUp()</code> runs before each test, builds env for testing</li> <li><code>tearDown()</code> runs after each test, removes things from env</li> <li><code>test_somecase()</code> these functions run as test.<ul> <li><code>assertTrue</code> Ok if True</li> <li><code>assertFalse</code> Ok if False</li> <li><code>with self.assertRaises(AttributeError):</code> statement that raise error.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>tests can be written in separate py files (modules) and the folder <code>tests</code> can have <code>__init__.py</code> as blank to make it a pkg</li> <li>in <code>flasky.py</code> you can add code to run tests automatically by adding a cli command.</li> <li>do <code>flask --app flasky.py test</code> to run all test cases<pre><code>@app.cli.command()\ndef test():\n\"\"\"Run the unit tests.\"\"\" # help msg on cli\nimport unittest\ntests = unittest.TestLoader().discover('tests')\nunittest.TextTestRunner(verbosity=2).run(tests)\n</code></pre> </li> </ul> <ul> <li><code>python -m unittest</code> discovers and runs all tests.</li> </ul> </li> </ul> <ul> <li>Unittest vs PyTest<ul> <li>Unittest is universally accepted and is built in Python standard library</li> <li>PyTest has lot of features and we need to write less</li> <li>Unitest needs classes &amp; methods. Pytest only needs methods.</li> <li>Pytest runner has full support for test cases written in UnitTest clasees.</li> <li>Use both, OOPs of Unittest and better assert of Pytest with and its better error reporting.</li> </ul> </li> </ul> <ul> <li> <p>Unittest and PyTest</p> <ul> <li>You can use Unittest and Pytest togehter to make use of best of both.</li> </ul> <ul> <li>Test Parametrization<ul> <li>when you have same test-code but have to run with different input parameters.</li> <li>Pytest uses non OOPs params, to make Unittest OOPs model work with PyTest add <code>pip install parameterized</code>.</li> <li>then use its decorator and pass params as list of tuples to argument.</li> <li>list is input scenarios</li> <li>tuple is variables in each scenario. One value tuple is <code>('name1',)</code></li> <li> <p>Eg, <code>[('name1',32), ('name2',24)]</code>, <code>@parameterized.expand([(n,) for n in range(9)])</code>, <code>@parameterized.expand(itertools.product([True, False], range(9)))</code></p> <pre><code>class TestLife(unittest.TestCase):\n# ...\n@parameterized.expand([('name1',32), ('name2',24)])\ndef test_load(self, name, age): # this method runs the number of items in list.\nu = User(name, age)\nassert u.name = name\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Test Exceptions<ul> <li> <p><code>pytest.raises()</code> can be used to test if a certain error is raised on run time.</p> <pre><code>with pytest.raises(RuntimeError):\ndata.load('corrupt_data.txt')\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Mocking<ul> <li>When you have to change return value of a pre defined function. You can mock a function to return a specific value irrespective of what is passed to it without modifying its code.</li> <li>More here on MG's Unit Testing - Mocking</li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>Test Code Structure</p> <ul> <li>create a test module (file) of same name as test subject with test_ prefixed. Eg, <code>test_foo.py</code></li> <li>import <code>unittest</code> and other required packages</li> <li>create classes and methods for testing.</li> <li> <p>in test_method</p> <ul> <li>call code from your app, set varibles or directly put code in assert</li> <li><code>assert some-code</code> some-code can be anything that evaluates to True.</li> </ul> <pre><code>import unittest\nfrom app import User, Engine\nclass TestUserAdd(unittest.TestCase):\ndef test_works(self):\nu = User()\nassert u.exists() # anything that evalueates to True\nclass TestEngineWork(unittest.TestCase):\npass\n</code></pre> </li> </ul> <ul> <li> <p>For a Flask App</p> <ul> <li><code>setUp</code> and <code>tearDown</code> methods are special that automatically invoked before and after each test case. This makes every test case run on clean slate. You can have different one in each class, or make a base class and import it in other classes.</li> <li>request functions<ul> <li><code>response = app.client.get('/', follow_redirects=True)</code> - use response same as you do in flask app</li> <li><code>response = self.client.post('/auth/register', data={some_json}, follow_redirects=True)</code> - submit a form this way</li> </ul> </li> </ul> <ul> <li>response methods<ul> <li><code>html = response.get_data(as_text=True)</code></li> <li><code>assert response.status_code == 200</code></li> <li><code>assert response.request.path == '/auth/login' # redirected to login</code></li> <li><code>response.json['token']</code></li> </ul> </li> </ul> <p>```python</p> </li> </ul> </li> </ul> <ul> <li>Do s<ul> <li> <p>If a piece of code is difficult to test with test case, consider refactoring it. Eg, some code that is not in funciton and just prints as part of execution can't be called from test case, so make a function for it. Alos, you can wrap any global code in a function and call it. This also makes code only direct executable when file is ran, import doesn't execute it.</p> <pre><code>def main():\nall_your_global_code()\nif __name__ == '__main__':\nmain()\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Links<ul> <li>MG' Flask Web App Testing</li> <li>MS's Testing code for Life Game</li> <li>Stackoverflow why to use PyTest</li> <li>Flask Docs - Pure Pytest</li> <li>RealPython - Flask testing has a different package, so differs</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#teststest_basepy","title":"tests/test_base.py","text":"<p>import unittest from flask import current_app from app import create_app, db</p> <p>class TestWebApp(unittest.TestCase):     def setUp(self):         self.app = create_app()         self.appctx = self.app.app_context()         self.appctx.push()         db.do_something() # you can call any method as well here         self.do_something() # method in this class that has code to be executed before each test, like register         self.client = self.app.test_client()</p> <pre><code>def tearDown(self):\n    db.drop_something() # again execute anything at end of test case\n    self.appctx.pop()\n    self.app = None\n    self.appctx = None\n    self.client = None\n\ndef test_app(self):\n    assert self.app is not None\n    assert current_app == self.app\n\ndef test_home_page_redirect(self):\n    response = self.client.get('/', follow_redirects=True)\n    slef.do_login() # funciton in this class that logs in to the app can be reused\n    assert response.status_code == 200\n    assert response.request.path == '/auth/login'\n```\n</code></pre>"},{"location":"0-Information-Technology/flask/#error-handling","title":"Error Handling","text":"<ul> <li>We can have templates for exceptions and errors so they don't go out to end users.</li> <li>Link RealPython Flask App Part III</li> </ul>"},{"location":"0-Information-Technology/flask/#log-in-flask","title":"Log in Flask","text":"<ul> <li>A standard Python logging component <code>logger</code> is available on the Flask object at <code>app.logger</code>.</li> <li>404 is autologged by server, so skip.</li> <li>request logs are autologged by proxy server, so skip.</li> <li>Exceptions, 400 and 500 can be logged to look back in time.</li> </ul> <ul> <li>Setup<ul> <li>configure logger as early as possible</li> <li>add path and log configs in <code>config.py</code> even before app is created. You can add logging config to any env config class. They are all called before app is created.</li> </ul> </li> </ul> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\napp = Flask(__name__)\napp.logger.info('some log')\n# prj/config.py\nimport logging\nclass Config:\nlogging.basicConfig(level=logging.DEBUG, format='[%(asctime)s] - %(name)s - %(levelname)s - %(module)s -: %(message)s')\n# prj/app/models.py\nfrom flask import current_app\ncurrent_app.logger.debug('Some message')\n</code></pre> <ul> <li> <p>Explore here</p> <p>```py log = logging.getLogger(name)</p> <p>def init_log():     logging.basicConfig(level=logging.DEBUG)     log.info(\"Logging enabled\")     # Set the log level for werkzeug to WARNING because it will print out too much info otherwise     logging.getLogger(\"werkzeug\").setLevel(logging.WARNING)   ```</p> </li> </ul> <ul> <li>Links<ul> <li>FlaskDocs - Config Logger</li> <li>MG - Logging to a File Legacy</li> <li>RealPython - Flask Part III - Logging. Eg, shows to Log Errors, keep 7 days history.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#make-the-project-installable","title":"Make the Project Installable","text":"<ul> <li>Makes the project distributable like a library, so people can do <code>pip install</code> and use it.</li> <li>Deploying is same as installing any other library. like you deploy <code>mkdocs</code> by installing it.</li> <li> <p><code>setup.py</code> outside <code>app</code> is where we can define this.</p> <pre><code>from setuptools import find_packages, setup\nsetup(\nname='your-project-name',\nversion='1.0.0',\npackages=find_packages(),\ninclude_package_data=True,\ninstall_requires=[\n'flask',\n],\n)\n</code></pre> </li> </ul> <ul> <li>also add <code>MAINFEST.in</code> to tell what other files to include in package. Eg, <code>some.sql</code> <code>static</code> or any other.</li> <li>more here</li> <li>RealPython Flask App part III</li> </ul>"},{"location":"0-Information-Technology/flask/#deployment-fundamentals","title":"Deployment Fundamentals","text":"<ul> <li>WSGI or \"Web Server Gateway Interface\"<ul> <li>is a protocol (calling convention) to forward requests from a web server (Apache or NGINX) to a backend Python web application or framework. Python then builds response which is passed back to the webserver which shares it to the requestor.</li> <li>it sits between Web Server and Python App. <code>Client -&gt; Webserver -&gt; WSGI -&gt; Python</code></li> <li>WSGI containers are Gunicorn, uWSGI. They invoke python callable object, such as a route in flask.</li> <li>WSGI container is required to be installed in the project so that a web server can communicate to a WSGI container which further communicates to the Python application and provides the response back accordingly.</li> </ul> </li> </ul> <ul> <li>Development Web Server<ul> <li>most frameworks come with development web server which serves requests. but this needs to be replaced on PROD.</li> </ul> </li> </ul> <ul> <li>Links<ul> <li>What is WSGI</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#deployment-windows-iis-server","title":"Deployment - Windows IIS Server","text":"<ul> <li><code>HTTP -&gt; IIS -&gt; ISAPI -&gt; FastCGI -&gt; WSGI -&gt; (Python Flask Application)</code></li> </ul> <ul> <li>IIS site will trigger a <code>wfastcgi.py</code> script and will use <code>web.config</code> file which calls module that has flask app (or creates using app factory).</li> <li>WFastCGI is a Py package, and <code>wfastcgi.py</code> provides a bridge between IIS and Python using WSGI and FastCGI. It is same as mod_python is for Apache.</li> <li>you can impersonate as a user in appPoolIdentity</li> <li>you can disable anonymous auth and can keep only windows authenticated access to get remote user in request.</li> </ul> <ul> <li>Links<ul> <li>Detailed deployment process on Medium</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#deployment-pythonanywhere-flask","title":"Deployment - PythonAnywhere Flask","text":"<ul> <li> <p>WSGI configuration</p> <ul> <li>On your Web App Configuration page, open \"WSGI configuration file\", and ensure you add your project folder to code below.</li> </ul> <pre><code>import sys\n# add your project directory to the sys.path\nproject_home = u'/home/username/mysite'\nif project_home not in sys.path:\nsys.path = [project_home] + sys.path\n# import flask app but need to call it \"application\" for WSGI to work\nfrom flask_app import app as application  # noqa\n</code></pre> </li> </ul> <ul> <li>more here</li> </ul>"},{"location":"0-Information-Technology/flask/#static-site-with-flask-frozen","title":"Static Site with Flask-Frozen","text":"<ul> <li>Static site can be generated and hosted on Netlify or GitHub pages.</li> </ul> <ul> <li>link<ul> <li>td.io - Frozen</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#access-localhost-flask-app-on-network","title":"Access localhost flask app on Network","text":"<ul> <li>Suppose on an Ubuntu VM a flask app is running on localhost and you want to access it from you host machine that is Mac.</li> </ul> <ul> <li>Run flask app with <code>app.run(host='0.0.0.0', debug=True)</code></li> <li>This tells your operating system to listen on all public IPs.</li> <li>then access <code>192.168.10.33:5000</code> from host machine.</li> </ul> <p>Now that our app is running we can add a database to this app. We will use FlaskSQLAlchemy package for this. Or Pandas.</p>"},{"location":"0-Information-Technology/flask/#machine-learning-pandas-app-in-flask","title":"Machine Learning Pandas App in Flask","text":"<p>You can use Flask it with Pandas, Matplot and other ML libraries to make it easily usable for end users.</p> <ul> <li>Import all your libs in flask app that you have used in Jupyter NB.</li> <li>Add code and functions to read data and perform tasks.</li> <li>Flask routes are executed for each request, so keep data reads outside to read them once.</li> <li><code>return render_template( 'search.html', data=df_result.to_html(classes='table table-striped table-hover')</code> - to_html makes html table that can be passed to html page.</li> <li><code>{{ data|safe }}</code> - safe makes it as markup and browser renders it.</li> </ul> <p>Reference:</p> <ul> <li>https://sarahleejane.github.io/learning/python/2015/08/09/simple-tables-in-webapps-using-flask-and-pandas-with-python.html</li> </ul>"},{"location":"0-Information-Technology/flask/#charts-graphs-visualization-in-flask","title":"Charts Graphs Visualization in Flask","text":"<ul> <li>Requirements<ul> <li>HTML5 instead of PNG</li> <li>dynamic, shows info on hover</li> <li>interactive, filters modify charts</li> <li>dashboard, filters update multiple charts</li> <li>streaming dataset</li> <li>animation</li> </ul> </li> </ul> <ul> <li>Plotly<ul> <li>dynamic &amp; interactive charts</li> <li>handle data and build-chart in view function, then send JSON to template, use JSON in JS.</li> </ul> </li> </ul> <ul> <li>Plotly Express<ul> <li><code>import plotly.express as px</code></li> <li><code>fig = px.bar()</code> lets build bar</li> <li><code>fig.show()</code> makes PNG</li> </ul> </li> </ul> <ul> <li>Plotly Graph Objects<ul> <li><code>import plotly.graph_objects as go</code> builds figure objects.</li> <li>has class for object like <code>go.Bar()</code></li> <li>objects need to be added to figure <code>fig = px.Figure()</code></li> </ul> </li> </ul> <ul> <li>Bokeh<ul> <li>beautiful charts, simple plot to complex dashboard with streaming dataset!</li> <li>dynamic &amp; interactive</li> <li><code>bokeh.plotting</code> has plotting functions</li> <li><code>bokeh.models</code> has data handling functions</li> <li><code>bokeh.embed</code> has component that return HTML with JS ready to embedd, when python <code>fig</code> is passed.</li> </ul> </li> </ul> <ul> <li>Dash<ul> <li>React front-end - yes</li> <li>dashboard - yes</li> <li>HTML in Python - NOooo</li> <li><code>from dash import Dash, html, dcc</code><ul> <li>Dash is app</li> <li>html lets build html components <code>Div()</code> H1</li> <li>dcc is Dash Core Components - lets build <code>Graph() Dropdown()</code>, graph has figues, from px.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Flask, Plotly &amp; AJAX<ul> <li>Flask app and html template</li> <li>use <code>json.dumps()</code> to get fig JSON and send to template</li> <li>use list of <code>chartJSON[]</code> for sending multiple charts</li> <li>template can use plotly js to plot chart with the json.</li> <li>js <code>Plotly.plot('chart',graphs,{});</code> where <code>chart</code> is <code>id</code> of <code>div</code></li> <li>to extend, send graphJSON, header, description</li> <li>AJAX<ul> <li><code>onchange=cb(this.value)</code> to invoke callback function, that passes value to python and python returns updated chartJSON</li> </ul> </li> </ul> </li> </ul> <ul> <li>Data Handling<ul> <li>mostly libraries use list, which has series from DataFrame</li> <li>px takes in dataframe as <code>data</code></li> </ul> </li> </ul> <ul> <li>Altair<ul> <li>py library</li> </ul> </li> </ul> <ul> <li>Chart.js<ul> <li>No Python wrapper</li> <li>is dynamic</li> </ul> </li> </ul> <ul> <li>Highchart, google charts, d3.js ?</li> </ul> <ul> <li>anychart<ul> <li>can be drawn from JSON, JSON needs to build without python wrapper</li> </ul> </li> </ul> <ul> <li>Matplot, ggplot<ul> <li>static chart, save fig as png, return file from view_function</li> </ul> </li> </ul> <ul> <li>Links<ul> <li>TDS - Web Visualization with Plotly and Flask</li> <li>TSD - Flask plotly AJAX</li> <li>Dash offical</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#restapi-in-flask","title":"RestAPI in Flask","text":"<p>What is REST?</p> <ul> <li>Client and Server are separate</li> <li>Stateless: No information from a request is stored on client to be used in other requests, eg, no session can be started, if authentication is required, username and password need to be sent with every request.</li> </ul> <p>What is RESTful API:</p> <ul> <li>There is a resource, eg, tasks</li> <li>It has endpoints for CRUD operations</li> <li>HTTP methods, GET PUT POST DELETE, are used for these operations.</li> <li>Data is provided with these requests in no particular format but usually as:<ul> <li>JSON blob in request body, or</li> <li>Query String arguments as portion of URL.</li> </ul> </li> </ul> HTTP Method URI Action GET http://[hostname]/todo/api/v1.0/tasks Retrieve list of tasks GET http://[hostname]/todo/api/v1.0/tasks/[task_id] Retrieve a task POST http://[hostname]/todo/api/v1.0/tasks Create a new task PUT http://[hostname]/todo/api/v1.0/tasks/[task_id] Update an existing task DELETE http://[hostname]/todo/api/v1.0/tasks/[task_id] Delete a task <p>Data of a task can be, JSON blob, as:</p> <pre><code>{\n'id': 1,\n'title': 'Title of a to do task',\n'description': 'Description of to do task', \n'done': False\n}\n</code></pre> <ul> <li>This API can be consumed by client side app which can be single page HTML.</li> <li>Note, JSON object is defined in python as dict, <code>jonify</code> converts and send as JSON Object.</li> </ul>"},{"location":"0-Information-Technology/flask/#jwt-authentication-in-flask","title":"JWT Authentication in Flask","text":"<ul> <li>JWT Authentication<ul> <li><code>jwt</code> python library is used to make a <code>token</code> that can be send in every request instead of sending username and password.</li> <li>Token is encoded string which has a valid time and it expires after that time.</li> <li><code>ExpiredSignatureError</code> is raised if you <code>decode</code> and expired token string.</li> <li> how to add remember me.</li> </ul> </li> </ul> <ul> <li>how to register?<ul> <li>comment <code>token_authentication</code> for <code>create_user</code></li> <li><code>curl -i -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"admin\"}' http://127.0.0.1:5000/admin</code></li> </ul> </li> </ul> <ul> <li>CURL Requests<ul> <li>Send Username and password to get token<ul> <li><code>curl -u username:password -i -X GET http://127.0.0.1:5000/login</code> returns token and duration</li> </ul> </li> <li>Send token in header to access protected resources<ul> <li><code>curl -H \"x-access-token: token\" -i -X GET http://127.0.0.1:5000/users</code></li> <li><code>curl -H \"x-access-token: token\" -i -X GET http://127.0.0.1:5000/users/9d8c738b-3a39-482d-8a17-0c1b755f9a23</code></li> <li><code>curl -H \"x-access-token: token\" -i -X GET http://127.0.0.1:5000/api/v1.0/tasks</code></li> <li><code>curl -H \"x-access-token: token\" -i -X GET http://127.0.0.1:5000/api/v1.0/tasks/19</code></li> </ul> </li> <li> will this be more secure and beneficial?<ul> <li><code>curl -u username_or_token:password_or_unused -i -X GET http://127.0.0.1:5000/users</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#app-restful-api-in-flask","title":"App - RESTful API in Flask","text":"<p>to be added</p>"},{"location":"0-Information-Technology/flask/#serving-over-https","title":"Serving over HTTPS","text":"<ul> <li>generate certificate key using <code>openssl req -x509 -newkey rsa:4096 -nodes -out cert.pem -keyout key.pem -days 365</code></li> <li>allow insecure connection to localhost in chrome, paste <code>chrome://flags/#allow-insecure-localhost</code></li> <li>https://blog.miguelgrinberg.com/post/running-your-flask-application-over-https</li> </ul>"},{"location":"0-Information-Technology/flask/#app-social-blogging-app-in-flask","title":"App - Social Blogging App in Flask","text":"<ul> <li> <p>User Authentication</p> <ul> <li>Password hashing<ul> <li>extensions - <code>from werkzeug.security import generate_password_hash, check_password_hash</code> this is tried and tested lib that is safe to use.</li> <li>model - implement <code>password</code> as write-only property of <code>User</code> class to set <code>password_hash</code></li> </ul> </li> </ul> <ul> <li>Blueprint - structure it as a sub-module <code>auth</code> Blueprint. It has view having login-route</li> </ul> <ul> <li> <p>Normal auth</p> <ul> <li>Login - <code>session['user_id'] = user['id']</code> once credentials are verified, save <code>user_id</code> in <code>session</code> dictionary, it makes it available across requests for the session.<ul> <li> <p><code>g.User</code> can hold user object. Using Blueprints decorator <code>@bp.before_app_request</code> register a function that sets <code>g.user</code>. If there is no <code>user_id</code> in session, <code>g.User</code> will be <code>None</code></p> <pre><code>@bp.before_app_request\ndef load_logged_in_user():\nuser_id = session.get('user_id')\nif user_id is None:\ng.user = None\nelse:\ng.user = get_db().execute(\n'SELECT * FROM user WHERE id = ?', (user_id,)\n).fetchone()\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Logout - <code>session.clear()</code></li> </ul> <ul> <li> <p>Login Required Decorator - lets you use <code>@login_required</code> on view function so the following code is run before view-route code.</p> <pre><code>def login_required(view):\n@functools.wraps(view)\ndef wrapped_view(**kwargs):\nif g.user is None:\nreturn redirect(url_for('auth.login'))\nreturn view(**kwargs)\nreturn wrapped_view\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>Flask-login is ext having functions and decorators that make authentication easy.</p> <ul> <li>model - few required class members can either be declared in <code>User</code> class or can be importe from <code>UserMixin</code> class of Flask-login.</li> <li> <p>initialize and instantiate extension with required conf</p> <pre><code>from flask_login import LoginManager\nlogin_manager = LoginManager()\nlogin_manager.login_view = 'auth.login'\ndef create_app(config_name):\n# ...\nlogin_manager.init_app(app)\n# ...\n</code></pre> </li> </ul> <ul> <li> <p>model implement user_loader in <code>User</code> class</p> <pre><code>from . import login_manager\n@login_manager.user_loader\ndef load_user(user_id):\nreturn User.query.get(int(user_id))\n</code></pre> </li> </ul> <ul> <li><code>login_required</code> decorator lets protect route.</li> <li>Flask-Login\u2019s <code>login_user()</code> logs user in once verified. It setts user session.</li> <li><code>logout_user()</code> logs user out.</li> </ul> </li> </ul> <ul> <li>Register User<ul> <li>build a form class in new <code>auth/forms.py</code>, add unique email and username validator using <code>validate_</code> function</li> <li>build a template that uses form <code>templates/auth/register.html</code></li> <li>build a register route in <code>auth/views.py</code><ul> <li>get - render form</li> <li>post - validate and add user to db</li> </ul> </li> </ul> </li> </ul> <ul> <li>account confirmations<ul> <li>use expiry token to validate email url.</li> <li>model - add token generation and validation function.</li> <li>view - send email on registration</li> <li>view - <code>@auth.route('/confirm/&lt;token&gt;')</code></li> </ul> </li> </ul> <ul> <li>Links<ul> <li>RealPython Flask-Login</li> </ul> </li> </ul> </li> </ul> <ul> <li>Roles and Permissions<ul> <li>database implementation<ul> <li>add <code>role</code> table</li> <li>add <code>permission</code> column to role table as integer<ul> <li>multiple permission can be binary numbers, 1,2,4,8,16</li> <li>add them and subtract them to get unique number as total permission of user. 2+4=6</li> <li>do bit wise and operation to match permission. 6&amp;2=2, 6&amp;4=4</li> </ul> </li> </ul> </li> <li>add decorator function to make it easy to protect route to access only if permission is checked.</li> </ul> </li> </ul> <ul> <li>User Profiles</li> </ul>"},{"location":"0-Information-Technology/flask/#app-mega-tutorial-by-mg","title":"App - Mega Tutorial by MG","text":"<p>This is understanding of a tutorial by Miguel Grinberg, we are learning to create a micro-blogging site using flask and other dependencies.</p> <ul> <li> UserMixin?</li> <li> Why we pass Classes as param to Class?</li> </ul>"},{"location":"0-Information-Technology/flask/#elastic-search-in-flask","title":"Elastic Search in Flask","text":"<ul> <li>You can install elastic search by <code>brew install elasticsearch</code> on mac.</li> <li>Access <code>http://localhost:9200</code> to view service JSON output.</li> <li>Also, install in python <code>pip install elasticsearch</code></li> <li>To have launched start elasticsearch now and restart at login: <code>brew services start elasticsearch</code></li> <li>Or, if you don't want/need a background service you can just run: <code>elasticsearch</code></li> </ul>"},{"location":"0-Information-Technology/flask/#advanced-flask","title":"Advanced Flask","text":"<ul> <li> <p>Request Processing</p> <ul> <li> <p>Following diagram show the cycle of request-response</p> <pre><code>graph LR\nRequest --&gt;|GET\\n1| Web_Server\nWeb_Server --&gt; WSGI_Server\nWSGI_Server --&gt;|Spawns\\n2| Flask_App\nFlask_App --&gt;|Pushes\\n3| Application_Context\nFlask_App --&gt;|Pushes| Request_Context\nApplication_Context --&gt;|current_app\\n4| View_Function\nRequest_Context --&gt;|request| View_Function\nsubgraph Global\nApplication_Context\nRequest_Context\nend\nsubgraph Worker\nFlask_App --&gt; View_Function\nend\nView_Function --&gt;|5| Response</code></pre> </li> </ul> <ul> <li>Step 1 - Handle request<ul> <li>Web_server - Apache &amp; NginX</li> <li>WSGI_Server - Gunicorn, uWSGI, mod_wsgi</li> </ul> </li> <li>Step 2 - Spawn a Worker<ul> <li>it can be a thread, process or coroutine.</li> <li>one worker handles one request at a time.</li> <li>hence for multiple concurrent request multiple worker can be spawned.</li> </ul> </li> <li>Step 3 - pushes context<ul> <li>worker pushes context to global-stack as <code>context-local</code> which uses <code>thread-local</code> data, which means, a worker, which is one thread, has data specific to a thread and can be only accessed by worker that created it. So its global-memory but worker-unique data as <code>global LocalStack()</code>.</li> </ul> </li> <li>Step 4 - local context, proxy<ul> <li>this context data is basically an object, stored as stack data structure. To make it available in view-function it is not passed as a parameter, neither is imported as a global object, rather it is made available using proxy</li> </ul> </li> <li>Step 5 - Clean Up<ul> <li>req and app context are removed from stack</li> </ul> </li> </ul> </li> </ul> <ul> <li>Threading</li> </ul> <ul> <li>Link<ul> <li>td.io - Request processing</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flask/#links","title":"Links","text":"<ul> <li>Official Flask Blogging Tutorial - Flaskr<ul> <li>app factory, blueprint</li> <li>Plane DB operations, no ORM SQLAlchemy</li> </ul> </li> <li>RealPython Flask Tutorial - Part I</li> <li>Flask Mega Tutorial I - Miguel Grinberg</li> <li>Flask Mega Tutorial I Legacy - Miguel Grinberg<ul> <li>no blueprint.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flutter/","title":"Flutter","text":"<p>Google Flutter is a framework for developing applications for iOS, Android and Web with same code base. It uses Dart as programming language. The dart code gets compiled to java/javascript/swift for native performance. It has rich open source libraries to plug in.</p> <p>Everything is a widget here :)</p>"},{"location":"0-Information-Technology/flutter/#quickstart","title":"Quickstart","text":"<ul> <li><code>flutter create --org com.codeo myapp</code> create a basic app</li> <li><code>flutter pub get</code> gets all packages</li> <li><code>flutter run -d Chrome</code> runs flutter app on device chrome</li> <li><code>pod setup</code> makes ios deploy faster</li> <li><code>flutter build web/apk</code> builds app for publishing</li> </ul>"},{"location":"0-Information-Technology/flutter/#structure","title":"Structure","text":"<ul> <li>assets - hold images/fonts</li> <li>lib - all the dart code<ul> <li>we can make folders specific for activity</li> <li>models - hold class for data in the app like users.dart, deserialize json</li> <li>pages - hold screens, each .php page or route</li> <li>widgets - component on pages, like progress bar</li> </ul> </li> <li>all folders are packages, eg, lib package, src package, models package.</li> </ul>"},{"location":"0-Information-Technology/flutter/#basic-workflow","title":"Basic Workflow","text":"<ul> <li>make product class, init constructor, add factory, the get and set functions</li> <li>link this to sqflite<ul> <li>have a db_provider</li> <li>and an init function</li> <li>crud functions</li> </ul> </li> <li>or firebase<ul> <li>get reference of a collection in instance.</li> <li>from ref get the snapshots and build.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/flutter/#development","title":"Development","text":"<ul> <li><code>add(a,b) =&gt; a + b</code> creates function inline and returns valuel, can be without name.</li> <li><code>setState(){}</code> - rebuilds the app. usually used in onTap(){}.</li> <li>wrapping parameters in {} make them named params and we have to specify the name when passing them in call. eg: <code>emp({String name, Int age})</code>, when called, <code>emp(name: 'Jon', age: 34)</code>.</li> <li><code>initState() {}</code> function gets executed in every State ful widget. can be used to call all what we want to initialize, like db fetch etc.</li> <li><code>&lt;Future&gt;</code> needs to be handled. Either we can use <code>.then((data) {...})</code> or we can add keywords <code>async...await</code> to the functions.</li> <li><code>factory</code> before a func declaration makes it accessible outside class just like static.</li> <li>To preserve state of app, use mixin keep alive.</li> <li>await and async are good to wait for a process to finish and the execute the rest.</li> <li>Null-aware Operators in Dart</li> </ul> <p>Navigation:</p> <ul> <li>We can generate route on the go with Navigator.pop or push.</li> </ul>"},{"location":"0-Information-Technology/flutter/#function-calling","title":"Function calling","text":"<ul> <li>When work needs to be done on call, then pass refrence.</li> <li>When function builds/returns then call with ()s.</li> <li>Here is the difference:<ul> <li>onPressed: _incrementCounter is a reference to an existing function is passed. This only works if the parameters of the callback expected by onPressed and _incrementCounter are compatible.</li> <li>onPressed: _incrementCounter() _incrementCounter() is executed and the returned result is passed to onPressed. This is a common mistake when done unintentionally when actually the intention was to pass a reference to _incrementCounter instead of calling it.</li> </ul> </li> </ul> <p>External Links:</p> <ul> <li>appicon.co - app icons</li> <li>icons8.com - use icons for free</li> <li>vecteezy.com - icons</li> <li>canva.com - create own design</li> </ul>"},{"location":"0-Information-Technology/flutter/#flutter-state-management","title":"Flutter State Management","text":"<p>Flutter allows to use many kind of state management architectures like Redux, BLoC, MobX and many more. These all are commonly used architecture to layer out UI from Database/WebAPIs.</p>"},{"location":"0-Information-Technology/flutter/#bloc-business-logic-component","title":"BLoC - Business Logic Component","text":"<ul> <li>separates UI from Business logic (Database and Network).</li> <li><code>Sink&lt;data&gt;</code> - data in - events</li> <li><code>Stream&lt;data&gt;</code> - data out - state</li> </ul> <ul> <li>BLoC component converts a stream of incoming events into a stream of outgoing states.</li> <li>Close bloc references in despose() methods.</li> <li>It has:<ul> <li>Bloc</li> <li>BlocBuilder</li> <li>BlocProvider</li> </ul> </li> </ul> <ul> <li>Reactive Programming, whenever there is new data coming from the server. We have to update the UI screen</li> </ul> <ul> <li>KeyNote: never make any network or db call inside the build method and always make sure you dispose or close the open streams.</li> </ul> <ul> <li>Single Instance - all screens have access to bloc, there is one instance in the app</li> <li>Scoped Instance - only widget to which the bloc is exposed has access</li> </ul> <ul> <li>PublishSubject: Starts empty and only emits new elements to subscribers. There is a possibility that one or more items may be lost between the time the Subject is created and the observer subscribes to it because PublishSubject starts emitting elements immediately upon creation.</li> <li>BehaviorSubject: It needs an initial value and replays it or the latest element to new subscribers. As BehaviorSubject always emits the latest element, you can\u2019t create one without giving a default initial value. BehaviorSubject is helpful for depicting \"values over time\". For example, an event stream of birthdays is a Subject, but the stream of a person's age would be a BehaviorSubject.</li> </ul> <ul> <li>We pass the blocProvider to MaterialRoute and then it houses all the variables to be passed. This acts as inheritedWidget.</li> <li>MovieApp - Part 2</li> </ul> <p>The workflow of the Counter App:</p> <ul> <li>add packages</li> <li>create events as enum.</li> <li>create state - in this app, state is <code>int</code> so we don't create state class.</li> <li>create bloc to take events, map it, and return state,<ul> <li><code>class CounterBloc extends Bloc&lt;CounterEvent, int&gt; {...}</code></li> <li>here override init state</li> <li>and override mapEventsToState</li> </ul> </li> <li>instantiate bloc in main using <code>BlocProvider&lt;Bloc&gt;{}</code>.</li> <li>create Page, get bloc,</li> <li>get bloc, <code>final CounterBloc counterBloc = BlocProvider.of&lt;CounterBloc&gt;(context);</code></li> <li>body will be <code>BlocBuilder&lt;CounterBloc, int&gt;();</code> to build UI based on state.</li> <li>action event, <code>onPressed: () {counterBloc.add(CounterEvent.increment);}</code></li> <li>based on Flutter Counter App tutorial by @felangel.</li> </ul> <p>Redux:</p> <ul> <li>provides routing as well</li> <li>works with store reducer concept</li> </ul> <p>ScopedModel</p> <ul> <li>Updates only model in scope, not the whole widget tree</li> <li>Have to notifyListeners() on each state change</li> </ul> <p>Links:</p> <ul> <li>Flutter Architecture Samples to build ToDo apps</li> <li>The Essential Guide to UI Engineering</li> </ul>"},{"location":"0-Information-Technology/flutter/#firestore-and-flutter","title":"Firestore and Flutter","text":"<p>Connecting apps:</p> <ul> <li>iOS:<ul> <li>add GoogleService-Info.plist in xCode</li> <li>add reverseClientId in key CFBundleURLSchemes Runner/info.plist</li> </ul> </li> <li>android:<ul> <li>add google-services.josn and</li> <li>make sure applicationId is correct in app/build.gradle</li> </ul> </li> </ul> <p>Reading data (Flutter):</p> <ul> <li>Create a reference to instance of a collection, <code>userRef = Firestore.instance.collection('users')</code>.</li> <li>The above has functions to fetch records as snapshot of data</li> <li>It returns future which need to be handled.</li> <li>use StreamBuilder</li> <li>stream: Firestore.instance.collection('users').snapshots(),</li> <li>reference object accepts chain of functions like <code>where()..orderBy()..limit()</code> etc. for compound queries.</li> <li><code>FutureBuilder</code> - reads data in database</li> <li><code>StreamBuilder</code> - provides stream to data, shows new user added.</li> </ul> <p>NoSQL Structuting:</p> <ul> <li>do not nest collections</li> <li>keep data flatten</li> <li>copy data but mostly stored in the way it is best to be fetched.</li> </ul> <p>Create/Update/Delete data (Flutter):</p> <ul> <li>onTap: () =&gt; record.reference.updateData({'key': new_value})</li> <li>now its all linked from front to back</li> <li>all sync and updates offline and online.</li> <li>reference has function like <code>add()..updateData()..delete()</code>. They all return <code>&lt;Future&gt;</code>.</li> </ul> <p>Triggers:</p> <ul> <li>user firestore triggers to listen and act on the change in a collection.</li> <li>It uses node js to write and deploy the functions.</li> <li>Triggers can be created by using Trigger functions. Steps:<ul> <li><code>firebase login</code> - login to your google account to use CLI.</li> <li><code>firebase init fucntions</code> - create fucntions folder in flutter project.</li> <li><code>firebase deploy --only functions</code> - deploy functions to firebase cloud.</li> </ul> </li> </ul> <p>References:</p> <ul> <li>Felix Angelov - https://www.youtube.com/watch?v=knMvKPKBzGE</li> <li>Brian Egan - https://www.youtube.com/watch?v=Wfc5LMgWaRA</li> </ul>"},{"location":"0-Information-Technology/google-cloud-platform/","title":"Google Cloud Platform","text":"<p>Google Cloud Platform is cloud service from Google just like AWS and Azure. It provides SaaS, PaaS and IaaS.</p>"},{"location":"0-Information-Technology/google-cloud-platform/#gcp-services","title":"GCP Services","text":"<ul> <li>GCP Firebase as datastoage engine.</li> <li>GCP App Engine is PaaS for deploying web apps on cloud:<ul> <li>App Engine also helps us deploy dockers and containers</li> <li>hands on colab.</li> </ul> </li> <li>GCP Compute Engine provides VMs, which is like IaaS.</li> <li>GCP Cloud Machine Learning:<ul> <li>Offers pretrained models with biggest library.</li> <li>Cloud Vision API, Video Intelligence</li> <li>Identify ojects, landmarks, celebrities, colors, million other entities</li> <li>NLP API, Translations,  Text2Speech, Seech2Text API</li> <li>Auto ML trains on your data using expertise from already trained neurals</li> <li>Provides interface to train, evaluate and proof onjects on your own data.</li> <li>SaaS with latest TensorFlow, PyTorch and SKLearn on VMs with TPU and GPU support</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/google-cloud-platform/#gcp-compute-engine","title":"GCP Compute Engine","text":"<p>Google Compute Engine is a cloud service from GCP which offers Infrastructure as a Service. You can get a machine with configurations as required and it can be easily scaled.</p> <p>Example, start a Micro Machine <code>f1-micro</code>, with Ubuntu Server installed on  20gb HDD, in region 'us-central', and can allow traffic 'http and https'. This is also free for lifetime.</p>"},{"location":"0-Information-Technology/google-cloud-platform/#free-ubuntu-server-on-gce","title":"Free Ubuntu Server on GCE","text":"<p>Get an instance on GCE as per requirement or as in example above. We will configure it and add swap memory, then we will make it web server by installing Apache. We will also install MySQL database and PHP/Python as backend languages to serve web apps.</p>"},{"location":"0-Information-Technology/google-cloud-platform/#install-gcloud-on-mac","title":"Install gcloud on mac","text":"<ul> <li>Follow this guide.</li> <li>Install <code>gcloud</code> on workstation machine, mac, <code>wget &gt; tar -xf &gt; install.sh &gt; gcloud init</code></li> <li>Connect to the VM machine using ssh gcloud command, get it from the SSH dropdown on GCP console near VM.</li> <li>Command: <code>gcloud beta compute ssh --zone \"us-central1-a\" \"vm_name\" --project \"project_name\"</code> this adds to known hosts.</li> <li>This allows you to ssh to GCE host machine from your terminal on workstation.</li> </ul> <p>Congratualations, you have your own linux machine on cloud, free for lifetime and is scalable. It is time to get your hand dirty.</p>"},{"location":"0-Information-Technology/google-cloud-platform/#transferring-files","title":"Transferring files","text":"<ul> <li>You can transfer files using various options mentioned in this guide.</li> <li>we are using <code>gcloud</code> cli to transfer files between workstation and gce instance.</li> <li>Upload <code>gcloud compute scp local-file-path instance-name:dir-on-instance</code><ul> <li><code>instance-name</code> is name given during creation of instance</li> <li><code>dir-on-instance</code> is address where you need to copy, eg, <code>~</code></li> </ul> </li> <li>Download <code>gcloud compute scp --recurse instance-name:remote-dir local-dir</code></li> <li>to login to server using command <code>gcloud beta compute ssh --zone \"us-central1-a\" \"instance-name\" --project \"project-name\"</code>.</li> </ul>"},{"location":"0-Information-Technology/google-cloud-platform/#gcp-firebase","title":"GCP Firebase","text":"<p>Firebase is cloud based, app-backend service that is scalable and it helps in authentication, database, file storage, hosting, crashlytics, messeging, adMob, analytics, campaigns etc.</p> <p>It has following components:</p> <ul> <li>ML Kit<ul> <li>Has in build ML models for text analytics, image recongnition etc.</li> <li>Works on device or on cloud</li> <li>Can add Tensor flow functions/models to firebase functions and it will be hosted and serverd.</li> </ul> </li> </ul> <ul> <li>Firebase Authentication<ul> <li>Google, fb, twitter etc</li> <li>Account based</li> <li>Gives back user information, unique_id, name, photo,</li> <li>manages sessions</li> </ul> </li> </ul> <ul> <li>Cloud functions<ul> <li>responses to event, like welcome email on sign in</li> <li>triggers on database events</li> <li>modify files uploaded</li> <li>send cloud messaging messages to other users.</li> <li>build API from database</li> <li>All written in JS using node and then deployed using CLI</li> </ul> </li> </ul> <ul> <li>Firebase Hosting<ul> <li>Static files hosting</li> <li>on SSD, serves SSL,</li> <li>can host PWA</li> </ul> </li> </ul> <ul> <li>Firebase Storage<ul> <li>Store files, secure them, reliable.</li> </ul> </li> </ul> <ul> <li>Firebase Realtime Database<ul> <li>Store and sync data in realtime, even offline</li> <li>It is NoSql database.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/google-cloud-platform/#firestore-notes","title":"Firestore Notes","text":"<p>It is NoSQL database storage engine in firebase</p> <ul> <li>Works online and offline</li> <li>Stores data in collections</li> </ul> <p>Initialization:</p> <ul> <li>create database</li> <li>create table, called collection, users</li> <li>create rows, called document, doc_id</li> </ul> <p>More on Flutter notes.</p>"},{"location":"0-Information-Technology/google-cloud-platform/#app-script","title":"App Script","text":"<p>Create app script https://developers.google.com/apps-script/add-ons/translate-addon-sample</p>"},{"location":"0-Information-Technology/javascript-notes/","title":"JavaScript","text":""},{"location":"0-Information-Technology/javascript-notes/#node-js","title":"Node JS","text":"<p>Overview:</p> <ul> <li>node js is like asp/php/python, it makes use of JS for backend lang.</li> <li>you can run .js files outside browser</li> <li>npm is package manager for node js, like pip</li> <li>pakages are nothing but js libraries.</li> <li><code>npm install</code> downloads a package and it's dependencies defined in a <code>package.json</code> file and generates a node_modules folder with the installed modules.</li> </ul>"},{"location":"0-Information-Technology/javascript-notes/#angular-js","title":"Angular JS","text":"<p>Overview:</p> <ul> <li>We can define a resource in app folder eg: hero.ts to include the class with it's members.</li> <li>We can make components for various behaviors of our app. eg:<ul> <li>heroes - to list all heroes</li> <li>hero-detail - to keep functionality for one hero</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/javascript-notes/#typescript","title":"Typescript","text":"<p>It is superset of javascript, basically used to make use of new features of JS coming with ES6, ES7 and compile them back to old ES3 that can be used with IE and Safari as well.</p>"},{"location":"0-Information-Technology/javascript-notes/#javascript_1","title":"JavaScript","text":"<p>Functions can do whatever we want them to do.. :)</p> <p>How Functions behave:</p> <p>We can make a function in JS by defining it like we define a variable.</p> <pre><code>myFunction = function(arg1, arg2, arg3) {\n// all that you want to do\n// use args or may be they are optional\n//...\nreturn myResult;\n}\n</code></pre> <p>another way is, tree is a function and data is argument:</p> <pre><code>myFunction = arg1 =&gt; {\n// all that you want to do\n// use args or may be they are optional\n//...\nreturn myResult;\n}\n</code></pre> <p>now this function can return a variable which could possibly be any data/object/json etc.</p> <p>Function can now be used to get the result</p> <pre><code>myFunction(arg1, arg2).done( function (data) {\n// Now do what you want to do with result in data\n});\n</code></pre> <p>Now we see that, done would be triggered once myFunction is completed. All jQuery promises provide a done method that takes a callback.</p> <p>JS Objects Concept</p> <ul> <li>JS Object can hold anything, they can even hold another function.</li> <li>They are accessed using . DOT notation.</li> </ul>"},{"location":"0-Information-Technology/javascript-notes/#how-to-quickly-scrape-all-links-from-page","title":"How to quickly scrape all links from page","text":"<p>Use JS path to get all a tags you are interested in, do inspect, go to div having all a, then right click and copy <code>JS Path</code>. Then add path till <code>a</code> tag to this <code>div JS Path</code>. Now that you have JS Path to all the anchor tags, you can iterate over them and make a list then copy. You can execute this in console directly, eg:</p> <ul> <li>JS Path to div <code>#root &gt; div &gt; div.sc-AxjAm.tlQbp &gt; div &gt; main &gt; div &gt; div &gt; div</code></li> <li>JS Path to all a tags <code>article &gt; div:nth-child(2) &gt; div &gt; div:nth-child(5) &gt; a</code></li> <li>Join both together, then loop</li> </ul> <pre><code>links = '';\ndocument.querySelectorAll(\"#root &gt; div &gt; div.sc-AxjAm.tlQbp &gt; div &gt; main &gt; div &gt; div &gt; div &gt; article &gt; div:nth-child(2) &gt; div &gt; div:nth-child(5) &gt; a\").forEach(function (e) {links+=\"yourCmd \"+e.href+\" \\n\";})\ncopy(links)\n</code></pre> <p>This copies the output to clipboard. Related Posts:</p> <ul> <li>NativeScript Notes</li> <li>ECMA6 Notes</li> <li>React JS Notes</li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/","title":"Material for MkDocs","text":"<p>all about MkDocs and Material theme</p>"},{"location":"0-Information-Technology/material-mkdocs/#mkdocs","title":"MkDocs","text":"<p>MkDocs is static site generator, more like <code>Pelican</code>. From markdown files, it can build static site.</p> <p>Static site can be deployed on Github Pages and builds can be automated using Github Actions.</p> <p>So one repo has your source markdown files and another repo has static site which is build and deployed using github actions.</p>"},{"location":"0-Information-Technology/material-mkdocs/#basics","title":"Basics","text":"<ul> <li><code>mkdocks.yml</code><ul> <li><code>site_name</code> and <code>site_url</code> are bare minimum to specify.</li> <li>new docs are auto picked and added to navs. If you specify pages in nav, you will have to do for all the pages you add, any new ones too..</li> </ul> </li> </ul> <ul> <li><code>mkdocs serve</code> live preview server on dev+</li> <li><code>mkdocs build</code> to create <code>site</code> folder</li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/#deployment","title":"Deployment","text":"<ul> <li><code>mkdocs gh-deploy</code> to deploy to github<ul> <li>creates <code>gh-pages</code> branch on local and adds site to it.</li> <li>pushes this branch to remote as default.</li> </ul> </li> </ul> <ul> <li>Issues<ul> <li>pushes static site, needs build. Can be resolved with GitHub actions.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/#github-actions","title":"Github Actions","text":"<ul> <li>GitHub Actions is yet another free option from GitHub, which is basically a build server in the cloud</li> <li>have a build server automatically pick up changes in Markdown source files and build the static website directly on the build server.</li> <li>More on git page</li> </ul> <ul> <li>Links<ul> <li>https://blog.elmah.io/deploying-a-mkdocs-documentation-site-with-github-actions/</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/#material-theme","title":"Material Theme","text":"<ul> <li>Requirements<ul> <li><code>pip install mkdocs-material</code></li> <li><code>pip install mkdocs-git-revision-date-localized-plugin</code></li> </ul> </li> </ul> <ul> <li> <p>add following to config file</p> <pre><code>theme:\nname: material\n</code></pre> </li> </ul> <ul> <li>For Good Looks<ul> <li>Keep <code>title: Two-Three words</code></li> <li>Can have H1-H5 as proper english sentences, keep small to a few words.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/#markdown-extensions","title":"MarkDown Extensions","text":"<p>Markdown is rendered in MkDocs using Python-Markdown. This supports basic markdown with some strict formats. It can be extended using Python Markdown Extensions and PyMdown Extensions.</p> <p>Extensions might need to be installed and added to configuration file.</p>"},{"location":"0-Information-Technology/material-mkdocs/#list-intent","title":"List Intent","text":"<p>Default is to keep 4 spaces for list intent. Extension <code>mdx_truly_sane_lists</code> allows to use 2 spaces.</p>"},{"location":"0-Information-Technology/material-mkdocs/#admonitions","title":"Admonitions","text":"Collapsible <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> Collapsible Open <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>More: https://squidfunk.github.io/mkdocs-material/reference/admonitions/#collapsible-blocks</p>"},{"location":"0-Information-Technology/material-mkdocs/#code-blocks","title":"Code Blocks","text":"<p>Inline <code>code</code> and block.</p> Code Title: bubble_sort.py<pre><code>def bubble_sort(items):\nfor i in range(len(items)):\nfor j in range(len(items) - 1 - i):\nif items[j] &gt; items[j + 1]:\nitems[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> <p>More: https://squidfunk.github.io/mkdocs-material/reference/code-blocks/</p>"},{"location":"0-Information-Technology/material-mkdocs/#content-tabs","title":"Content Tabs","text":"CC++ <pre><code>#include &lt;stdio.h&gt;\nint main(void) {\nprintf(\"Hello world!\\n\");\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nint main(void) {\nstd::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\nreturn 0;\n}\n</code></pre> <p>More: https://squidfunk.github.io/mkdocs-material/reference/content-tabs/</p>"},{"location":"0-Information-Technology/material-mkdocs/#diagrams-mermaid","title":"Diagrams Mermaid","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre> <ul> <li>Links<ul> <li>Mermaid JS - Flowchart 101</li> <li>MKDocs Diagrams</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/#mathjax","title":"MathJax","text":"<p>Inline \\(\\alpha\\) math.</p> \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] <p>More: https://squidfunk.github.io/mkdocs-material/reference/mathjax/</p>"},{"location":"0-Information-Technology/material-mkdocs/#lists-as-tasks","title":"Lists as Tasks","text":"<ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul> <p>More: https://squidfunk.github.io/mkdocs-material/reference/lists/</p>"},{"location":"0-Information-Technology/material-mkdocs/#third-party-tweaks","title":"Third Party Tweaks","text":"<p>Modify theme and interact with core Python Plugins</p>"},{"location":"0-Information-Technology/material-mkdocs/#last-10-updated-pages","title":"Last 10 updated pages","text":"<p>Link https://timvink.github.io/mkdocs-git-revision-date-localized-plugin/howto/override-a-theme/#example-list-last-updated-pages</p>"},{"location":"0-Information-Technology/material-mkdocs/#iyv-wiki-specifics","title":"iYV Wiki Specifics","text":"<p>Decisions</p> <ul> <li>Don't need tabs</li> <li>need sidebar sections</li> <li>need blog</li> </ul> <p>Example repo wiki - https://github.com/barnumbirr/wiki</p> <p>view all page items</p> <pre><code># all page items\n{% for key,value in page.__dict__.items() %}\n{{ key,value }}\n{% endfor %}\n{% for key,value in page.meta.items() %}\n{{ key,value }}\n{% endfor %}\n</code></pre>"},{"location":"0-Information-Technology/material-mkdocs/#markdown-101-rules","title":"Markdown 101 - Rules","text":"<p>Based on a year of work, following structure has emerged and has worked in arranging notes all around, for work logs, meetings and knowledge base. make a <code>~/notes</code> folder, which should be a GIT repo and can have following files:</p> <ul> <li>Project Specific - markdown file <code>project_name.md</code> - H1s<ul> <li><code># Understanding</code> - add notes as you gain understanding of process etc. Can have all sort of h2, h3 etc.</li> <li><code># Work Log</code> - add dated work that you do, or steps you follow, kind of rough log. <code>## 22-11 - tu - adding exception handling</code></li> <li><code># Meeting Log</code> - add dated meeting rough notes. <code>## 23-04 - mo - Show and tell with James</code></li> </ul> </li> <li>Meetings markdown - <code>meetings.md</code> -  a file to have all meeting that you do - H1s<ul> <li><code># People Log</code> - this can have <code>## John Doe</code> which can have log of conversation, facts, or actions with a person.<ul> <li><code>## Others</code> - log of people you interact less.</li> </ul> </li> <li><code>Meeting Log</code> - logs of meeting, can have actions [ ] with date to be completed on. <code>## 12-03 - tu - Sales Pitch Overview</code></li> </ul> </li> <li>Daily Logs markdown - <code>daily_log.md</code> - H1s<ul> <li><code># ToDo - Backlog - Minddump</code> has any thing that comes to ming, todos, actions to be taken, read later etc.</li> <li><code># Daily Log - 2022</code> - followed by week numbers - latest at top<ul> <li><code>## Week 48</code> -  followed by daily log of work.<ul> <li><code>28-11 - mo</code> probably add hourly burns</li> <li><code>week review</code> - reflect how your week went, goods and bads, what can be improved, what gave you appreciation. Are you aligning to a wider goal?</li> </ul> </li> </ul> </li> </ul> </li> <li>Notepad - <code>notepad.md</code> the huge notepad where you build your knowledge base, H1s<ul> <li><code># Team DNA - Business &amp; Vision</code> - knowlege base specific to your team, unit. Add business understanding, projects, team hierarchy, team's vision.</li> <li><code># ABC Inc - Business &amp; Vision</code> - build knowledge base aroung your company, what it does, entities, relations, public info, customers, products, business processes.</li> <li><code># Tools/Links/Processes</code> - this has info of all tools, portals, how tos, third parties, databases. All specific to your company.</li> <li>Notes in general - add H1s to have generic notes that are around a technology, but not specific to company. These can later go to your personal knowlege base e.g.<ul> <li><code># Python</code> - all things you learn in python</li> <li><code># Git</code> - all knowlege you gain in git</li> </ul> </li> </ul> </li> </ul> <ul> <li>Writing Rules and basics<ul> <li>Add date where possible.</li> <li> to have todo actions. can be searched.</li> <li> to have action done. - resolution.<ul> <li>or resolution in next line, tabbed like this.</li> </ul> </li> <li>avoid adding h3, h4 to rough notes.</li> </ul> </li> </ul> <ul> <li>How to arrange notes for easy add on and updates and follow ups<ul> <li>Notes should have section of action 'what you want to do'. Eg, create, install, read, write etc.</li> <li>So when you learn something new about an action, you know the section to add to. Similarly, when you have to do an action, you know what to refer to.</li> <li>Keep knowledge at one place, like sqlite to be on its page and other pages can refer to it. Do not repeat on separate pages.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/material-mkdocs/#links","title":"Links","text":"<ul> <li>Furo - theme</li> </ul>"},{"location":"0-Information-Technology/nativescript-notes/","title":"NativeScript","text":"<p>NativeScript ( or tns Telerik NativeScript) is used to make native iOS and Android apps using Angular/TypeScript or JavaScript.</p>"},{"location":"0-Information-Technology/nativescript-notes/#setting-up-the-environment","title":"Setting up the environment","text":"<p>Required:</p> <ul> <li>node</li> <li>nativescript cli</li> <li>native script cli uses npm</li> </ul> <p>Installation:</p> <ul> <li>do npm install script and then add package</li> </ul> <ul> <li><code>$ sudo npm install nativescript -g</code> to install globally</li> <li><code>nativescript --version</code> to confirm installation</li> <li>tns is alias to nativescript</li> </ul> <p>iOS prerequisites</p> <ul> <li>Xcode</li> <li>Xcode CLT</li> </ul> <p>NS CLI</p> <ul> <li>component</li> <li>module</li> <li>html</li> </ul>"},{"location":"0-Information-Technology/nativescript-notes/#application-architecture","title":"Application Architecture","text":"<p>How the appication is architectured.</p>"},{"location":"0-Information-Technology/nativescript-notes/#javascript","title":"JavaScript","text":"<ul> <li>app.ts is the entry point of application. We can do app level initialization here. But this is basically used to pass control to first module.</li> <li>we can have app.css to keep our global css rules.</li> <li>A folder for each module/view<ul> <li>eg: home</li> </ul> </li> <li>home folder can have three files.<ul> <li>home-page.xml having xml for UI</li> <li>home-page.ts code behind file for xml above. Can call functions</li> <li>home-view-model.ts having data, binding and other logics.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/nativescript-notes/#angular-script","title":"Angular Script","text":"<p>for each module we need:</p> <ul> <li>home.component.html it has all html ui defined</li> <li>home.component.css has css rules related to this module</li> <li>home.component.ts has code behind the html ui</li> <li>home.module.ts imports everything to one place</li> <li>home-routing.module.ts routing for module ui</li> </ul> <p>Component is building block of all angular nativescript</p> <ul> <li>Component defines UI elem and screens</li> <li>root - app.component</li> <li>child - pt_backlog</li> <li>backlog module</li> </ul> <p>Modules</p> <ul> <li>use one module per file as an ES15 standard</li> </ul>"},{"location":"0-Information-Technology/nativescript-notes/#notes","title":"Notes","text":"<ul> <li>Every UI element should be inside a layout, else only last UI element takes whole screen.</li> <li>Making Angular Groceries App<ul> <li>All UI elements come in stack layout in app.component.ts and add their css to css files</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/nativescript-notes/#uninstaslling","title":"Uninstaslling","text":"<ul> <li><code>$ sudo npm uninstall nativescript -g</code> to uninstall globally</li> </ul> <p>References:</p> <ul> <li>Refer: https://docs.nativescript.org/angular/start/tutorial/ng-chapter-1#11-what-youre-building</li> </ul>"},{"location":"0-Information-Technology/pelican/","title":"Pelican","text":"<p>Pelican is a static site generator in Python.</p>"},{"location":"0-Information-Technology/pelican/#quickstart","title":"Quickstart","text":"<ul> <li>make a dir</li> <li>create virtual env <code>python3 -m venv venv</code></li> <li>upgrade pip <code>./venv/bin/pip install --upgrade pip</code></li> <li>activate env <code>source venv/bin/activate</code></li> <li>install pelican <code>pip install pelican</code></li> <li>create basic files and dir <code>pelican-quickstart</code></li> <li>start server <code>make devserver</code> go to <code>http://localhost:8000/</code></li> <li>It builds the <code>output</code> dir</li> </ul>"},{"location":"0-Information-Technology/pelican/#structure","title":"Structure","text":"<ul> <li><code>content</code> holds all contents,<ul> <li>articles can be created as <code>.md .html or .rst</code></li> <li><code>content/pages</code> dir can have pages</li> <li><code>content/downloads</code> can serve static content for pages</li> <li><code>{static}/downloads/logo.jpg</code> copies file to output and links to path</li> <li>Samples can be found on docs and eg site</li> </ul> </li> </ul> <ul> <li><code>output</code> has all the static pages built using content and theme.</li> </ul>"},{"location":"0-Information-Technology/pelican/#adding-theme","title":"Adding Theme","text":"<ul> <li>Make a themes dir anywhere</li> <li>add this dir to <code>pelicanconf.py</code> as <code>THEME = 'themes_dir/my_theme</code></li> <li><code>my_theme</code> should have two folders<ul> <li><code>static</code> all your css, js and images can go here, copied as-is to output</li> <li><code>templates</code> templates for various mandatory pages<ul> <li><code>base.html</code> starting point, links <code>href=\"{{ SITEURL }}/theme/css/my.css\"&gt;</code></li> <li><code>page.html</code> imports base and adds content for pages</li> <li><code>index.html</code> lists all blog articles</li> <li>other pages are mandatory like article, author, tag etc can be copied from here.</li> </ul> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/pelican/#dev-sprints","title":"Dev Sprints","text":"<ul> <li>Go to folder</li> <li>activate env <code>source venv/bin/activate</code></li> <li>start server <code>make devserver</code> go to <code>http://localhost:8000/</code></li> <li>this will launch the site and will autoupdate site on page modifications.</li> </ul>"},{"location":"0-Information-Technology/pelican/#production-push","title":"Production Push","text":"<ul> <li>Delete the output dir</li> <li>run <code>make devserver</code> go to <code>http://localhost:8000/</code> verify all changes</li> <li>then make an archive of <code>output</code> folder and upload to your host.</li> <li>for GCP please follow steps here.</li> </ul>"},{"location":"0-Information-Technology/pelican/#tips-and-tricks","title":"Tips and Tricks","text":"<ul> <li>to replace blog index page, add following metas to any new <code>homepage.html</code></li> </ul> <pre><code>  &lt;meta name=\"save_as\" content=\"index.html\" /&gt;\n&lt;meta name=\"url\" content=\"index.html\" /&gt;\n</code></pre> <ul> <li>sorting menu items<ul> <li>in <code>pelicanconf.py</code> add <code>PAGE_ORDER_BY = 'reversed-date'</code></li> <li>then in pages meta add <code>&lt;meta name=\"date\" content=\"2020-07-26 07:00\" /&gt;</code></li> <li>you can then change time to sort pages in menu bar.</li> </ul> </li> </ul> <p>Minimum html required for pages:</p> <pre><code>&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;My super title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n        This is the content of my super blog post.\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>To do:</p> <ul> <li>exclude some pages from menu</li> <li>add articles</li> </ul>"},{"location":"0-Information-Technology/python-notes/","title":"Python","text":"<p>all learnings here, keep one file for easier updates</p>"},{"location":"0-Information-Technology/python-notes/#python-interpreters","title":"Python Interpreters","text":"<ul> <li>there may be many python version and interpreter installed on your machine. eg, <code>/bin/python3</code> or <code>~/anaconda/bin/python</code></li> <li>identify current the default, <code>which python</code></li> <li>find all installed binaries, <code>locate \"bin/python\"</code> - this lists all the binaries including venvs.</li> <li>to set anaconda python as default python, add following to <code>~/.bashrc</code><ul> <li><code>export PATH=\"/home/username/anaconda3/bin:$PATH\"</code></li> <li>then restart terminal or do <code>source ~/.bashrc</code></li> <li>check with <code>which python</code>, should be using anaconda.</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/python-notes/#virtual-environments","title":"Virtual Environments","text":"<ul> <li>Why use virtual environment - It gives different apps isolation and personal environment so that modules don't interfere and it is easy when we have to productionize the app.</li> </ul> <ul> <li>What is Python Virtual Environment  <ul> <li>Basically a folder having python core binaries and use this new installation to install libraries that will be specific to this installation (or environment).</li> <li>It is an isolated environment</li> <li>When you activate a virtual environment, your PATH variable is changed. The Scripts directory of <code>venv_app</code> is put in front of everything else, effectively overriding all the system-wide Python software.</li> </ul> </li> </ul> <ul> <li>Create<ul> <li><code>python -m venv venv_app</code> - creates folder venv_app</li> </ul> </li> </ul> <ul> <li>Usage<ul> <li><code>source venv_app/bin/activate</code> - activates this environment</li> <li><code>&gt;venv_app\\Scripts\\activate</code> in Windows</li> <li>check using <code>python -V</code> or <code>which python</code></li> <li>now do <code>python -m pip install &lt;package-name&gt;</code> - this installs the package only in this environment.</li> <li>add <code>#!venv_app/bin/python</code> on top of main.py file to make it use this python.</li> <li>python or python3 depends on your installation.</li> </ul> </li> </ul> <ul> <li>Deactivate<ul> <li><code>deactivate</code> to deactivate the current env.</li> </ul> </li> </ul> <ul> <li>View &amp; Share<ul> <li><code>python -m pip list</code> to see installed libs.</li> <li><code>python3 -m pip freeze</code> to share libs.<ul> <li><code>python3 -m pip freeze &gt; requiremeents.txt</code> to make a file.</li> <li><code>python3 -m pip install -r requirements.txt</code> to install all libs from file</li> </ul> </li> </ul> </li> </ul> <ul> <li>Delete<ul> <li><code>rm -r venv_app</code> delete</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/python-notes/#offline-virtual-environment-setup","title":"Offline Virtual Environment Setup","text":"<ul> <li>On machine with internet<ul> <li><code>pip download -r requirements.txt -d path/pip-packages</code> downloads requirements and its dependencies to a folder <code>path/pip-packages</code></li> </ul> </li> </ul> <ul> <li>On machine without internet</li> <li><code>python -m venv venv</code> create virtual environment</li> <li><code>venv\\Scripts\\activate</code> activate environment</li> <li><code>pip install -r requirements.txt --find-links=pip-packages --no-index</code> install requirements<ul> <li><code>--no-index</code> tells to not use any repository like pypi</li> <li><code>--find-links</code> tells a path to find all packages</li> </ul> </li> <li><code>flask --app app:create_app('testing') run</code></li> </ul> <ul> <li>Links<ul> <li>Stackoverflow answer</li> <li>PIP Docs - pip install</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/python-notes/#conda-miniconda-anaconda","title":"Conda Miniconda Anaconda","text":"<p>Conda is package and virtual environment manager, like pip, for any language\u2014Python, R, Ruby and more. It is a CLI and can</p> <ul> <li>install packages like flask, jupyter, pandas etc.</li> <li>can manage envs, virtual environment is separate python and its packages. This means each project you work on can have its own set of packages.</li> </ul> <p>Anaconda is toolkit for Data Science. Along with conda it includes ds and ml libraries (500Mb) installed.</p> <p>Anaconda Navigator is GUI to use conda.</p> <p>Miniconda includes conda and python but not much libraries.</p> <p>So we can use conda alone to create a development virtual environment for new data science project or use miniconda.</p> <p>Installing Conda on Linux</p> <ul> <li><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</code></li> <li><code>bash Miniconda3-latest-Linux-x86_64.sh</code> this installs python, conda, vevn and others, all in virtual environment.</li> <li>After installation, restart terminal, and it will load new environmnet called 'base'. Now python is not the default system python.<ul> <li>If you'd prefer that conda's base environment not be activated on startup, set the auto_activate_base parameter to false: <code>conda config --set auto_activate_base false</code></li> <li>more: https://www.projectdatascience.com/step-by-step-guide-to-setting-up-a-professional-data-science-environment-on-a-linux/</li> </ul> </li> </ul> <p>Quick Start using Conda for a new project</p> <pre><code>conda deactivate\nmkdir prj1\ncd prj1\nconda create -n prj1env pandas numpy jupyter scikit-learn matplotlib seaborn\nconda activate prj1env\ntouch README.md\ncode .\n</code></pre> <p>Run <code>conda activate prj1env</code> in code shell.</p> <p>Undo <code>conda deactivate &amp;&amp; conda remove --name prj1env --all</code> and remove files if any.</p> <p>Conda Basic Commands</p> <ul> <li><code>conda update conda</code> updates conda</li> <li><code>conda install PACKAGENAME</code> installs pkg to default/active env</li> <li><code>conda update PACKAGENAME</code> updated pkg</li> <li><code>pip install pkg</code> aslo intalls to active env</li> </ul> <p>Conda Env Commands</p> <ul> <li><code>conda create --name py35 python=3.5</code> created new env called 'py35' and installs py 3.5</li> <li><code>conda activate py35</code> activates</li> <li><code>conda list</code> lists all packages installed in active env.</li> <li><code>conda remove --name my-env --all</code> deletes the env.</li> </ul>"},{"location":"0-Information-Technology/python-notes/#python-programming","title":"Python Programming","text":"<p>Decorators are a standard feature of the Python language. A common use of decorators is to register functions as handler functions to be invoked when certain events occur.</p> <ul> <li>Global Local Variables and its scope<ul> <li>If you use a var with same name in function (local) and module (global) then you need to take caution</li> <li>when you assign a var in function, python create that local var irrespective of it being present in global context. To use the global var in function:</li> <li>either pass as param, or</li> <li>you can use <code>global</code> keyword before var to let python interpreter know to use global var and not redeclare it.</li> <li>more on this on StackOverflow - UnboundLocalError: local variable referenced before assignment</li> </ul> </li> </ul> <ul> <li>Packages &amp; Modules<ul> <li><code>Package</code> is usually a folder with <code>__init__.py</code> in it.</li> <li>Other python files are <code>modules</code>.</li> </ul> </li> </ul> <ul> <li>Public, Private, Protected in python<ul> <li>public - every member of class in python is public by defaut, can be accessed outside class using object.</li> <li>protected attribute needs to be prefixed with underscore, <code>_name</code>. It can be accessed, just a convension.</li> <li>private members can be <code>__name</code> prefixed with double underscore, this makes them non accessible outside \"directly\". though can be accessed using <code>_Classname__attrname</code></li> <li>Python provides conceptual implementation but not exactly like java or C++. As the underscores tell what is protected and private but does not make them non accessible.</li> <li> <p>To implement a \"write-only\" attribute use \"property\"</p> <ul> <li>getter - use <code>@property</code> decorator with function, <code>def pvt_prop_name(self):</code> raise err in this func so no one can get this property.</li> <li>setter - use <code>@pvt_prop_name.setter</code> with function <code>def pvt_prop_name(self, value):</code> to implement setting some values. You can set value to another public property. Thus this makes <code>pvt_prop_name</code> as write-only.</li> </ul> <pre><code>class Book():\nscrambled = None # public, can be get or set\n__safe = None    # pvt, can't be directly get or set\n@property\ndef secret(self):\nraise AttributeError()\n@secret.setter\ndef secret(self,value):\nself.scrambled = value[::-1]\n# `secret` is write_only member\n</code></pre> </li> </ul> </li> </ul>"},{"location":"0-Information-Technology/python-notes/#exception-handling-with-try-except-else-and-finally","title":"Exception handling with try, except, else, and finally","text":"<p>Try: This block will test the excepted error to occur Except:  Here you can handle the error Else: If there is no exception then this block will be executed Finally: Finally block always gets executed either exception is generated or not</p>"},{"location":"0-Information-Technology/python-notes/#files-handling-in-python","title":"Files Handling in python","text":"<p><code>f  = open(filename, mode)</code> Where the following mode is supported:</p> <ul> <li>r: open an existing file for a read operation.</li> <li>w: open an existing file for a write operation. If the file already contains some data then it will be overridden but if the file is not present then it creates the file as well.</li> <li>a:  open an existing file for append operation. It won\u2019t override existing data. creates if not exists.</li> <li>r+:  To read and write data into the file. The previous data in the file will be overridden.</li> <li>w+: To write and read data. It will override existing data.</li> <li>a+: To append and read data from the file. It won\u2019t override existing data.</li> </ul> <pre><code>## read\nfile_handle = open('notes/abc.txt', 'r')\ncontent = file_handle.read()\nfile_handle.close()\n## write\nfile = open('note.txt','a')\nfile.write(\"quick brown\")\nfile.write(\"munde, not fox\")\nfile.close()\n</code></pre> <ul> <li>non recursive replace<code>[os.rename(f, f.replace('_', '-')) for f in os.listdir('.') if not f.startswith('.')]</code></li> </ul> Replace '_' with '-' in filenames recursively<pre><code>directory = '.'\nfor subdir, dirs, files in os.walk(directory):\nfor filename in files: # !! use dirs instead of files to rename dirs first\nnew_filename = filename.replace('_','-')\nsubdirectory_path = os.path.relpath(subdir, directory) #get the path to your subdirectory\nfile_path = os.path.join(subdirectory_path, filename) #get the path to your file\nnew_file_path = os.path.join(subdirectory_path, new_filename) #create the new name\n# os.rename(file_path, new_file_path) #rename your file\nprint(file_path, new_file_path) #rename your file\n</code></pre>"},{"location":"0-Information-Technology/python-notes/#logging-in-python","title":"Logging in Python","text":"<ul> <li>Logging is done to keep record of events of software. They can be logged to console or a file or emailed.</li> <li><code>level</code> is set to filter logs, default is <code>warning</code> so anything below it is not logged.</li> <li><code>basicConfig()</code> set in one module works for all modules used in a session. You can pass<ul> <li><code>level</code> to filter</li> <li><code>filename</code> to save logs</li> <li><code>format</code> - what to log, it can have, log level, message, time, location etc.<ul> <li>all format strings here</li> </ul> </li> <li><code>datefmt</code> to set date format of <code>asctime</code></li> </ul> </li> </ul> <ul> <li>When to use What<ul> <li><code>print()</code> is good for small script to display on console. Else use logging.</li> <li><code>raise exception</code> when run time error occurs, that need to stop software.</li> <li><code>logging.exception() or logging.error() or logging.critical()</code> when error is to be logged and application can continue</li> <li> <p>Following table show when to use which level of logging</p> Level When it is used DEBUG detailed info, typically for problem analysis INFO confirmation that event is working as expected WARNING default. unexpected behaviour, but system will work. Eg, low space ERROR serious problem, that software has not performed an action CRITICAL serious error that may bring system down </li> </ul> </li> </ul> <ul> <li>Advanced<ul> <li>loggers, handlers, filters, and formatters are components that can be used to have control on the functionality.</li> <li>more here on PythonDocs - Advanced Logging</li> <li>Configuring Logging - configs can be in code, in file or in dictionary.</li> </ul> </li> </ul> <pre><code>import logging\n## Very Basic\nlogging.warning('Watch out!')  # will print a message to the console\nlogging.info('I told you so')  # will not print anything as it is below default level\n## To a file\nlogging.basicConfig(filename='example.log',level=logging.DEBUG)\nlogging.debug('This message should go to the log file')\n# DEBUG:root:This message should go to the log file\n## Formatting\nlogging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %I:%M:%S %p')\nlogging.debug('Something is happenning')\n# 02/16/2023 01:50:17 PM - root - DEBUG - Something is happenning\n## New filename for each run\nimport os, time\nfrom time import localtime\nbasedir = os.path.abspath(os.path.dirname(__file__))\nlog_dir = os.path.join(basedir, 'logs')\nparent_process_id=os.getppid()\nprocess_id=os.getpid()\nlog_time=time.strftime('%Y%m%d_%H%M', localtime())\nlog_filename=str(log_time)+'_app_'+str(parent_process_id)+'_'+str(process_id)+'.log'\nLOG_FILE_PATH = os.path.join(log_dir, log_filename)\nlogging.basicConfig(level=logging.DEBUG, \\\n                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \\\n                    datefmt='%Y/%m/%d %H:%M:%S %p', \\\n                    filename=LOG_FILE_PATH, \\\n                    filemode='w')\nlogging.info(\"New Working directory is: \" + str(os.getcwd()))\n## Using Components\nimport logging\nlogger = logging.getLogger()\nfhandler = logging.FileHandler(filename='mylog.log', mode='a')\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nfhandler.setFormatter(formatter)\nlogger.addHandler(fhandler)\nlogger.setLevel(logging.DEBUG)\nlogging.error('hello!')\nlogging.debug('This is a debug message')\nlogging.info('this is an info message')\nlogging.warning('tbllalfhldfhd, warning.')\n## 2015-01-28 09:49:25,026 - root - ERROR - hello!\n## 2015-01-28 09:49:25,028 - root - DEBUG - This is a debug message\n## 2015-01-28 09:49:25,029 - root - INFO - this is an info message\n## 2015-01-28 09:49:25,032 - root - WARNING - tbllalfhldfhd, warning.\n</code></pre> <p>Links</p> <ul> <li> RealPython - Logging in Python</li> <li>PythonDocs - When to use what level</li> <li>TD.io - logging in python</li> </ul>"},{"location":"0-Information-Technology/python-notes/#datetime-and-time-in-python","title":"Datetime and Time in Python","text":"<ul> <li><code>datetime</code> and <code>time</code> are separate modules.</li> <li><code>datetime</code> has most methods to work with date and time, some sub modules are<ul> <li><code>datetime.datetime</code> has both date and time handling methods, mostly used, <code>from datetime import datetime as dt</code><ul> <li><code>dt.now()</code> =&gt; datetime.datetime(2022, 10, 20, 8, 14, 44, 277307)</li> </ul> </li> <li><code>datetime.date</code> date specific methods</li> <li><code>datetime.time</code> time specific methods</li> </ul> </li> <li><code>time</code> module has <code>sleep()</code> function to pause program execution</li> </ul> <pre><code>import time\ntime.time() # timestamp\ntime.sleep(2) # sleeps for two seconds\n</code></pre> <pre><code>from datetime import datetime as dt\nstart = dt.now() # datetime.datetime(2022, 10, 20, 8, 14, 44, 277307)\ndt.now().ctime() # Thu Oct 20 08:16:51 2022\nend = dt.now()\nend - start # datetime.timedelta(seconds=11, microseconds=129035)\ndelta = (end - start).seconds # 11\n</code></pre>"},{"location":"0-Information-Technology/python-notes/#testing-in-python","title":"Testing in Python","text":"<p>Manual testing is done to check if all functionalities are performed as expected.</p> <p>Now if you change the code you have to check all the functionalities again. To avoid this, you can do Automated Testing.</p> <p>There is <code>test step</code> and <code>test assertion</code>. Eg, step is that button will turn on light, to see that the light is on is assertion.</p> <p>An integration test checks that components in your application operate with each other. Eg, switch turns on light.</p> <p>A unit test checks a small component in your application. Eg, switch, battery, wire, bulb etc.</p> <p>You can check a output against a <code>known output</code></p> <p><code>assert</code> keywork is used to check a logical statement. In case of False, error is raised.</p> <pre><code>def test_sum():\nassert sum([1, 2, 3]) == 6, \"Should be 6\"\n</code></pre> <p><code>AssertionError</code> is raised in case of failure, else nothing.</p> <p><code>unittest</code> is a test runner, based on JUnit from java. It requires that:</p> <ul> <li>You put your tests into classes as methods</li> <li>:TODO https://realpython.com/python-testing/</li> </ul>"},{"location":"0-Information-Technology/python-notes/#documenting-code-in-python","title":"Documenting Code in Python","text":"<ul> <li>Why - when you revisit after months, it saves time to pick back<ul> <li>when it is public or team work, it helps others contribute</li> </ul> </li> </ul> <ul> <li>Documenting is making it understandable to users, like react-docs</li> <li>Commenting is for developers, to understand why code is written. It can be to understand, reasons, description or<ul> <li>Tagging, <code># todo: some work</code>, <code># bug: fix the bug</code>, <code># FIXME: some fix</code>.</li> </ul> </li> </ul> <ul> <li>Docstrings - these are structured string format. They can be parsed by parser like Sphinx, and can autogenerate documentation from code.<ul> <li>everything in Python is an object. And that object has a property <code>__doc__</code> that stores the docstring that can be printed when using help.</li> <li>you can set this as <code>my_func.__doc__ = \"Some string\"</code></li> <li>or the next line after function in <code>\"\"\"Some string\"\"\"</code> automatically sets the docstring for the function.</li> <li>docstring structures are of three types<ul> <li>Google - google's way (mostly used)</li> <li>reStructured - python style</li> <li>em - same as done in java</li> </ul> </li> </ul> </li> </ul> <ul> <li>Sphinx lets you write documentation using markdown and can auto-generate documentation from docstrings.<ul> <li>Installation - <code>pip install sphinx</code></li> <li>Initialization<ul> <li>In the project root folder, <code>my_project/</code></li> <li><code>sphinx-quickstart docs</code>, creates docs dir <code>my_project/docs</code></li> </ul> </li> <li>Configuration</li> <li>Build - <code>sphinx-build -b html docs/source/ docs/build/html</code></li> </ul> </li> </ul> <ul> <li>Links<ul> <li>TD.io using Sphinx</li> <li>PythonHosted.ORG - Examples</li> <li>RealPython - Doc Guide</li> <li>Sphinx Google Example</li> <li>Shinx Autogen from docstring</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/python-notes/#concurrency-and-parallelism-in-python","title":"Concurrency and Parallelism in Python","text":"<ul> <li>wait is when you have I/O or N/W or processing operation.</li> <li>you can at same time do other things while you wait, concurrency</li> <li>you can also do things simultaneously, parallelism</li> <li>Thread lets break a program into small pieces that execute separately. You can create multiple threads in a program, they all start one after other (not in parallel). This can be faster compared non-thread execution because when a thread waits another starts execution. Hence, it enables continuous execution.</li> <li>Python has slightly different approach for parallelism, because <code>threading</code> module lets create thread but can't execute in parallel, <code>multiprocessing</code> module is similar and enables parallel execution.</li> </ul> <ul> <li>Asyncio is another better way to do tasks concurrently. It lets you perform tasks in non-blocking way using <code>async</code> / <code>await</code> syntax.<ul> <li>Non-blocking means other tasks can exucute while a task is waiting. Synchronous operations suffer to wait and execute in sync.</li> <li><code>aiohttp</code> for non-blocking requests, <code>aiofiles</code> for non- blocking file operations. <code>asyncio</code> is python standard library.</li> </ul> </li> </ul> <ul> <li>Parallelism<ul> <li>it can be done using <code>multiprocessing</code> or <code>concurrent.futures</code> library.</li> <li>it lets distribute compute over multiple processors.</li> </ul> </li> </ul> <ul> <li>CRUX<ul> <li>Threading enable concurrency, execute tasks independently without wait</li> <li>Multiprocessing enables parallelism, execute with more compute power</li> <li>Asyncio enables asynchronous execution, let long running task be handled in a nice way.</li> </ul> </li> </ul> <ul> <li>When to use Multiprocessing or AsyncIO or Threading<ul> <li>When doing compute heavy task use multiprocessing. Eg, heavy math operation, string comparision.</li> <li>Use asyncio or threading when using network, like request response read write.</li> <li>Use both multiprocessing and asyncio tohether when using doing both high compute and n/w task. But, good rule of thumb is to fork a process before you thread(use) asyncio.</li> <li>threads are cheap compared to processes.</li> </ul> </li> </ul> <ul> <li>Link<ul> <li>Tstdriven.io - Concurrency  Parallelism AsyncIO</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/python-notes/#snippets-python","title":"Snippets Python","text":"<p>Taking input - <code>msg = str(input(\"Message? : \"))</code></p>"},{"location":"0-Information-Technology/python-notes/#web-scraping-selenium","title":"Web Scraping - Selenium","text":"<p>Install web driver</p> <ul> <li>visit <code>https://chromedriver.chromium.org/downloads</code> and download version same as your browser version.</li> <li>unzip and move <code>chromedriver</code> to <code>/usr/local/bin/chromedriver</code></li> </ul> <p>More - https://realpython.com/modern-web-automation-with-python-and-selenium/</p>"},{"location":"0-Information-Technology/python-notes/#data-science-setup","title":"Data Science Setup","text":"<p>Python installed in Ubuntu or Mac should not be used. Instead create a Virtual Environment for it.</p> <p>Virtual Environments can be created using conda or venv module. Each virtual environment has its own Python binary and can have its own independent set of installed Python packages in its site directories. More here.</p> <p>Quick Start on Linux more here.</p> <pre><code>sudo apt update\nsudo apt install python3 python3-dev python3-venv\n\nsudo apt-get install wget\nwget https://bootstrap.pypa.io/get-pip.py\nsudo python3 get-pip.py\n\npip --version\n\ncd your-project\npython3 -m venv env\n\nsource env/bin/activate\n</code></pre> <p>This will create a dir <code>env</code> and will have its own python, python3, pip and pip3. Now you can install any packages and this will not interfere with system.</p> <p>Install Jupyter in the venv. Now that we have an environment (base) you can use it, or create a new. Then</p> <ul> <li><code>pip install jupyter</code></li> <li><code>which jupyter</code> shows <code>/home/vaibhav/code/miniconda3/bin/jupyter</code> it does not effect the system python.</li> <li>it is pkg, same as flask</li> <li><code>jupyter notebook</code> runs a server to server jupyter notebooks at http://localhost:8888/tree</li> </ul>"},{"location":"0-Information-Technology/python-notes/#animation-and-modelling-in-python","title":"Animation and Modelling in Python","text":"<p>VPython GlowScript</p> <ul> <li>can be used to create objects and animate them</li> <li>VPython makes it unusually easy to write programs that generate navigable real-time 3D animations.</li> <li>https://www.glowscript.org/docs/VPythonDocs/videos.html</li> </ul> <p>Manim</p> <ul> <li>can animate equations and plots</li> <li>https://github.com/3b1b/manim</li> <li>https://www.youtube.com/watch?v=ENMyFGmq5OA</li> </ul> <p>Sage</p> <ul> <li>Allows equation animations and plotting</li> <li>https://www.sagemath.org/download-mac.html</li> </ul> <p>Povray</p> <ul> <li>The Persistence of Vision Raytracer is a high-quality, Free Software tool for creating stunning three-dimensional graphics. The source code is available for those wanting to do their own ports.</li> <li>http://www.povray.org/</li> </ul> <p>ImageMagick</p> <ul> <li>Create, edit, compose, or convert digital images.</li> <li>It can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and B\u00e9zier curves.</li> </ul> <p>EdX</p> <ul> <li>https://learning.edx.org/course/course-v1:CornellX+ENGR2000X+1T2017/home</li> </ul>"},{"location":"0-Information-Technology/python-notes/#links","title":"Links","text":"<ul> <li>Python Coding Kaggle</li> <li>Pandas Kaggle</li> <li>Flask - back end web framework micro</li> <li>Python Official Tutorial</li> <li>pythonbasics.org</li> </ul>"},{"location":"0-Information-Technology/r-language/","title":"R and R-Studio","text":"<p>They are statistical language and ID</p> <ul> <li><code>r</code> or <code>R</code> - R console in terminal</li> <li><code>Rscript my.r</code> - executes file in terminal</li> <li><code>Rscript -e \"getwd()\"</code> - executes cmd in terminal, can quickly install a library.</li> <li><code>R CMD BATCH my.r</code> runs R script and saves output to <code>my.r.Rout</code></li> <li>To make R Script executable like <code>./my.r</code> then:<ul> <li>set permission to 755</li> <li>add correct <code>#!</code> to top of file</li> </ul> </li> </ul> <pre><code>#!/usr/bin/env Rscript\nsayHello &lt;- function(){\nprint('hello')\n}\nsayHello()\n</code></pre>"},{"location":"0-Information-Technology/react-js-notes/","title":"ReactJS","text":"<p>It is a JS Library, it can be added to HTML page as other JS libraries (like jQuery). It is used to create single-page applications. It uses only one HTML page <code>index.html</code> and then all changes to page and routes are managed strictly by JS events.</p> <p>Build in Browser using https://react.new/</p> <p>Upgrade browser with <code>React Developer Tool</code> browser extension. It shows react components.</p>"},{"location":"0-Information-Technology/react-js-notes/#react-traditional-style-without-nodejs","title":"React Traditional Style - Without Node.js","text":"<p>Scripts to include, Both React and ReactDOM are available over a CDN.</p> <pre><code>&lt;script crossorigin src=\"https://unpkg.com/react@18/umd/react.development.js\"&gt;&lt;/script&gt;\n&lt;script crossorigin src=\"https://unpkg.com/react-dom@18/umd/react-dom.development.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Add this to page and you can use react.</p> <p><code>ReactDOM</code> class is available, call its <code>render()</code> function to render elements in DOM.</p> <p><code>React</code> class is available, call its <code>createElement()</code> function to create new DOM elements.</p> <pre><code>&lt;body&gt;\n&lt;div id=\"root\"&gt;&lt;/div&gt;\n&lt;script type=\"text/javascript\"&gt;\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(\nReact.createElement(\"h1\",null,\"Hi\"), // adds as heading\n// \"&lt;p&gt;hi&lt;/p&gt;\", // does not add as p, adds as string\ndocument.getElementById(\"root\")\n);\n&lt;/script&gt;\n&lt;/body&gt;\n</code></pre> <p>We can write HTML in JS to add it to DOM. HTML is written as string in, eg <code>\"&lt;h1&gt;\"</code> tag. However to directly write HTML in JS not as string, JS is extended and JSX is introduced.</p>"},{"location":"0-Information-Technology/react-js-notes/#jsx-and-babel","title":"JSX and Babel","text":"<p>JSX is not HTML, JSX is JavaScript XML, an extension of JavaScript that allows writing HTML in JS. To execute it, we need a compiler that can convert JSX to JS and HTML.</p> <p>JSX and JS go one in another and can be nested using {}s. When you start JS put in {} , then can again write HTML and again nest JS in {}.</p> <p>Babel is a JS compiler. You can insert plane HTML without quotes. Also add variable names with JS code within curly braces <code>&lt;p&gt;Hi {name.toUpperCase()}&lt;/p&gt;</code>. Eg:</p> <p>Babel converts JSX <code>&lt;p&gt;Hi&lt;/p&gt;</code> to JS <code>React.createElement(\"p\", null, \"Hi\");</code> on the fly.</p> <pre><code>...\n  &lt;script src=\"https://unpkg.com/@babel/standalone/babel.min.js\"&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id=\"root\"&gt;&lt;/div&gt;\n&lt;script type=\"text/babel\"&gt; //type is changed from javascript to babel\nlet msg = \"Tom\";\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(\n&lt;p&gt;Hi {msg}&lt;/p&gt;, // JSX, text without quotes. Renders as react element using babel}\n);\n&lt;/script&gt;\n&lt;/body&gt;\n</code></pre> <p>Babel can be said to be like Jinja in Flask and Blade in Laravel but not same.</p> <p>Conceptually - Using React, HTML can be written in JS, which renders it and adds it to a HTML DOM element, eg <code>root</code>. Now that it is in JS, it can be programmed and be data driven and dynamic. To manage the HTML code we split the UI into independent and reusable <code>Components</code>.</p> <p>This was all in file and now we will use node and create react app. file use is okay for prototype but prod should use app.</p>"},{"location":"0-Information-Technology/react-js-notes/#react-with-nodejs","title":"React with Node.js","text":"<p>Node.js creates structure for react project with Babel, file bundling etc.</p> <p><code>npx create-react-app app_name</code> create a folder with all required libraries like react, react dom, babel, react scripts etc.</p> <p>NPX, a package in node, that lets you run and execute packages without having to install them locally or globally.</p> <p><code>cd app_name</code> then <code>npm start</code> to run a web server using node and serve this app on <code>http://localhost:3000</code> as a dev build.</p>"},{"location":"0-Information-Technology/react-js-notes/#understanding-the-folder-structure-and-files","title":"Understanding the folder structure and files","text":"<p><code>package.json</code> - All dependencies can be seen in this file.</p> <p><code>node_modules</code> dir has all dendencies installed by Node.js.</p> <p><code>public</code> dir is used to serve app. It has index.html and other static files.</p> <p><code>build</code> dir will be added later when you create a prod build.</p> <p><code>manifest.json</code> - In <code>public</code> dir this file provides information about the app in JSON format. It is used by mobile and desktop when we install this app. We can update <code>short_name</code> and <code>name</code> here.</p> <p><code>src</code> dir has app code.</p>"},{"location":"0-Information-Technology/react-js-notes/#running-existing-project","title":"Running existing project","text":"<p>To run an existing react project, that you have downloaded, you need to install all the dependencies and that can be done by <code>npm install</code>. It uses <code>package.json</code> to install all dependencies.</p>"},{"location":"0-Information-Technology/react-js-notes/#adding-dependencies","title":"Adding Dependencies","text":"<pre><code>npm install bootstrap@5.2.0 react-bootstrap react-router-dom serve\n</code></pre> <p><code>serve</code> is a static file web server that can be used to run the production version of the React application.</p> <p>Notice here, that it is not only JS packages but also CSS frameworks like <code>bootstrap</code>. <code>import 'bootstrap/dist/css/bootstrap.min.css';</code> to load only CSS file. <code>import Container from 'react-bootstrap/Container'</code> loads the library.</p>"},{"location":"0-Information-Technology/react-js-notes/#the-indexjs-file","title":"The index.js File","text":"<p><code>index.js</code> is entry point to render app to DOM. <code>public/index.html</code> has <code>&lt;div id=\"root\"&gt;&lt;/div&gt;</code> that is used in <code>index.js</code>. <code>render()</code> function renders the app and takes JSX tree, as argument, that structures the entire app.</p> <p>Note: Any code that is non-JavaScript standard like import of file and JSX are converted to standart-JavaScript then they are served on browser. <code>import varName from 'filename.ext'</code> can be used to pull any file say image as var. Eg, in <code>app.js</code>, <code>import \"./styles.css\";</code> is non- javascript kind of code. This is later compiled and transformed to make it standard JS code and execute on browser. JSX uses CamelCase wile HTML lower.</p> <p>Each component is in its own file, eg, <code>app.js</code>, <code>header.js</code>.</p> <p><code>export default App</code> means export this component (function) as default App component.</p>"},{"location":"0-Information-Technology/react-js-notes/#react-components","title":"React Components","text":"<p>React Component is a building block of app, one of the UI component (same as a template in Flask). Eg, <code>Header</code>, <code>Sidebar</code>, <code>Content</code> and <code>Footer</code>. This lets split whole page in to independent, dynamic, resuable components. Hence, eaisier to manage and control them using JS.</p> <p>Conceptually, components are like JavaScript functions. They accept arbitrary inputs (called \u201cprops\u201d) and return React elements (JSX) describing what should appear on the screen. Eg,</p> <pre><code>function Header(props) {\nreturn &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;;\n}\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(&lt;Header name=\"Sara\" /&gt;;\n</code></pre> <p>So previously we could only render standard tags like <code>&lt;div&gt;</code>, <code>&lt;p&gt;</code> etc. but now can render custom tags like <code>&lt;Header /&gt;</code>, also pass properties (props) to it. Remember, every <code>ComponentFunction</code> follows CamelCase. It should return only one JSX tag like <code>&lt;div&gt;</code>, <code>&lt;p&gt;</code> or <code>&lt;Header /&gt;</code>. To return muliple elements, wrap them in div, and if you want to avoid extra divs added to dom, use <code>&lt;React.Fragment&gt;blah blah&lt;/React.Fragment&gt;</code> or shorthand <code>&lt;&gt; ...</code>.</p> <p>Props make components dynamic. You can use logic in any component, like hiding sidebar when loggin in. Props is basically an <code>object</code> (key-value), its properties can passed in JSX in same way as we pass props in HTML <code>&lt;App name=\"Tom\" yob={1990}&gt;</code>, they are passed where we render a component. It can be recieved as <code>function App(props)</code> or as using ES6 as <code>function App ({name, yob})</code>.</p> <p>To loop lists of elements use <code>map()</code> of <code>Array</code> class, and include a <code>key</code> attribute with a unique value per element. React requires it to efficiently rerender only part of list. It can be inline function, eg, <code>arr.map( (a) =&gt; (a.length) )</code>.</p> <p>Add conditional rendering expressions with the <code>&amp;&amp;</code> (if-then) and <code>?:</code> (if-then-else) operators. Expression on right of &amp;&amp; is executed when left is true. Eg, <code>data.length === 0 &amp;&amp; &lt;p&gt;There is nothing to show here.&lt;/p&gt;</code></p> <pre><code>function Posts() {\nconst posts = [\n{id: 1, text: 'Hello, world!'},\n{id: 2, text: 'The Next Post'},\n];\nreturn (\n&lt;&gt;\n{posts.length === 0 ?\n&lt;p&gt;There are no blog posts.&lt;/p&gt;\n:\nposts.map(p =&gt; {\nreturn (\n&lt;p key={post.id}&gt;{post.text}&lt;/p&gt;\n);\n})\n}\n&lt;/&gt;\n);\n}\n</code></pre> <p>Good strategy is to build multiple components with each having one purpose. Eg, <code>Header</code> <code>Sidebar</code>. Add <code>ContentArea</code> that can be swapped based on naigation.</p> <p>Components can be nested to build hierarchy. Eg,</p> <pre><code>&lt;Body name=\"Tom\"&gt;\n&lt;Posts /&gt;\n&lt;/Body&gt;\n</code></pre> <p>If the component is called with children, like above, then a <code>children</code> key is included in <code>props</code> object, which is equal to child components, here <code>&lt;Posts /&gt;</code>.</p> <pre><code>function Body({name, children}) {\nreturn (...);\n}\n</code></pre>"},{"location":"0-Information-Technology/react-js-notes/#class-implementation","title":"Class Implementation","text":"<p>Component can also be a ES6 Class, that <code>extends React.Component</code> and implements <code>render() {}</code>.</p> <pre><code>class Post extends React.Component {\nrender() {\nreturn &lt;h2&gt;Post Title!&lt;/h2&gt;;\n}\n}\n</code></pre>"},{"location":"0-Information-Technology/react-js-notes/#react-bootstrap","title":"React-Bootstrap","text":"<p>React-Bootstrap provides <code>Container</code> and <code>Stack</code> components to design layout of website.</p> <pre><code>  return (\n&lt;Container fluid className=\"App\"&gt; // className is HTML class\n...  // &lt;-- no changes to JSX content\n&lt;/Container&gt;\n);\n</code></pre>"},{"location":"0-Information-Technology/react-js-notes/#hooks","title":"Hooks","text":"<p>useState Hook</p> <p>useState is a function in React class that can be used to manage state of App.</p> <p><code>useState(arg)</code> arg can be any data type.</p> <p>it returns array having <code>[stateValue, setStateFunc] = setState(\"a Value\")</code> we can use them in app to manage states. We can have multiple states of app, so make multiple instance of this function.</p> <p>useEffect Hook</p> <p>These are like eventListners that can listen to some variable and if there is a change in its state they can do something.</p> <p><code>useEffect(funcDoSomething, [varToListenTo]);</code> when arg2 changes, arg1 is executed. arg2 = [] then only run once, arg2 can have multiple vars to listen to.</p> <p>useReducer Hook can be used to manage state and effect at once.</p> <p>It takes two arguments, arg1 is function to execute on state change, and arg2 is initial state value.</p> <p>It returns, 1 state value, 2 function to change state. Eg, state is counterValue</p> <pre><code>const [counterValue, setCounterValue] = useReducer(\n(a) =&gt; a++, //\n0\n);\n</code></pre> <p>ToDo: Need some more understanding here on, how to use reducer to do different action based on param passed?</p>"},{"location":"0-Information-Technology/react-js-notes/#handling-forms-14-07-2022","title":"Handling Forms - 14-07-2022","text":"<p>Uncontrolled Component: <code>useRef</code> we can create instance of this function and attach that to form inputs.</p> <pre><code>const empName = useRef();\n&lt;input ref={empName} ...&gt;\n// on Submit\na = empName.current.value; // GET\nempName.current.value = 'A'; // SET\n</code></pre> <p>We can get and set the values using <code>empName.current.value</code></p> <p>Controlled Component: <code>useState</code> and bind to input tag using <code>onChange</code>:</p> <pre><code>const [empName, setEmpName] = useState(\"\");\n&lt;input value={empName} onChange={ (e) =&gt; setEmpName(e.target.value) } ...&gt;\n// on Submit\na = empName; // GET\nsetEmpName(\"A\"); // SET\n</code></pre> <p>Custom Hooks</p> <p>We can create our own custom hooks that can be reused based on our requirements. They have to start with <code>use...</code>. They instantiate another hook within them. Eg, we can make a custom hook to handle form events like setting default value, getting current value, onChange events, validation etc.</p> <p>Others: formik.org, react-hook-form.com, usehooks.com</p>"},{"location":"0-Information-Technology/react-js-notes/#routes","title":"Routes","text":"<p>React makes SPA, only one page is served from server. So <code>react-router-dom</code> is library that can be used to manage routes on browser.</p> <p>In <code>index.js</code> or<code>App.js</code> you can create <code>&lt;Route&gt;</code> in <code>&lt;Routes&gt;</code> having <code>path</code> and <code>element</code>.</p> <pre><code>import { App, About, Contact } from \"./App\";\nimport { BrowserRouter, Routes, Route, Navigate } from react-router-dom\";\nReactDOM.render(\n  &lt;BrowserRouter&gt;\n    &lt;Routes&gt;\n      &lt;Route path=\"/\" element={&lt;App /&gt;} /&gt;\n      &lt;Route path=\"/about\" element={&lt;About /&gt;} /&gt;\n      &lt;Route path=\"/contact\" element={&lt;Contact /&gt;} /&gt;\n      &lt;Route path=\"*\" element={&lt;Navigate to=\"/\" /&gt;} /&gt;\n    &lt;/Routes&gt;\n  &lt;/BrowserRouter&gt;,\n  document.getElementById(\"root\")\n);\n</code></pre> <p>You can link routes to create hierarcy. Use <code>{ Link }</code> a XHR, to add link to component in DOM. It is like <code>url_for</code> in Flask.</p>"},{"location":"0-Information-Technology/react-js-notes/#routes-with-bootstrap","title":"Routes with Bootstrap","text":"<p>Bootstrap has <code>Nav.Link</code> component that creates nav-item, it has <code>as</code> and <code>to</code> props to work with React-Route's <code>NavLink</code>.</p> <pre><code>import Navbar from \"react-bootstrap/Navbar\";\nimport Nav from \"react-bootstrap/Nav\";\nimport { NavLink } from 'react-router-dom';\nexport default function Sidebar() {\nreturn (\n&lt;Navbar sticky=\"top\" className=\"flex-column Sidebar\"&gt;\n&lt;Nav.Item&gt;\n&lt;Nav.Link as={NavLink} to=\"/\"&gt;Feed&lt;/Nav.Link&gt;\n&lt;/Nav.Item&gt;\n&lt;Nav.Item&gt;\n&lt;Nav.Link as={NavLink} to=\"/explore\"&gt;Explore&lt;/Nav.Link&gt;\n&lt;/Nav.Item&gt;\n&lt;/Navbar&gt;\n);\n}\n</code></pre>"},{"location":"0-Information-Technology/react-js-notes/#parameters-and-routes","title":"Parameters and Routes","text":"<p>To define a route with a dynamic section, the path attribute of the Route component uses a special syntax with a colon prefix:</p> <pre><code>&lt;Route path=\"/user/:username\" element={&lt;UserPage /&gt;} /&gt;\n</code></pre> <p>The component referenced by the element attribute or any of its children can use the <code>useParams()</code> hook function to access the dynamic parameters of the current URL as an object.</p>"},{"location":"0-Information-Technology/react-js-notes/#development-and-structuring","title":"Development and Structuring","text":"<p>Following steps can help you build a React App:</p> <ol> <li>Plan the UI that you want to build as a wireframe or sketch.</li> <li>Break the UI into top level Components like header, sidebar, content and footer.<ol> <li>Build these components and place in <code>src/components</code></li> </ol> </li> <li>Think of logical pages that use the above components but have different low level componenets. Eg, ProfilePage and FeedPage, both have header, sidebar and content BUT the content will have different sub-components like profile or posts.<ol> <li>Build these components and place in <code>src/pages</code></li> </ol> </li> <li>Build routes for these Pages and update the header.</li> </ol> <p>State - use to set and get data, like responses, session variables and state (loading, error, done)</p> <p>Effect - use to do functionality like - fetch, or any function.</p> <p>If a function returns JSX then it is a react component.</p>"},{"location":"0-Information-Technology/react-js-notes/#testing","title":"Testing","text":"<p><code>Jest.js</code> is used to write test.</p>"},{"location":"0-Information-Technology/react-js-notes/#deployment","title":"Deployment","text":"<p>App can be deployed to Netlify.com</p> <p>Do <code>npm run build</code> and then <code>build</code> folder has prod ready code to deploy.</p>"},{"location":"0-Information-Technology/react-js-notes/#resources","title":"Resources","text":"<p>Links</p> <ul> <li>React Tutorial Miguel Grinberg - https://blog.miguelgrinberg.com/post/the-react-mega-tutorial-chapter-2-hello-react</li> <li>LinkedIn Learning - https://www.linkedin.com/learning/react-js-essential-training</li> <li>React Docs - https://reactjs.org/docs/hello-world.html</li> </ul> <p>Next</p> <ul> <li>ReactNative</li> <li>GraphQL</li> </ul>"},{"location":"0-Information-Technology/text-editors/","title":"Text Editors","text":"<p>If you love coding text editors are your sharp tools. Customizing them to your needs will help you save time and increase productivity.</p>"},{"location":"0-Information-Technology/text-editors/#sublime-text","title":"Sublime Text","text":""},{"location":"0-Information-Technology/text-editors/#how-to-use-python-script-with-key-bindings","title":"How to use Python script with Key Bindings","text":"<p>We will create a sample package that will display time on status bar when we press keys <code>ctrl+shift+c</code>, just for demonstrating.</p> <ul> <li>Create a new python file inside Users Package Library. On Mac with Sublime Text 3 it can be created at: <code>Users/yourname/Library/Application Support/Sublime Text 3/Packages/User/any_name.py</code></li> </ul> <ul> <li>In the python file add following content:</li> </ul> <pre><code>import sublime\nimport sublime_plugin\nimport time\nclass MyCustomMessageCommand(sublime_plugin.WindowCommand):\n# Command shows message on Status Bar\ndef run(self):\nnow = time.strftime(\"%c\")\nmessage = \"The time is \" + now\nsublime.status_message(message)\n</code></pre> <ul> <li>Add the key bindings:</li> </ul> <pre><code>[\n{\n\"keys\" : [\"ctrl+shift+c\"], \n\"command\" : \"my_custom_message\" \n}\n]\n</code></pre> <p>As you can see that the python class name becomes the command name with _ added.</p> <p>Now on pressing <code>ctrl+shift+c</code> you can execute this python file which displays the time on status bar in this case.</p> <p>You can use this feature to unlimited possibilities. I used it to add timestamp to file whenever it was saved.</p> <p>References:</p> <ul> <li>https://forum.sublimetext.com/t/automatically-updated-timestamp/7156/7</li> </ul>"},{"location":"0-Information-Technology/text-editors/#extending-sublime-text-for-markdown-support","title":"Extending Sublime Text for Markdown Support","text":"<p>If you want more syntax highlighting and better preview of what you write then you can extend Sublime Text by installing  package, follow steps below:</p> <ul> <li>Type: <code>Cmd + Shift + P</code> to open package manager.</li> <li>Then type <code>install package</code> and hit enter. This will provide you list of available packages from packagecontrol.io</li> <li>Next when you get dropdown type <code>Markdown</code> and this will list you all markdown related packages.</li> <li>You can select <code>Markdown Editing</code> to install the package. This provides much better highlighting and preview.</li> </ul> <p>I, personally, didn't like it much and was a bit distracting for me. So I removed this package. But you may like it.</p> <p>Removing a package from Sublime Text:</p> <ul> <li>press <code>Cmd + Shift + P</code> and</li> <li>then type <code>remove package</code>. This will give you list of packages installed and</li> <li>next select <code>Markdown Editing</code> to remove it.</li> </ul>"},{"location":"0-Information-Technology/text-editors/#vs-code","title":"VS Code","text":"<p>Recently VS Code turned out to be best editor for Markdown however it is bit heavy. Also 'Markdown Preview' extension on Chrome makes it handy to preview markdown files. VS Code can be logged in using GitHub to start sync.</p> <ul> <li>Extensions can be disabled when not in use.</li> <li>open <code>~/.config/Code/User/settings.json</code> to add extension configurations</li> <li>add below codes within the curly braces</li> </ul> <p>Markdownlint disable rules:</p> <pre><code>  \"markdownlint.config\": {\n\"default\": true,\n\"MD007\": { \"indent\": 4 }\n}\n</code></pre> <p>cSpell disable code check in Markdown code blocks:</p> <pre><code>    \"cSpell.languageSettings\": [\n{\n// use with Markdown files\n\"languageId\": \"markdown\",\n// Exclude code inline and multiline both\n\"ignoreRegExpList\": [\n\"^\\\\s*```[\\\\s\\\\S]*?^\\\\s*```\",\n\"\\\\s`[\\\\s\\\\S]*?\\\\s*`\",\n]\n}\n],\n</code></pre>"},{"location":"0-Information-Technology/text-editors/#pycharm","title":"PyCharm","text":"<ul> <li>Keyboard Shortcuts<ul> <li>Back and forth - <code>ctrl-alt-left</code> ro <code>ctrl-alt-right</code></li> </ul> </li> </ul>"},{"location":"0-Information-Technology/tools-frameworks/","title":"Tools and Frameworks","text":"<p>tools, framworks, libraries, systems, projects that help do IT Engg work. Landing zone for new topics you learn that have no dedicated file</p> <ul> <li>Kubernetes - is an open-source container orchestration system for automating software deployment, scaling, and management.</li> </ul> <ul> <li>IAC - Infrastructure as a Code<ul> <li>Ansible - It can provision the underlying infrastructure of your environment, virtualized hosts and hypervisors, network devices, and bare metal servers.</li> <li>Terraform - It is used to automate various infrastructure tasks.</li> <li>AWS CloudFormation - lets you create and manage a collection of Amazon Web Services (AWS) resources by provisioning and updating them in a predictable way</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/virtual-box/","title":"Virtual Box","text":"<p>Vagrant is a CLI to create virtual box with all configurations in a file. </p> <ul> <li>Install vagrant by downloading from site. It installs package with CLI.</li> <li>Create following file in any folder, say <code>~/vagrant/vagrantfile</code>:</li> </ul> <pre><code>Vagrant.configure(\"2\") do |config|\nconfig.vm.box = \"ubuntu/xenial64\"\nconfig.vm.network \"private_network\", ip: \"192.168.33.10\"\nconfig.vm.provider \"virtualbox\" do |vb|\nvb.memory = \"1024\"\nend\nend\n</code></pre> <ul> <li>Then run <code>vagrant up</code>. On first run it will download and install ubuntu 16.04, 1GB, at 192.168.33.10. In subsequent run it will just start the VM.</li> <li>do, <code>vagrant ssh</code> to ssh to new vm.</li> <li><code>vagrant halt</code> to stop a VM</li> <li>DANGER ZONE: <code>vagrant destroy</code> to delete a VM</li> </ul>"},{"location":"0-Information-Technology/web-server-config/","title":"Web Server Config","text":"<p>Web server can be a linux server that takes client requests and provides a response. It can host a web app. Web app can be backed by a programming language that and process data and store this data in  a database.</p> <p>In this article we would be covering all that is listed in contents below. It is assumed that you have a machine with Ubuntu server installed. It can be on cloud like GCP or AWS etc, or it can be on a virtual machine via Vagrant and Virtual Box.</p> <ul> <li>Do not remove this line (it will not be displayed) {:toc}</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#ubuntu-server-configuration","title":"Ubuntu Server Configuration","text":"<p>Now that you are connected to host VM via SSH, let's start with:</p> <ul> <li>Updating Ubuntu: <code>sudo apt update &amp;&amp; sudo apt upgrade</code></li> <li>Check ram and CPU usage <code>htop</code> , we see that we do not have swap memory, this helps in low ram system when on high load.</li> </ul> <p>Adding the swap memory:</p> <ul> <li>Lets allocate 1GB swap memory: <code>sudo fallocate -l 1G /swapfile</code></li> <li><code>sudo dd if=/dev/zero of=/swapfile bs=1024 count=1048576</code></li> <li>Assign the correct permission to swapfile: <code>sudo chmod 600 /swapfile</code></li> <li>make the swap: <code>sudo mkswap /swapfile</code></li> <li>Turn on the swapfile: <code>sudo swapon /swapfile</code></li> <li>edit the fstab file: <code>sudo nano /etc/fstab</code></li> <li>add this line to the end of file: <code>/swapfile swap swap defaults 0 0</code></li> <li>mount the files: <code>sudo mount -a</code></li> <li>Check ram and cpu again to verify swap: <code>htop</code></li> </ul>"},{"location":"0-Information-Technology/web-server-config/#install-apache2-php-and-mysql-using-lamp","title":"Install Apache2 PHP and MySQL using LAMP","text":"<p>Install the softwares using below commands:</p> <ul> <li><code>sudo apt install tasksel</code></li> <li><code>sudo tasksel install lamp-server</code></li> <li><code>sudo apt install php-curl php-gd php-mbstring php-xml php-xmlrpc</code></li> <li>Get the external IP address: <code>curl ifconfig.me</code></li> <li>Type http://123.456.789.10 , the external IP address in browser to see served page.</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#domain-configuration","title":"Domain Configuration","text":"<p>Now we need to point the domain to this webserver so that we can access files server. We will use <code>example123.com</code> in this example.</p> <p>Only if you do not have a domain to point to server and want to use vhost:</p> <ul> <li>Modify the host file to add virtual hosts: <code>sudo nano /etc/hosts</code></li> <li>To map 'example123.com' tp IP address add this line: <code>35.111.00.111 example123.com</code></li> </ul> <p>If you have a domain,</p> <ul> <li>edit DNS records and add 'A-record' with the external IP address, for eg:</li> <li>host: *</li> <li>IP: 35.111.00.111</li> <li>then, <code>example123.com</code> will open the page from GCP VM machine.</li> <li>You may also reserve static external IP address of VM on GCP:<ul> <li>From your GCP dashboard find 'Networking &gt; External IP addresses'.</li> <li>Now click the down arrow under the 'Type' column and select 'Static' for the External IP address which is connected to your instance of GCP Compute Engine.</li> <li>By reserving a Static IP Address you will not loose your access to website after server outages or restarts.</li> </ul> </li> </ul> <p>Point a domain to external IP Address:</p> <ul> <li>To Name servers, add DNS name server, eg, <code>dns1.india-to.com</code></li> <li>on DNS Management of the DNS server<ul> <li>add Host Name '@', record type 'A (Address)', then your IP Address</li> <li>add Host Name 'www', record type 'A (Address)', then your IP Address</li> </ul> </li> </ul>"},{"location":"0-Information-Technology/web-server-config/#add-sites-to-apache-server","title":"Add sites to Apache Server","text":"<p>Now we need to enable sites on apache we server to connect domain with dir of files to be served by this server.</p> <ul> <li><code>cd /etc/apache2/sites-available/</code></li> <li><code>ls -l</code></li> <li>Copy configuration file for new domain to be added: <code>sudo cp 000-default.conf example123.com.conf</code></li> <li>Let us switch to root user: <code>sudo su</code></li> <li>edit: <code>nano example123.com.conf</code> and add following content to file:</li> </ul> <pre><code>&lt;Directory /var/www/html/example123.com&gt;\nRequire all granted\n&lt;/Directory&gt;\n&lt;VirtualHost *:80&gt;\nServerName example123.com\nServerAlias www.example123.com\nServerAdmin webmaster@localhost\nDocumentRoot /var/www/html/example123.com\nErrorLog ${APACHE_LOG_DIR}/error.log\nCustomLog ${APACHE_LOG_DIR}/access.log combined\n&lt;/VirtualHost&gt;\n</code></pre> <ul> <li>disable default site: <code>a2dissite 000-default.conf</code></li> <li>enable new site: <code>a2ensite example123.com.conf</code></li> <li>restart apache service: <code>systemctl reload apache2</code></li> <li>go to web documents location: <code>cd /var/www/html</code></li> <li>create directory for new site: <code>mkdir example123.com</code></li> <li><code>cd example123.com</code> go in the directory.</li> <li><code>nano index.html</code> create an html file.</li> <li>Now open browser and goto 'example123.com' you should see the contents of index.html.</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#mysql-database-configuration","title":"MySQL Database Configuration","text":"<p>Now we will configure MySQL database so that we can use that in our web apps.</p> <ul> <li><code>mysql -u root</code></li> </ul> <pre><code>&gt; CREATE DATABASE db123;  &gt; GRANT ALL ON db123.* TO 'db123_user' IDENTIFIED BY 'db123_pwd!';  &gt; quit;  </code></pre> <ul> <li>Secure the installation <code>mysql_secure_installation</code>, select Y for all or as per your need.</li> </ul> <p>Configure PHP:</p> <ul> <li><code>nano /etc/php/7.2/apache2/php.ini</code></li> <li>update:</li> </ul> <pre><code>upload\\_max\\_filesize = 20M  \npost\\_max\\_size = 21M\n</code></pre> <p>Congratulations, can you believe we are already done! We can create and host any webapp on one of the Worlds biggest cloud infrastructure, GCP, and its scalable!</p>"},{"location":"0-Information-Technology/web-server-config/#wordpress-installation-on-ubuntu-server","title":"Wordpress Installation on Ubuntu Server","text":"<p>Now that we have Apache, PHP and MySQL configured, connected and working together, we can start developing web apps. Wordpress is a easy to use CMS in PHP, lets get started with installing wordpress.</p> <ul> <li><code>cd /var/www/html/example123.com/</code></li> <li>download wordpress: <code>wget https://wordpress.org/latest.tar.gz</code></li> <li>Unzip the file <code>tar -xvf latest.tar.gz</code></li> <li><code>mv wp-config-sample.php wp-config.php</code></li> <li><code>nano wp-config.php</code></li> </ul>"},{"location":"0-Information-Technology/web-server-config/#web-server-tuning","title":"Web Server Tuning","text":"<p>Configure MPM_Prefork.conf to manage apache load performance:</p> <ul> <li><code>nano /etc/apache2/mods-enabled/mpm_prefork.conf</code></li> <li>Update to below:</li> </ul> <pre><code>&lt;IfModule mpm_prefork_module&gt;\nStartServers    1\nMinSpareServers   2\nMaxSpareServers   5\nMaxRequestWorkers 10\nMaxConnectionsPerChild  1000\n&lt;/IfModule&gt;\n</code></pre> <p>Tune the new Apache install:</p> <ul> <li><code>cd ~</code></li> <li><code>wget https://raw.githubusercontent.com/richardforth/apache2buddy/master/apache2buddy.pl</code></li> <li><code>chmod +x apache2buddy.pl</code></li> <li><code>./apache2buddy.pl</code></li> <li>This perl script tells the health of Apache server.</li> </ul> <p>User guides:</p> <ul> <li>video used: YouTube</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#how-to-add-multiple-domains-on-apache-web-server","title":"How to add multiple domains on Apache Web Server","text":"<p>We can host multiple sites on one server with vistual hosts in Apache.</p> <ul> <li>create conf file <code>cd /etc/apache2/sites-available/</code> then <code>sudo cp 000-default.conf addonDomain.com.conf</code></li> <li>open conf file using nano, then edit</li> </ul> <pre><code>&lt;Directory /var/www/html/addonDomain.com&gt;\nRequire all granted  \n&lt;/Directory&gt;\n&lt;VirtualHost *:80&gt;\nServerName example.com\nServerAlias www.example.com\nServerAdmin admin@example.com\nDocumentRoot /var/www/example.com/html\n&lt;/VirtualHost&gt;\n</code></pre> <ul> <li>make folders <code>mkdir var/www/html/addonDomain.com/</code></li> <li>enable site:</li> </ul> <pre><code>a2ensite example.com.conf\nsystemctl reload apache2\n</code></pre> <ul> <li>More details here.</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#serve-python-files-on-apache-web-server","title":"Serve Python files on Apache Web Server","text":"<p>Python files can be served via CGI or WSGI. Python is language, Apache2 is webServer, CGI and WSGI are protocol to help web server and language talk to each other.</p>"},{"location":"0-Information-Technology/web-server-config/#cgi-scripts","title":"CGI Scripts","text":"<p>Common Gateway Interface or CGI provides interface for web server to serve HTML from console programs like Python.</p> <ul> <li>By CGI we can directly open <code>index.py</code> in browser and it works like PHP file. It outputs the result of the script file.</li> <li>default directory is <code>/usr/lib/cgi-bin/</code>, you can add, <code>hello.cgi</code> here and open in browser.</li> <li>enable in apache: <code>a2dismod mpm_event</code></li> <li>enable cgi module: <code>a2enmod mpm_prefork cgi</code></li> <li>to make new dir for cgi files, add following to site conf file:</li> </ul> <pre><code>&lt;VirtualHost *:80&gt;\n...\n&lt;Directory /var/www/html/cgi_dir&gt;\nOptions +ExecCGI\nAddHandler cgi-script .py .cgi\n# DirectoryIndex index.py\n&lt;/Directory&gt;\n...\n&lt;/VirtualHost&gt;\n</code></pre> <ul> <li>CGI runs script when requested, where as WSGI runs script with start of WebServer.</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#wsgi","title":"WSGI","text":"<p>Web Server Gateway Interface or WSGI is a simple calling convention for web servers to forward requests to web applications.</p> <ul> <li><code>mod_wsgi</code> is an Apache HTTP Server module that provides a WSGI compliant interface for hosting Python based web applications. It is an alternative to CGI.</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#flask-wsgi-and-apache2-on-linux-hands-on","title":"Flask, WSGI and Apache2 on Linux [Hands On]","text":"<p>Assuming you have a working apache2 server and you have python installed. Next we need to install pip and WSGI module.</p> <p>Python 3:</p> <ul> <li><code>sudo apt-get install libapache2-mod-wsgi-py3</code></li> <li><code>sudo apt-get install python3-pip</code></li> </ul> <p>Python 2:</p> <ul> <li><code>sudo apt-get install libapache2-mod-wsgi</code></li> <li><code>sudo apt-get install python-pip</code></li> </ul> <p>Enable WSGI and install flask:</p> <ul> <li><code>a2enmod wsgi</code> enable the WSGI module in apache.</li> <li><code>pip3 install flask</code></li> </ul> <p>Set up directory and flask files:</p> <ul> <li><code>mkdir /var/www/apps</code> this contains all flask apps.</li> <li><code>mkdir /var/www/apps/blog</code> this is our first app.</li> <li><code>mkdir /var/www/apps/blog/lib</code> this contains code for our blog app.</li> <li><code>mkdir /var/www/apps/blog/lib/static</code> this will serve static files for our blog app.</li> </ul> <p>Make flask app:</p> <ul> <li><code>sudo nano /var/www/apps/blog/lib/main.py</code></li> </ul> <pre><code>from flask import Flask\napp = Flask(__name__)\n@app.route('/')\ndef hello_world():\nreturn 'Hello from Flask blog app!'\nif __name__ == '__main__':\napp.run()\n</code></pre> <p>Make this folder as python module, (important):</p> <ul> <li><code>touch /var/www/apps/blog/lib/__init__.py</code></li> <li>We created <code>__init__.py</code> as a blank file. This is important and is required to import our lib folder as a python module. Now we can import <code>lib.main</code> in wsgi file.</li> </ul> <p>Add the wsgi file:</p> <ul> <li><code>sudo nano /var/www/apps/blog/app.wsgi</code></li> </ul> <pre><code>import sys\nsys.path.insert(0, '/var/www/apps/blog')\nfrom lib.main import app as application\n</code></pre> <p>Configuring virtual hosts conf file to make it work:</p> <ul> <li>Imp, in exmple below, replace 'myapps.com' with your domain name.</li> <li><code>cd /etc/apache2/sites-available/</code></li> <li>add a site file <code>cp 000-default.conf myapps.com.conf</code></li> <li><code>nano myapps.com.conf</code></li> </ul> <pre><code>&lt;VirtualHost *:80&gt;\nServerName myapps.com\nServerAdmin webmaster@localhost\n# This is path for homepage of myapps.com\nDocumentRoot /var/www/html/myapps.com\n# App: blog, URL: http://myapps.com/myblog\nWSGIScriptAlias /myblog /var/www/apps/blog/app.wsgi\n&lt;Directory /var/www/apps/blog&gt;\nOrder deny,allow\nAllow from all\n&lt;/Directory&gt;\nAlias /myblog/static /var/www/apps/blog/lib/static\n# Enables passing of authorization headers\nWSGIPassAuthorization On\n# logs configuration\nErrorLog ${APACHE_LOG_DIR}/error.log\nCustomLog ${APACHE_LOG_DIR}/access.log combined\n&lt;/VirtualHost&gt;\n</code></pre> <ul> <li><code>a2ensite myapps.com.conf</code> enable the site.</li> <li><code>service apache2 restart</code> restart the service.</li> <li>Now visit <code>http://myapps.com/myblog/</code> to access app.</li> </ul> <p>If you see errors:</p> <ul> <li><code>tail -30 /var/log/apache2/error.log</code> shows you error logs from apache server.</li> </ul>"},{"location":"0-Information-Technology/web-server-config/#multiple-flask-apps-and-adding-user-and-group-to-process","title":"Multiple Flask apps and adding user and group to process","text":"<ul> <li>Add new user <code>adduser apps</code>, remember password here</li> <li>update primary group <code>usermod -g www-data apps</code></li> <li>give permission to group <code>chmod 775 /home/apps</code></li> </ul> <ul> <li>login with new user <code>apps</code></li> <li><code>git clone the_web_app.git</code></li> <li><code>python3 -m venv venv</code></li> <li><code>source venv/bin/activate</code></li> <li><code>pip3 install -r requirements.txt</code></li> <li><code>touch __init__.py</code></li> <li>add <code>app.wsgi</code></li> </ul> <pre><code>#!venv/bin/python3\nimport sys\nimport logging\nlogging.basicConfig(stream=sys.stderr)\nsys.path.insert(0, '/home/apps/todo')\nfrom lib.main import app as application\n</code></pre> <p>Apache v-host file:</p> <pre><code>&lt;VirtualHost *:80&gt;\nServerName py.ess.com\nServerAdmin webmaster@localhost\nDocumentRoot /var/www/html/py.ess.com\nWSGIScriptAlias /site1 /var/www/apps/app1/app1.wsgi\n&lt;Directory /var/www/apps/app1&gt;\nOrder deny,allow\nAllow from all\n&lt;/Directory&gt;\nAlias /site1/static /var/www/apps/app1/static\nWSGIScriptAlias /flap /var/www/apps/flap/app.wsgi\n&lt;Directory /var/www/apps/flap&gt;\nOrder deny,allow\nAllow from all\n&lt;/Directory&gt;\nWSGIScriptAlias /todo /var/www/apps/todo/app.wsgi\n&lt;Directory /var/www/apps/todo&gt;\nOrder deny,allow\nAllow from all\n&lt;/Directory&gt;\nWSGIDaemonProcess todo-client user=apps group=www-data threads=5\nWSGIScriptAlias /todo-client /home/apps/todo/app.wsgi\n&lt;Directory /home/apps/todo&gt;\nWSGIApplicationGroup todo-client\nWSGIProcessGroup todo-client\nOrder deny,allow\nAllow from all\nRequire all granted\n&lt;/Directory&gt;\nAlias /todo-client/static /home/apps/todo/lib/static\nWSGIPassAuthorization On\n# WSGIDaemonProcess site2 user=myserviceuser group=myserviceuser threads=5 python-home=/$\n# WSGIScriptAlias /site2 /var/www/apps/app2/application.wsgi\n# &lt;Directory /var/www/apps/app2&gt;\n#     WSGIApplicationGroup site2\n#     WSGIProcessGroup site2\n#     Order deny,allow\n#     Allow from all\n# &lt;/Directory&gt;\n# logs configuration\nErrorLog ${APACHE_LOG_DIR}/error.log\nCustomLog ${APACHE_LOG_DIR}/access.log combined\n&lt;/VirtualHost&gt;\n</code></pre> <p>Note:</p> <ul> <li>ensure group has permission to database and log directories.</li> </ul> <p>To Do:</p> <ul> <li>WSGIDaemonProcess helloworldapp user=www-data group=www-data threads=5</li> <li>WSGIProcessGroup</li> <li>Multiple Apps: Apache virtualhost is only for domain/sub-domain, to add more apps with different directories, add directory tags to configuration file. If the two Flask apps are running on the same domain just as subfolders, then you only need one VirtualHost but you\u2019ll need multiple WSGIScriptAlias directives.</li> </ul> <p>Links:</p> <ul> <li>Muiltiple flask apps usgin Apache2 and Ubuntu.</li> </ul>"},{"location":"1-Software-Engineering/cs-se-basics/","title":"Software Engineering","text":"<p>all about standards, conventions, ethics, practices</p>"},{"location":"1-Software-Engineering/cs-se-basics/#coding-best-practices-ways-of-working","title":"Coding Best Practices - Ways of Working","text":"<ul> <li>Follow coding standards</li> <li>Use git</li> <li>Write Unit testing - use code to test the small units of programme, test standalone modules.</li> <li>Write integration testing - use code to test if modules work correclty when connected together.</li> <li>Do funcitonal testing - as a tester, test the functionality of the application.</li> <li>Test business outcomes, verify by business people</li> <li>Work with people smarter than you</li> <li>do pair programming</li> </ul> <ul> <li>Link<ul> <li>td.io - Software Development 101</li> <li>Open Sourcing a Python Project the Right Way</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/cs-se-basics/#open-source-contribution","title":"Open Source Contribution","text":"<ul> <li>Why? - It is a great way to grow and evovle, learn, build your skill and be part of community, grow your network, showcase your presence.</li> </ul> <ul> <li>Links - OpenSourceGuide</li> </ul>"},{"location":"1-Software-Engineering/cs-se-basics/#working-on-someone-elses-code","title":"Working on someone else's code","text":"<ul> <li>Start a debugger</li> <li>Step into and over, understand the variable values, add breakpoints.</li> </ul>"},{"location":"1-Software-Engineering/cs-se-basics/#links","title":"Links","text":"<ul> <li>3 EDX Soft engg - https://www.edx.org/course/software-engineering-basics-for-everyone</li> <li>2 edx Soft Engg MM - https://www.edx.org/micromasters/ubcx-software-development</li> <li>1 edx Algorithms and Data Structures MM - https://www.edx.org/micromasters/ucsandiegox-algorithms-and-data-structures</li> <li>g4g DSA - https://www.geeksforgeeks.org/complete-roadmap-to-learn-dsa-from-scratch/</li> </ul>"},{"location":"1-Software-Engineering/cs-se-basics/#coding-naming-conventions","title":"Coding Naming Conventions","text":"<ul> <li>Python - Use underscores</li> <li>Javascript - Camel Case</li> <li>files and folders - use hyphen. Link google style guide</li> </ul>"},{"location":"1-Software-Engineering/cs-se-basics/#computer-science","title":"Computer Science","text":"<p>A thread is the smallest sequence of instructions that can be man\u2010 aged independently. It is common for a process to have multiple active threads, sometimes sharing resources such as memory or file handles. Multithreaded web servers start a pool of threads and select a thread from the pool to handle each incoming request.</p>"},{"location":"1-Software-Engineering/cs-se-basics/#oops","title":"OOPS","text":"<ul> <li>Object is a Class and has<ul> <li><code>attributes</code> - variables</li> <li><code>methods()</code> - functions</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/data-structures-algorithms/","title":"Data Structures &amp; Algorithms","text":"<p>https://www.quora.com/How-do-I-start-learning-or-strengthen-my-knowledge-of-data-structures-and-algorithms/answer/Robin-Thomas-16</p>"},{"location":"1-Software-Engineering/git/","title":"Git and GitHub","text":"<p>Git is version control software to track changes in source code. GitHub is cloud storage for Gits. We check-in and check-out files to git and it keeps a track of the history.</p>"},{"location":"1-Software-Engineering/git/#installation","title":"Installation","text":"<ul> <li><code>git --version</code> to check the version of git installed.</li> <li><code>where git</code> to find path<ul> <li>to fix this, add the location of folder having <code>git.exe</code> to <code>$PATH</code>.</li> </ul> </li> <li>On mac it was pre installed as part of Xcode Command Line Tools.</li> </ul>"},{"location":"1-Software-Engineering/git/#terminology","title":"Terminology","text":"<ul> <li><code>HEAD</code> variable that points to default branch.</li> <li><code>checkout</code> switch or activate a branch</li> <li><code>remote</code> - Git repo on server. Git stores remote URLs in objects called \"remotes\"<ul> <li><code>origin</code> origin is the default remote for almost all repositories. It has info on fetch/push url, remote branches, track status etc.</li> </ul> </li> <li><code>track</code> - local-branch needs a link to remote-branch to do push and pull.<ul> <li>as a <code>tracking reference to the upstream server</code></li> <li>set <code>the remote as upstream</code> </li> <li>to <code>track remote branch</code></li> <li>current branch <code>has no upstream branch.</code></li> <li><code>-u</code> or <code>--set-upstream</code> or <code>--set-upstream-to=origin/master</code> or <code>--track</code> all are same.</li> <li><code>upstream branch</code> - remote-branch to which local-branch tracks to</li> </ul> </li> <li><code>fetch</code> look for changes but don't download</li> <li><code>pull</code> download changes to local</li> <li><code>fork</code> - copies the code to your-remote-space. Keeps link to original upstream, in case you want to pull future changes.</li> <li><code>clone</code> to local-system for making changes</li> <li><code>pull request</code> Ask remote-repo owner to pull your branch into main branch. This will merge your updates. Do follow developer guidelines for this to be accepted.</li> </ul>"},{"location":"1-Software-Engineering/git/#configuration","title":"Configuration","text":"<ul> <li>You can get/set/edit/unset options with this command</li> <li>values can be set at global or system or local (repo) level<ul> <li><code>~/.gitconfig</code> global</li> <li><code>./.gitconfig</code> local in repo</li> </ul> </li> <li>username and email are required to be correctly set locally as they are written in each commit (who did it?). This also helps to associate correct account when pushed to remote.</li> <li>format is <code>git config --flag name.key value</code></li> </ul> <ul> <li>read config<ul> <li><code>git config user.name</code> shows name  </li> <li><code>git config user.email</code> shows email</li> <li><code>git config --list --global</code> get all global options, --list or -l</li> <li><code>git config --list --local</code> get all local options</li> <li><code>git config --get remote.origin.url</code> - remote URL, --get is optional</li> </ul> </li> </ul> <ul> <li>write config<ul> <li><code>git config --global user.name \"Your Name\"</code> sets the user name in global file</li> <li><code>git config user.name \"Your Name\"</code> sets user name in local repo file</li> <li><code>git config --global credential.helper 'cache --timeout=72000'</code> caches. so enter credentials once every 20 hours</li> <li><code>git config --global credential.helper store</code> - stores the username and password in store utility</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/git/#operations","title":"Operations","text":""},{"location":"1-Software-Engineering/git/#read-local-repo","title":"Read Local Repo","text":"<ul> <li><code>git status</code> - current local branch and changes</li> <li><code>git branch</code> - local branches</li> <li><code>git branch -r</code> - remote branches</li> <li> <p><code>git branch -a</code> - all, local and remote branches</p> <ul> <li> <p>output</p> <pre><code>* PRJ-454\ndevelop\nremotes/origin/PRJ-454\nremotes/origin/PRJ-508\nremotes/origin/HEAD -&gt; origin/develop\nremotes/origin/origin/develop\n</code></pre> </li> </ul> <ul> <li>first two are local and then remotes, see <code>HEAD</code> points to one of the remote branch, this is checkout and acts as default.</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/git/#write-local-repo","title":"Write Local Repo","text":"<ul> <li>create repo<ul> <li><code>git clone https://...git</code> - clone remote repository</li> <li><code>git init</code> - start repository local</li> </ul> </li> </ul> <ul> <li>commits<ul> <li><code>git add --all</code></li> <li><code>git commit -m \"Initial Commit\"</code></li> </ul> </li> </ul> <ul> <li>remotes add/set<ul> <li><code>git remote add origin https://...git</code> add a remote to existing local repo</li> <li><code>git remote set-url origin https://...git</code> update remote, change to new</li> </ul> </li> </ul> <ul> <li>branch/pull<ul> <li><code>git checkout -b &lt;new-branch&gt;</code> - creates new-local-branch and checksout. It has no upstream to track.</li> <li><code>git checkout &lt;branch-name&gt;</code> - checksout existing-local-branch</li> <li><code>git checkout head</code> - checksout detached default branch</li> <li><code>git checkout HEAD</code> - checksout default branch, usually master.</li> <li><code>git branch -u origin/remote-branch-name</code> to set-upstream on current-local-branch to track. remote-branch-name should exist.</li> <li><code>git branch -u origin/remote-branch-name local-branch-name</code> to set upstream on another-local-branch.</li> <li><code>git pull</code> - downloads changes from remote to current-local-branch</li> <li><code>git pull origin remote_branch_name</code> - pulls an existing remote branch to local repository, local branch with same name should exist, else do <code>git checkout -b &lt;new-branch&gt;</code></li> <li>If you want to create a new branch to retain commits you create, you may do so (now or later) by using -c with the switch command. Example:<ul> <li><code>git switch -c &lt;new-branch-name&gt;</code></li> </ul> </li> </ul> </li> </ul> <ul> <li>merge - changes from one branch to another, say from <code>hotfix</code> to <code>master</code><ul> <li><code>git checkout branch-merge-into</code> - master if you have to merge changes into master</li> <li><code>git merge branch-merge-from</code> - say hotfix</li> <li><code>git rebase master</code> - if you have new changes in master that you want in your branch. more here.</li> <li>it can go smooth or can have conflicts, then resolve conflicts</li> <li>more details here</li> </ul> </li> </ul> <ul> <li>stash<ul> <li>stash means keep safely. When you have to switch from branch A to B but not commit changes in branch A, then stash changes in A, switch to B, do work, back to A, then stash pop to return to your uncommited changes.</li> <li><code>git stash</code> on branch A, to not commit but keep changes safely</li> <li><code>git checkout B</code> - do changes, commit.. push.. whatever</li> <li><code>git checkout A</code></li> <li><code>git stash pop</code> - to return your uncommited changes in A.</li> <li>more here</li> </ul> </li> </ul> <ul> <li>delete<ul> <li><code>git branch -d my-branch-name</code> - use <code>-D</code> to force delete</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/git/#read-remote-repo","title":"Read Remote Repo","text":"<ul> <li><code>git remote show origin</code> all the information about a remote called origin. Output:<ul> <li>fetch and push URL</li> <li>All remote branches, their tracking status and HEAD branch</li> <li>who pulls from whom</li> <li>who pushes to whom<pre><code>* remote origin\nFetch URL: URL/user/repo.git\nPush  URL: URL/user/repo.git\nHEAD branch: master\nRemote branches:\n  PRJ-001 tracked\n  PRJ-000 stale (use 'git remote prune' to remove)\nmaster  tracked\nLocal branches configured for 'git pull':\n  PRJ-001 merges with remote PRJ-001\n  master  merges with remote master\nLocal refs configured for 'git push':\n  PRJ-001 pushes to PRJ-001 (up to date)\nmaster  pushes to master  (up to date)\n</code></pre> </li> </ul> </li> </ul> <ul> <li><code>git fetch</code> - reads from remote if changes are available to pull, does not pull</li> </ul>"},{"location":"1-Software-Engineering/git/#write-remote-repo","title":"Write Remote Repo","text":"<ul> <li><code>--set-upstream</code> or <code>-u</code> to set upstream</li> <li><code>git push</code> writes current-local-branch to remote<ul> <li><code>git push -u origin &lt;local-branch-name&gt;</code> - sets upstream as origin/local-branch-name and pushes current-local-branch to remote git. New remote-branch \"local-branch-name\" is created, if not exists.</li> <li><code>git push -u origin local-branch:remote-branch</code> - uses different branch names. Creates new on remote if does not exist.<ul> <li>Output <code>Branch 'local-branch' set up to track remote branch 'remote-branch' from 'origin'.</code></li> </ul> </li> <li><code>git push -u origin HEAD</code> need not write</li> <li><code>git push -u origin</code> - sets upstream as origin and pushes current-local-branch to remote.</li> </ul> </li> <li><code>git push origin</code> pushes all branches to remote</li> </ul>"},{"location":"1-Software-Engineering/git/#pull-requests","title":"Pull Requests","text":"<ul> <li>approvals<ul> <li><code>git checkout remote_branch_name</code> - this creates a new local branch and links remote with it.</li> </ul> </li> </ul> <ul> <li>create<ul> <li>you can create pull request when your branch (source) is ahead of the destination branch, else pull and merge destination.</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/git/#how-to-clone-a-repository-from-githubcom","title":"How to clone a repository from GitHub.com","text":"<ul> <li><code>git clone https://github.com/YOUR-USERNAME/YOUR-REPOSITORY</code></li> <li>eg, <code>git clone https://github.com/miguelgrinberg/microblog.git</code></li> <li>This will bring all the files from remote to local directory with git repository on local folder.</li> <li>Now if you have permission to commit to this repo then you can authenticate to push, else change the remote to another repo that you can push to.</li> </ul>"},{"location":"1-Software-Engineering/git/#guide-how-to-sync-when-network-is-restricted","title":"Guide - How to sync when network is restricted","text":"<ul> <li>Idea is to use following branches on local:<ul> <li><code>master</code> - this will have files from remote and updated to last merged activity. Download and extract here.</li> <li><code>ofc</code> - branch moves ahead with updates in local environment</li> <li><code>ofc_masked</code> branch having only files that can go remote</li> <li><code>zip</code> - download and extract zip from remote when you have to merge</li> </ul> </li> </ul> <ul> <li>Merge process</li> </ul> <pre><code># in local on branch ofc, commited\ngit checkout -b ofc_masked # create branch\n# delete internal files, commit\ngit add .\ngit commit -m 'ofc_masked for diff'\ngit checkout -b zip\nrm -rf . # delete all \n# then extract zip downloaded from remote\ngit add .\ngit commit -m \"remote for diff\"\ngit diff ofc_masked zip &gt; diff.patch\n\n# on remote\n# create new branch in remote and apply patch\ngit checkout -b master_patched\n\"C:\\Program Files\\Git\\usr\\bin\\patch.exe\" -p1 &lt; diff.patch\n# check manually for `*.orig` files\n# merge to master\ngit checkout master\ngit merge master_patched\ngit push\n\n# download and extract in master on local\n# git diff --no-prefix ofc_masked zip &gt; diff.patch # for this\n# \"C:\\Program Files\\Git\\usr\\bin\\patch.exe\" -p0 &lt; diff.patch # use this\n</code></pre> <ul> <li>Init or after merge, on local - auto<ul> <li>checkout master, delete all, download and extract remote</li> <li>checkout ofc, <code>git rebase master</code></li> <li>do manual merge conflicts, <code>git add .</code></li> <li><code>git rebase --continue</code></li> </ul> </li> </ul> <ul> <li>Init or after merge, on local - manual<ul> <li>download and unzip to master</li> <li>backup internal folder from <code>ofc</code></li> <li>create <code>ofc</code> branch from master and add internal folder</li> <li>delete all from <code>zip</code> and <code>ofc_masked</code></li> </ul> </li> </ul> <p>Link - https://gist.github.com/nepsilon/22bc62a23f785716705c</p>"},{"location":"1-Software-Engineering/git/#guide-git-local-to-remote-basics","title":"Guide - Git Local to Remote Basics","text":""},{"location":"1-Software-Engineering/git/#setup-git","title":"Setup Git","text":"<ul> <li>On any folder, do this once</li> <li>eg, <code>mkdir myProject</code> then <code>cd myProject</code></li> <li><code>git init</code> this will create a local git repository on your local drive. Now if you need to add this to a remote git repository, for example, a repository on github.com or bitbucket then you need to add remote to this folder.</li> </ul> <p>Now once you have written your code, you can add and commit new code to local git:</p>"},{"location":"1-Software-Engineering/git/#add-and-commit-code","title":"Add and Commit code","text":"<ul> <li><code>git add .</code> adds all files to git. To add one file, pass filename.</li> <li><code>git diff</code> shows changes made to files.</li> <li><code>git commit -m \"Message\"</code> commits to git with message.</li> <li>optional, <code>cat .gitignore</code> add files that you want git to ignore</li> </ul>"},{"location":"1-Software-Engineering/git/#add-remote","title":"Add Remote","text":"<ul> <li>Create a new repository on GitHub.com</li> <li>on your local folder, <code>git remote add  [name] [url]</code> will add remote. Here, <code>name</code> can be origin and <code>url</code> is https/ssh url of git repo created online on GitHub.com. Use SSH if you have SSH authentication setup.</li> <li>Once remote is added to your local git then you can push or pull the files based on the commands below.</li> </ul>"},{"location":"1-Software-Engineering/git/#syncing-local-and-remote","title":"Syncing local and remote","text":"<ul> <li><code>git pull</code> pulls updates from remote to local</li> <li><code>git push</code> pushes the committed changes from local to remote. We can also specify remote name and branch here. eg:<ul> <li><code>git push -u origin master</code>.</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/git/#rename-git-branch","title":"Rename git branch","text":"<ul> <li><code>git branch --move main master</code> - moves main to master, <code>-m</code> is same as <code>--move</code></li> <li><code>git push -u origin master</code> - pushed master to remote as master (new on remote if not exists)</li> <li><code>git branch -a</code> - to view all branches</li> <li>finally make <code>master</code> as default on remote and delete <code>main</code>.</li> <li>or simply rename on github.com.</li> </ul>"},{"location":"1-Software-Engineering/git/#ssh-authentication-to-push-to-remote","title":"SSH Authentication to push to remote","text":"<p>You can connect to GitHub using the Secure Shell Protocol (SSH), which provides a secure channel over an unsecured network. It can help connect one machine to another using keys and thus avoiding to provide username and password/token on each request. <code>id_rsa.pub</code> is default public key.</p> <ul> <li>if <code>~/.ssh/id_rsa.pub</code> exists do <code>cat ~/.ssh/id_rsa.pub</code> else generate SSH Key <code>ssh-keygen</code>, passphrase is optional.</li> <li>copy the content, Open GitHub, click your profile icon, settings, SSH and GPC Keys, Click on the new ssh key button.</li> <li>enter any title and key that you copied</li> <li>more - https://docs.github.com/en/authentication/connecting-to-github-with-ssh</li> </ul> <p>Checking</p> <ul> <li>Check using <code>ssh -T git@github.com</code></li> <li>Output should say <code>Hi &lt;user_name&gt;! You've successfully authenticated, but GitHub does not provide shell access.</code></li> </ul> <p>Fixing SSH issue</p> <ul> <li>error - <code>ssh: connect to host github.com port 22: Connection refused</code></li> <li>change ssh config to use new url and port, Override SSH settings <code>gedit ~/.ssh/config</code> and add</li> </ul> <pre><code># Add section below to it\nHost github.com\n  Hostname ssh.github.com\n  Port 443\n</code></pre> <ul> <li>save and try again.</li> <li>Change your git remote to use SSH URL instead of HTTPS <code>git remote set-url origin git@github.com:YOUR-USERNAME/REPO-NAME.git</code></li> </ul>"},{"location":"1-Software-Engineering/git/#get-and-set-remotes","title":"Get and Set Remotes","text":"<ul> <li><code>git remote -v</code> do on a folder to check remotes added.</li> <li><code>git remote get-url --all REMOTE-NAME</code> to see URL of remote.</li> <li><code>git remote set-url origin https://github.com/YOUR-USERNAME/YOUR-REPO.git</code> to update remote on a folder.</li> </ul>"},{"location":"1-Software-Engineering/git/#handling-conflicts","title":"Handling Conflicts","text":"<p>If you push to git from two different repositories then there may be conflict. eg, you push from mac repo and a cloud repo or ubuntu repo. To handle conflict:</p> <ul> <li>Open conflicted file in editor and look for <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code> .</li> <li>You'll see the changes from the HEAD or base branch (github usually) after the line <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code></li> <li><code>========</code>, it divides your changes from the other branch as <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;YOUR_BRANCH_NAME</code></li> <li>You can decide if you want keep your branch changes or not. If you want to keep the changes what you did, delete the conflict marker they are, <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;</code> and then do a merge.</li> <li>Once done, <code>add commit push</code> :)</li> </ul>"},{"location":"1-Software-Engineering/git/#version-controlling-in-git","title":"Version controlling in GIT","text":"<p>You can see previous versions of file in your git repository.</p> <ul> <li>to see the checkins done</li> </ul> <pre><code>&gt; git reflog\n044cf0e (HEAD -&gt; master) HEAD@{0}: commit: updates\naae1995 HEAD@{1}: commit (initial): first commit\n</code></pre> <ul> <li><code>git show HEAD@{1}:path/to/file.ext</code> show file on terminal</li> <li>press down arrow to navigate and <code>q</code> to quit</li> </ul> <p>or</p> <ul> <li><code>git show -1 filename</code> - shows difference with last revision</li> <li>use -1 or -2 or -3 and so on for going into history.</li> </ul>"},{"location":"1-Software-Engineering/git/#adding-rsa-for-password-free-sync-on-mac","title":"Adding RSA for password free sync on Mac","text":"<p>GitHub is excellent for code repositories online to share work, collaborate or keep a backup.</p> <p>I have followed an excellent post by Karl Broman on the same. To summaries the flow:</p> <ul> <li>Install git on local drive.</li> <li>Setup RSA for SSL: RSA is used for making safe authentications via SSL.</li> <li>Setup GitHub Account: You will get an online space to upload your code with version controlling.</li> </ul>"},{"location":"1-Software-Engineering/git/#todo","title":"Todo","text":"<ul> <li> - Merge guide to operations</li> </ul>"},{"location":"1-Software-Engineering/js-ecma6-notes/","title":"ECMA 6+","text":"<p>ECMAScript is a JavaScript standard meant to ensure the interoperability of web pages across different web browsers.</p> <p>ECMA 6 or ES 6 or ECMAScript 2015, added new feature to javascript which are highlighted below.</p>"},{"location":"1-Software-Engineering/js-ecma6-notes/#new-changes-in-es6","title":"New Changes in ES6","text":"<p>Some changes in ES6 compared to ES5</p>"},{"location":"1-Software-Engineering/js-ecma6-notes/#variables","title":"Variables","text":"<p><code>let</code> is used to allow block scope of variables.</p> <p><code>const</code> is used to define a fixed value to variable, if it changes, it throws error and does not allow to change.</p> <p>Template strings are used to print formatted strings. use <code>Name is $(fName)</code>, here fName is a variable. it cna be multiline too.</p> <pre><code>let greeting = `Hello, ${name}!`;\n</code></pre>"},{"location":"1-Software-Engineering/js-ecma6-notes/#functions","title":"Functions","text":"<p><code>for ... of</code> new for loop.</p> <pre><code>for (name of names) {\nconsole.log(name)\n}\n</code></pre> <p><code>new Symbol()</code> can be added to an object (dict) to give it a unique identifier that never conflicts with its other keys.</p> <p><code>new Map()</code> is new data type that can be used to hold key and value of any type, we can have non-string keys. We can mix the data types. both key and value can be value or key. it is iterable in order of insersion.</p> <p><code>new Set()</code> have unique values. it has index 0,1...n.</p> <p><code>...</code> is spread operator and is used to flatten an array.</p> <p>Object's key/values can be functions as well. In this case objects behave as class having static instance.</p> <p>Desctucturing - If in function argumnet we see <code>{}</code> thats destructuring of object. We can only recieve key of object using this syntax. Eg, <code>function App ( {emp} ) {...}</code></p> <pre><code>// destructuring array\nconst [a,b] = [1,2]; // a=1, b=2\n// destructuring object\nconst {p,q} = {p:1,q:2} // use same key name\n// p=1, q=2\n</code></pre>"},{"location":"1-Software-Engineering/js-ecma6-notes/#import-and-export","title":"Import and Export","text":"<p>Now you can import functions from modules that export it. This is more robust dependency management compared to using <code>&lt;script&gt;</code> tag.</p> <p>A JavaScript module is a JS file. It can have a function with <code>export</code> to make use of it in another file. Or import entire JS file.</p> <pre><code>export GRAVITY = 9.81;\nexport default function abc() {\nconsole.log('from abc in file1.js !');\n}\n</code></pre> <p>Another file can import it. As it is <code>default</code>, it can be imported with any name.</p> <pre><code>import abc from './file1.js';\nimport { GRAVITY } from './file1.js';\nimport './index.css';\n</code></pre> <p>Provide relative path of file (module). <code>.js</code> is optional. <code>index.css</code> has no export and hence entire file is imported without using <code>from</code> keyword.</p> <p>Other way is to use library, like <code>react</code>. You can import without absolute path. <code>Module</code> is a unit of software that is basically a file that you can refer. It usually has variables and functions. <code>Library</code> is collection of modules that is distributed as <code>package</code> and is managed by a manager like npm or pip. Library has multiple files.</p> <pre><code>import React from 'react';\n</code></pre>"},{"location":"1-Software-Engineering/js-ecma6-notes/#arrow-functions","title":"Arrow Functions","text":"<p><code>=&gt;</code> arrow funcitons.</p> <pre><code>let funcName = (arg1, arg2) =&gt; {\nstatement1;\nreturn statement2;\n}\n</code></pre> <p>If there is one argument then remove the parantheses brackets, if there is only one statement the remove the curly barckets and the return keyword. Eg,</p> <pre><code>const square = x =&gt; x * x; // no  ()\nconst mult = (x, y) =&gt; x * y; // no {}\nconst mult = (x, y) =&gt; {\nconst result = x * y;\nreturn result;\n};\ndata.map(element =&gt; return (console.log(element))\n);\n</code></pre> <p><code>map</code> is function of <code>Array</code> class.</p> <p><code>generator</code> functions can be used to add a pause to execution of function and make it execute in parts using <code>yield</code> keyword. That is a funciton can yield many outputs or returns. It can be iterated calling <code>funcName.next()</code></p>"},{"location":"1-Software-Engineering/js-ecma6-notes/#promises-and-asynchronous","title":"Promises and Asynchronous","text":"<p>Promises and Asynchronous behaviour - Async means that there is delay in response when requested. A promise is a proxy object that is returned to the caller of an asynchronous operation running in the background. This object can be used by the caller to keep track of the background task and obtain a result from it when it completes.</p> <p>In JS code, promise is executed in background and the execution moves to next statement. Later promise can either resolve or reject and the chained methods gets executed.</p> <p>A Promise is in one of these states:</p> <ul> <li>pending: initial state, neither fulfilled nor rejected.</li> <li>fulfilled: meaning that the operation was completed successfully.</li> <li>rejected: meaning that the operation failed.</li> </ul> <p>When we define then Promise takes a callBackFunction as an argument.</p> <p><code>myPromiseObj.then(funcName() {}</code> anything in this funcName is passed as <code>resolve</code> to Promise.</p> <p>This object can be used by the caller to keep track of the background task and obtain a result from it when it completes. We can use <code>then</code> in chain to execute one func on top of other.</p> <pre><code>const myPromise = new Promise((resolve, reject) =&gt; {\nsetTimeout(() =&gt; {\nresolve('foo');\n}, 300);\n});\nmyPromise\n.then()\n.catch(e =&gt; console.log(e)); // prints error if \n// Example\nfetch('http://example.com/data.json') // returns apromise\n.then(r =&gt; r.json()) // output of promise is passed to r\n.then(data =&gt; console.log(data)) // chained functions\n.catch(error =&gt; console.log(`Error: ${error}`)); // Error cached\n</code></pre> <p>This is good, but all execution has to be chained which makes it different than a normal function. To make the syntax same as normal funciton we can use <code>async... await</code></p>"},{"location":"1-Software-Engineering/js-ecma6-notes/#async-and-await","title":"Async and Await","text":"<p>Async/Await - we can define an async function, which executes a Promise(), and then await until the promise is resolved. This makes synchronous execution for a asynchronous call.</p> <pre><code>async function f() {\nconst r = await fetch('https://example.com/data.json');\nconst data = await r.json();\nconsole.log(data);\n}\n</code></pre> <p>Error handling can be done using <code>try.. catch</code> block in this.</p>"},{"location":"1-Software-Engineering/js-ecma6-notes/#classes","title":"Classes","text":"<p>Now you can use classes in ES6.</p>"},{"location":"1-Software-Engineering/js-ecma6-notes/#jsx-javascript-xml","title":"JSX - JavaScript XML","text":"<p>This is not part of ES6, but is an extension to make it easier to use HTML in JavaScript. It lets us write HTML inline and this templates are eaisier to maintain. More in [[React]]</p> <p>Links</p> <ul> <li>Modern JavaScript - https://blog.miguelgrinberg.com/post/the-react-mega-tutorial-chapter-1-modern-javascript</li> <li>Learning ECMAScript 6+ (ES6+) - https://www.linkedin.com/learning/learning-ecmascript-6-plus-es6-plus/using-modern-javascript-today</li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/","title":"Linux Terminal","text":"<p>Here are some basic understandings and commands that can be used on UNIX terminal and eventually on Mac.</p>"},{"location":"1-Software-Engineering/linux-terminal/#mac-specific","title":"Mac Specific","text":""},{"location":"1-Software-Engineering/linux-terminal/#homebrew","title":"Homebrew","text":"<ul> <li>package manager for mac,<ul> <li>cask are usually GUIs apps like Sublime.</li> <li>formulae are packages, CLIs, like node.</li> </ul> </li> </ul> <p>Brew Global Commands:</p> <ul> <li><code>brew update</code> - Update brew and cask list, not packages</li> <li><code>brew upgrade</code> -  Upgrade all packages</li> <li><code>brew list</code> - List installed packages and casks</li> <li><code>brew outdated</code> - List outdated packages?</li> <li><code>brew doctor</code> - Diagnose brew issues</li> <li><code>brew cleanup</code> - cleans all packages</li> <li><code>brew services list</code>- lists all services installed</li> </ul> <p>Brew Commands:</p> <ul> <li><code>brew install git</code> -  Install a package</li> <li><code>brew uninstall git</code> -  Remove/Uninstall a package</li> <li><code>brew upgrade git</code> -  Upgrade a package</li> <li><code>brew switch git 2.5.0</code> -  Change versions</li> <li><code>brew list --versions git</code>  See what versions you have</li> <li><code>brew cleanup git</code> Remove old versions</li> </ul> <p>Brew Cask (GUI) commands:</p> <ul> <li><code>brew install --cask firefox</code> Install the Firefox browser</li> <li><code>brew list --cask</code>  List installed applications</li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#others","title":"Others","text":"<p><code>diskutil list</code> - lists all disks</p> <p>Format a disk from Mac terminal:</p> <ul> <li><code>diskutil eraseDisk FILE_SYSTEM DISK_NAME DISK_IDENTIFIER</code></li> <li>eg: <code>diskutil eraseDisk FAT32 VY_Disk /dev/disk2</code> or use ExFAT</li> </ul> <ul> <li><code>/Volumes/PenDrive</code> location of usb mounts</li> </ul> <p>Copy to clipboard</p> <ul> <li><code>$ pbcopy &lt; my_filename.ext</code> it copies the content of file to clipboard.</li> <li>It is helpful to quickly copy RSA key to clipboard which you need to paste on, may be, GitHub.</li> </ul> <p>Androids</p> <ul> <li><code>~/.android</code> - google utility folder</li> <li><code>avdmanager list avd</code> - lists all android virtual devices installed.</li> </ul> <p>Uninstalling: Usually check for following dirs and remove:</p> <ul> <li><code>sudo rm /usr/local/mypkg</code></li> <li><code>sudo rm -rf /usr/local/var/mypkg</code></li> <li><code>sudo rm -rf /usr/local/mypkg*</code></li> <li><code>sudo rm -rf /Library/StartupItems/mypkg*</code></li> <li><code>sudo rm -rf /Library/PreferencePanes/MyPkg*</code></li> <li><code>rm -rf ~/Library/PreferencePanes/MyPkg*</code></li> <li><code>sudo rm -rf /Library/Receipts/mypkg*</code></li> <li><code>sudo rm -rf /Library/Receipts/MyPkg*</code></li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#ubuntu-specific","title":"Ubuntu Specific","text":"<p>Ubuntu is debain based os, others are Mint, Elementary and PoP OS.</p> <p>Debain uses dpkg packaging system, for install/uninstall software.</p> <p>Packages are maintained in repositories, Main, Universe, Restricted and Multiverse.</p> <ul> <li><code>sudo add-apt-repository universe</code> to enable a repo.</li> </ul> <p>PPA - Personal Package Archive - allows application developers to create their own repositories to distribute.</p> <ul> <li><code>sudo add-apt-repository ppa:mkusb/ppa</code> add a ppa repo</li> </ul> <p>APT - Advanced Package Tool is CLT UI that works with core libraries to handle the installation and removal of software on Debian, Ubuntu. IT manages dependencies, config files and upgrades/downgrades.</p> <p><code>apt-get</code> performs installation, search, updates to pkg available on system. works with <code>sudo</code> only.</p> <p><code>sudo apt-get update</code> - updates local copy of packages database. The result has :</p> <ul> <li>Hit: no change in pkg</li> <li>Get: update available, downloads details but not the update</li> <li>Ign: ignores.</li> </ul> <p><code>sudo apt-get upgrade</code> updates core system and apps installed. For one package update <code>sudo apt-get upgrade [package_name]</code>.</p> <p><code>sudo apt-get install [pkg1] [pkg2]</code> if you know the name of apps.</p> <p><code>sudo apt-get remove [package_name]</code> to uninstall. but kepps config files.</p> <p><code>sudo apt-get autoremove</code> cleans up unwanted pkg.</p> <p><code>apt list --installed</code> see all that's installed.</p> <p>apt=most common used command options from apt-get and apt-cache. It is high level wrapper on old apt-get. Use apt for better UI and info like summary and progress bar.</p> <p>Install a <code>.deb</code> file, eg, Chrome:</p> <ul> <li><code>sudo dpkg -i /path/to/foo.deb</code> installs.</li> <li><code>sudo apt-get install -f</code> fix-broken dependencies.</li> </ul> <p>Or simply use below to install with dependencies</p> <ul> <li><code>sudo apt install ./name.deb</code></li> </ul> <p><code>dpkg</code> does not handle dependency, while <code>apt</code> does. apt under the hood uses dpkg.</p>"},{"location":"1-Software-Engineering/linux-terminal/#first-steps","title":"First Steps","text":"<p>Do following in a new install</p> <ul> <li>update and upgrade <code>sudo apt update &amp;&amp; sudo apt upgrade</code></li> <li>codecs flash and fonts <code>sudo apt install ubuntu-restricted-extras</code></li> <li>vlc - <code>sudo apt install vlc</code></li> <li>chrome <code>wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb</code> then <code>sudo dpkg -i google-chrome-stable_current_amd64.deb</code></li> <li>more - https://itsfoss.com/things-to-do-after-installing-ubuntu-20-04/</li> </ul> <p>Clean up</p> <ul> <li>Delete apps - <code>sudo apt purge thunderbird</code></li> <li>remove sw dependencies <code>sudo apt autoremove</code></li> <li>remove partially installed packages <code>sudo apt autoclean</code></li> <li>remove cache <code>sudo apt clean</code></li> </ul> <p>Speed up</p> <ul> <li>disable animations <code>gsettings set org.gnome.desktop.interface enable-animations false</code></li> </ul> <p>Dev Softwares</p> <ul> <li>sublime <code>sudo snap install sublime-text --classic</code></li> <li>vs code <code>sudo snap install code --classic</code></li> </ul> <p>Install Git and Gh:</p> <ul> <li>install git and essentials <code>sudo apt-get install build-essential procps curl file git</code></li> <li>set up git - <code>git config --global user.name \"YOUR NAME\"</code></li> <li>set up git - <code>git config --global user.email \"YOUR EMAIL ADDRESS\"</code></li> </ul> <p>Install Jupyter notebook, see Python Notes https://iyadavvaibhav.github.io/python-notes/</p> <p>Install nsepa and Citrix Workspace:</p> <ul> <li><code>wget http://ftp.br.debian.org/debian/pool/main/n/network-manager/libnm-util2_1.6.2-3+deb9u2_amd64.deb http://ftp.br.debian.org/debian/pool/main/n/network-manager/libnm-glib4_1.6.2-3+deb9u2_amd64.deb</code> download debs</li> <li><code>sudo apt install ./libnm-util2_1.6.2-3+deb9u2_amd64.deb ./libnm-glib4_1.6.2-3+deb9u2_amd64.deb</code> install the debs downloaded</li> <li>Download .deb file from Citrix, amd 64</li> <li><code>cd ~/Downloads</code></li> <li><code>sudo dpkg -i icaclient_21.4.0.11_amd64.deb</code></li> <li><code>sudo apt-get install -f</code></li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#others_1","title":"Others","text":"<ul> <li><code>lsblk</code> lists disk</li> </ul> <p>Check graphics card installed</p> <ul> <li>check hardware using lshw (list hardware) is a small Linux/Unix tool which is used to generate the detailed information of the system's hardware configuration from various files in the /proc directory. E.g. to see graphics driver - <code>sudo lshw -c video</code></li> <li>check loaded modules using lsmod - it shows which loadable kernel modules are currently loaded. <code>lsmod | grep radeon</code></li> <li>The glxinfo program shows information about the OpenGL and GLX implementations running on a given X display. <code>sudo apt install mesa-utils</code> and <code>glxinfo -b</code></li> <li>Check boot message for graphics card in use <code>dmesg | grep -i radeon</code></li> </ul> <p>Windows on Linux</p> <ul> <li><code>sudo apt-get install playonlinux</code></li> <li>installs wine too, 32 bit</li> <li>to install a program, create a virtual machine and install it.</li> <li>to install nfsmw<ul> <li>create a machine, 32bit</li> <li>add drivers dcdx9 and vcrun6</li> <li>more on install https://www.youtube.com/watch?v=lUqU_uf-o9E</li> <li>more on download https://www.youtube.com/watch?v=no8-fB4MX00&amp;t=1s</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#users-and-groups","title":"Users and Groups","text":"<p>List all users</p> <ul> <li><code>getent passwd</code></li> <li><code>compgen -u</code></li> <li><code>cut -d: -f1 /etc/passwd</code></li> </ul> <p>List all groups</p> <ul> <li><code>compgen -g</code></li> </ul> <p>Add user to group - <code>sudo adduser username group</code></p>"},{"location":"1-Software-Engineering/linux-terminal/#os-setup-and-virtualization","title":"OS Setup and Virtualization","text":"<p>USB Installation</p> <ul> <li>works like a charm,</li> <li>make a bootable live usb/cd - https://linuxhint.com/create_bootable_linux_usb_flash_drive/</li> <li>boot from it and install to another USB - https://www.fosslinux.com/10212/how-to-install-a-complete-ubuntu-on-a-usb-flash-drive.htm</li> <li>space and drive speed is a issue.</li> <li>Clean grub of mac - https://apple.stackexchange.com/questions/337189/unwanted-grub-on-macos-high-sierra</li> <li>Tripe boot mac - https://www.youtube.com/watch?v=B0EuYHFeLAA</li> <li>First steps on Ubuntu - https://www.youtube.com/watch?v=GrI5c9PXS5k</li> </ul> <p>Virtual box add on:</p> <ul> <li><code>sudo apt update</code></li> <li><code>sudo apt install virtualbox-guest-dkms virtualbox-guest-x11 virtualbox-guest-utils</code></li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#linux-ways","title":"Linux Ways","text":"<ul> <li><code>alias vynote=\"subl ~/path/to/file/notepad.txt\"</code> add to <code>.bash_profile</code> to make shortcut</li> </ul> <p>ENVs:</p> <ul> <li><code>source activate [path to env]</code> activates env</li> <li><code>source deactivate</code> deactivates enn</li> </ul> <p>Emac Basic</p> <ul> <li>Press <code>ctrl + c + x</code> to save and exit a file.</li> </ul> <p>Other</p> <ul> <li>everything global is installed in <code>/usr/local/bin/</code></li> <li>use PostMan for http requests to REST routes</li> </ul> <ul> <li><code>rmdir</code> removed empty dir</li> <li><code>rm -rf</code> removes non/empty dir and files forcefully</li> <li><code>rm</code> removes files not directories.</li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#youtube-dl","title":"youtube-dl","text":"<ul> <li><code>youtube-dl --extract-audio --audio-format mp3 -o \"%(title)s.%(ext)s\" http://www.youtube.com/watch?v=fdf4542t5g</code> -o is --output of filename.</li> </ul>"},{"location":"1-Software-Engineering/linux-terminal/#mobile-linux","title":"Mobile Linux","text":"<p>Everything related to iOS and Android Linux.</p> <p>Install Termux App on Android.</p> <pre><code>termux-setup-storage\ntermux-change-repo\npkg update\n\npkg install git\ngit --version\n\npkg install python\n\npkg install openssl\n\npip install --upgrade youtube-dl\n\nyoutube-dl -i PLyAyDdlMr3GOHFBt0IzgvED-n3uhwyrhd\n</code></pre> <p>Install on <code>a-Shell</code> iOS App</p> <pre><code>cd ~/code\nwget -qO- http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86/apk-tools-static-2.10.6-r0.apk | tar -xz sbin/apk.static &amp;&amp; ./sbin/apk.static add apk-tools &amp;&amp; rm sbin/apk.static\napk add python3\napk add py3-pip\npip install youtube-dl\n</code></pre>"},{"location":"1-Software-Engineering/linux-terminal/#links","title":"Links","text":"<ul> <li>cheat book - https://github.com/0nn0/terminal-mac-cheatsheet#english-version</li> </ul>"},{"location":"1-Software-Engineering/oops-python/","title":"OOPs in Python","text":"<ul> <li>Object is a Class and has<ul> <li><code>attributes</code> - variables</li> <li><code>methods()</code> - functions</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/oops-python/#instance-class-or-static-methods","title":"Instance, Class or Static Methods","text":"<ul> <li>Instance - method is specific to instance of class. First argument is <code>self</code> (referece to object) and is auto passed.</li> <li>Class - method can be called without instantiating the class. First argument is <code>cls</code> (referece to class itself) and is auto passed.</li> <li>Static - similar to class but can be called without passing <code>cls</code></li> </ul> <pre><code>class Book:\n# Class attribute, common for all instances\nkind = \"Novels\"\ndef __init__(self, row):\n# row is db record\n# instance attribute\nself.title = row.title\nself.author = row.author\nself.year = getattr(row, 'year', None) # if year is not in row\ndef age(self):\n# return age of book\n# this is per instance of book\nreturn (year_today - self.year)\n@classmethod\ndef fetch_book(cls, id):\n# fetch the row from db or api\nrow = fetch_service(id)\nobj = cls(row)\nreturn obj\n@staticmethod\ndef fetch_books():\n# fetch the row from db or api\nobjs = []\nrows = fetch_service('all')\nfor row in rows:\n# create object and add to objcts list\nobjs.append(Book(row))\nreturn objs\nbook_obj = Book.fetch_book(21) # class method\nbook_obj.age() # instance method\nbook_objects = Book.fetch_books() # static method, no auto arg passed\n</code></pre> <ul> <li>More about different class methods here on stackoverflow</li> </ul>"},{"location":"1-Software-Engineering/oops-python/#inheritance","title":"Inheritance","text":"<ul> <li>to be added</li> </ul>"},{"location":"1-Software-Engineering/oops-python/#links","title":"Links","text":"<ul> <li>RealPython OOPS - https://realpython.com/python3-object-oriented-programming/</li> </ul>"},{"location":"1-Software-Engineering/regex/","title":"Regex","text":"<p>Regex are in simple terms \"a sequence of characters that define a search pattern\"</p> <ul> <li>basic is <code>*.gif</code> where * means anything.</li> </ul> <ul> <li><code>Position</code> of search<ul> <li><code>^</code> - starts with - <code>^Simple</code> - any line that start with this</li> <li><code>$</code> - ends with - <code>park$</code> - any line that end with this</li> </ul> </li> </ul> <ul> <li><code>Frequency</code> of occurrence<ul> <li><code>*</code> - 0 or more - <code>ab*</code> a followed by zero or more b's</li> <li><code>+</code> - 1 or more - <code>ab+</code> - the letter a followed by one or more b's</li> <li><code>?</code> - 0 or 1 - ab? - zero or just one b</li> <li><code>{n}</code> - n exactly - ab{2} - the letter a followed by exactly two b's</li> <li><code>{n,}</code> - n or more - ab{2,} - the letter a followed by at least two b's</li> <li><code>{n,y}</code> - n to y occurance - ab{1,3} - the letter a followed by between one and three b's</li> </ul> </li> </ul> <ul> <li><code>Class</code> of characeters - list or range, and are case-sensitive<ul> <li>Range - <code>[a-z]</code> or <code>[A-Z]</code> or <code>[0-9]</code></li> <li>List - <code>[a,d,p,w]</code> or <code>[adpwKRM]</code> - match any single character</li> <li>Mix - <code>[A-Z2-4pw]</code> - matches range A-Z, 2-4 and literally p, and literally w</li> <li>Except - <code>[^abXyP-Q]</code> and character except what is in</li> </ul> </li> </ul> <ul> <li><code>Flags</code> to search for special types of characters without needing to list them in a range<ul> <li><code>.</code> m any character</li> <li><code>\\s</code> - whitespace - <code>\\S</code> opposite</li> <li><code>\\w</code> - word - <code>\\W</code> not a word</li> <li><code>\\d</code> - digit (number) - <code>\\D</code> not a digit</li> <li><code>\\b</code> - word boundary - <code>ate\\b</code> finds ate at end of word, eg, plate but not gates.- <code>\\B</code> not boundary</li> </ul> </li> </ul> <ul> <li>Other<ul> <li><code>\\n</code> <code>\\r</code> <code>\\t</code> <code>\\0</code> - new line, carriage, tab, null</li> <li><code>|</code> - or - <code>The (?:cat|dog) jumps</code> matches cat or dog</li> </ul> </li> </ul> <ul> <li>Regex Groups<ul> <li>In Find: you can use regex with \"capturing groups,\" e.g. <code>I want to find (group1) and (group2)</code>, using parentheses</li> <li>In Replace: you can refer to the capturing groups via $1, $2 etc.</li> <li>Eg, VS Code - to use what you found in replace use <code>$1</code>, eg, find <code>&lt;h1&gt;(.+)&lt;/h1&gt;</code>, replace <code>&lt;b&gt;$1&lt;/b&gt;</code>. Replaces <code>&lt;h1&gt;Todo&lt;/h1&gt;</code> with <code>&lt;b&gt;Todo&lt;/b&gt;</code></li> <li>more here.</li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/regex/#snippets","title":"Snippets","text":"<ul> <li>mulitline with one line <code>\\s\\n+</code> <code>\\n</code></li> <li>remove end whitespaces <code>\\s+\\n</code> <code>\\n</code></li> </ul> <ul> <li> <p>Remove single line comments // from code:</p> <ul> <li><code>\\/\\/.*$\\n</code> - Finds all single line comments starting with //.<ul> <li><code>\\/\\/</code> - string has //</li> <li><code>.*</code> - then has anything after that</li> <li><code>$\\n</code> - then matches next line as well.</li> </ul> </li> </ul> </li> </ul>"},{"location":"1-Software-Engineering/regex/#links","title":"Links","text":"<ul> <li>Check and Validate on Regex101</li> </ul>"},{"location":"1-Software-Engineering/software-diagrams/","title":"Software Diagrams","text":"<p>Diagrams are often used for plannig and sharing ideas and understanding in a group. Software engineering you can have following</p>"},{"location":"1-Software-Engineering/software-diagrams/#type-of-diagrams","title":"Type of diagrams","text":"<ul> <li>Flowcharts / Process Diagrams - Process Flow Diagram</li> <li>UMLs - Unified Modeling Language. This general-purpose modeling language helps you visualize a system\u2019s design. Can show:</li> <li>structural information (such as class diagrams),</li> <li>behavioral information (like use case diagrams), or</li> <li>display interactions (a sequence diagram).</li> <li>ORG Charts - herarchal organization mapping in parent-child form.</li> <li>ER Diagram - shows an entity\u2013relationship model which describes interrelated things of interest in a specific domain of knowledge. A basic ER model is composed of entity types (tables) and specifies relationships that can exist between entities.</li> </ul>"},{"location":"1-Software-Engineering/software-diagrams/#methodology-generalization","title":"Methodology / Generalization","text":"<ul> <li>C4model is a technique to stucturize your diagrams. It is an \"abstraction-first\" approach to diagramming software architecture. What are the 4C\u2019s?</li> <li>Context - people and system, user and app</li> <li>Container - containers in a system. app has front end, middle, db and api.</li> <li>Component - components in a container. middle has user management and loggin system.</li> <li>Code - code or physical view of components. Class diagram, ER diagram.</li> </ul>"},{"location":"1-Software-Engineering/software-diagrams/#tools-to-build","title":"Tools to build","text":"<ul> <li>Draw.io</li> <li>Visio</li> <li>LucidChart</li> </ul>"},{"location":"1-Software-Engineering/software-diagrams/#links","title":"Links","text":"<ul> <li>https://c4model.com/</li> </ul>"},{"location":"1-Software-Engineering/web-development/","title":"Web Development","text":"<p>Web development may need:</p> <ul> <li>OS and Infa - linux mostly, hosting/gcp/aws - machine connected to internet</li> <li>Web Server - Apache/NginX - connects domain to DIR/Process.</li> <li>Web Cache - optional - Squid</li> <li>Database - to store, mysql/sqlite/mongo/postgres</li> <li>Backend - lang &amp; framework - this will take requests and return response and can connect to DB.</li> <li>Frontend - is on the client side, JS, can have framework.</li> </ul> <p></p> <p>Web Servers / Proxy Servers</p> <ul> <li>Is a server application that acts as an intermediary between a client requesting a resource and the server providing that resource.</li> <li>Can help configrue DIR in case of static site and process in case of python/perl/php and use WSGI or CGI. Uses:<ul> <li>Monitoring and filtering</li> <li>Filtering of encrypted data</li> <li>Bypassing filters and censorship - Geo restriction, firewall etc</li> <li>Logging</li> <li>Improving performance</li> </ul> </li> </ul> <ul> <li>Gunicorn, is a Web Server Gateway Interface (WSGI) server implementation that is commonly used to run Python web applications.</li> </ul> <ul> <li>Apache</li> </ul> <ul> <li>NginX</li> </ul> <ul> <li>more on webserver</li> </ul> <p>Databases:</p> <ul> <li>mongo - nosql - JSON like document based</li> <li>mysql / PostgreSQL - sql</li> <li>neo4j - graph</li> </ul>"},{"location":"1-Software-Engineering/web-development/#backend","title":"Backend","text":"<p>It is the server side part of the app. It provides services which clients can request or consume.</p> <p>Frameworks and languages</p> <ul> <li>Flask - Python</li> <li>Laravel - PHP</li> <li>Elastic.js - JS</li> </ul> <p>Auth is required for all request, so decouple and make a service of it. The gateway can take req and the authenticate it or reject it. Once autheticated it can send it to the correct service.</p> <p>APIs or Headless or RESTful backend can be build when we need to completely separate client from server.</p> <ul> <li>request payload is JSON data sent with req. In GET req we don't have to send payload we just send URL params.</li> <li>avoid actions in payload. like func name in payload, instead keep action in route</li> <li>avoid doing everything in one route, eg, if not exist then create else add, instead make the actions atomic to routes.</li> <li>for huge responses, like get_orders() returning all orders with all details, add pagination or fragmentation (in microservices)</li> </ul> <p>Load Balancing or Consistent Hashing</p> <ul> <li>when requests to a server increases we need to add new servers, then redirect requests to different servers. This can be done using hashing. Hash gives a random number to a request, then that number can be used to direct a request to a particular server, eg, hash_number mod servers is the server ID, 14%4=2, so req hased as 14 goes to server 2, if we have 4 servers.</li> <li>now when we add new server, say 5, then the mod operation changes, every req gets mod of 5, this makes huge operational difference, as in there is a shift in all requests, so all cache that we built becomes useless, to avoid this, we use consistent hashing.</li> <li>more - https://www.youtube.com/watch?v=K0Ta65OqQkY</li> </ul> <p>DjangoREST vs FastAPI, ???</p> <p>WebSockets vs HTTP - Unlike req-res architecture of HTTP, in web sockets server can also send updates to client, updates are sent immediately when they are available. WebSockets keeps a single, persistent connection open while eliminating latency problems that arise with HTTP request/response-based methods. Can be used in messaging and notifications. Protocol is:</p> <ul> <li>XMPP on TCP</li> </ul> <p>Microservices - ???</p> <p>Gateway - ???</p>"},{"location":"1-Software-Engineering/web-development/#frontend","title":"Frontend","text":"<p>It makes the UI or client for an app. It can talk to API and do CRUD. It need to send authorization and access key/token to API.</p> <p>Must have features:</p> <ul> <li>Modular Layout - cards, templates</li> <li>Search</li> <li>Sort</li> <li>Filter</li> <li>Pagination</li> <li>Favourites</li> <li>Enhancements:<ul> <li>Event Bubling / Capturing</li> <li>Debouncing</li> </ul> </li> </ul> <p>Frameworks</p> <ul> <li>React</li> <li>Angular</li> <li>Vue</li> </ul> <p></p> <p>Object-Relational Mapping (ORM)is a technique that lets you query and manipulate data from a database using an object-oriented paradigm. It abstracts Object oriented code from database and hence we can switch DBs. eg, Eloquent in Laravel, SQLAlchemy is an open-source SQL toolkit and object-relational mapper for the Python programming language</p> <p>Headless is backend app with no frontend, it only has API endpoints.</p> <p>12-Factor Application - The Twelve-Factor App methodology is a methodology for building software-as-a-service applications. These best practices are designed to enable applications to be built with portability and resilience when deployed to the web. More - https://12factor.net/</p> <p>PWA - Progressive Web Apps</p> <p>Stacks:</p> <ul> <li>LAMP - Linux Apache MySql PHP</li> <li>MEAN - mongo express angular node</li> <li>MERN - mongo express react node</li> </ul> <p>What is a docker??</p> <p>FastAPI</p> <p>Flask Mega Tutorial</p> <p>Saleor - Python eCom open-source framework:</p> <ul> <li>headless ecom SDK</li> <li>can create category hierarchy</li> <li>can have attributes for products like size cost etc</li> </ul> <p>References:</p> <ul> <li>https://www.fullstackpython.com/</li> <li>https://yalantis.com/blog/tech-stack-for-web-app-development/</li> <li>https://testdriven.io/blog/fastapi-mongo/</li> </ul>"},{"location":"1-Software-Engineering/web-development/#mobile-app-development","title":"Mobile App Development","text":"<p>Data is sourced from RESTAPI or can be local storage.</p> <p>Apps can be:</p> <ul> <li>WebApp/HTML5 App - it is nothing but a webpage, optmized for mobile experience. Frameworks: Bootstrap, jQuery Mobile, Onesen UI.<ul> <li>HTML5 - Same as website but with Local Storage, Video Streaming, Drag and Drop.</li> <li>Progressive Web App - Website with Push Notifications, Offline Work, Splash Screen and Installable with icon.</li> </ul> </li> <li>Hybrid - Native container, installable, running webapp in webview in native container app. PhoneGap/Cordova can build container that can run webApp.</li> <li>Native Cross Platform - One code base, multi platform, native like most experience. React Native, Flutter, Xamarin.</li> <li>Native - Pure iOS and Android app. Different codebase. Full functionality.</li> </ul> <p>More:</p> <ul> <li>https://www.mobiloud.com/blog/native-web-or-hybrid-apps</li> </ul>"},{"location":"2-Data-Engineering/data-architecture/","title":"Data Architecture","text":"<p>Aim is to collect and store data in a way that it is optimised for reading to enable analytics and BI.</p>"},{"location":"2-Data-Engineering/data-architecture/#concepts","title":"Concepts","text":"<ul> <li>Modeling - Logical is modeling on paper/ppt. Physical is modelling on database with the data.</li> <li>Data storage can follow this journey<ul> <li>staging area where it is dump from feeds</li> <li>then 3nf schema - where it is clean and ready for joining, it is data warehouse</li> <li>then denormalised simple query for consumers, it is data mart</li> </ul> </li> <li>schema is collection of database objects (tables, views and indexes).</li> <li>3NF Schema minimizes redundancy by splitting data in multiple tables and linking them with relationships. Adding new entity is easy without effecting current applicaiton. But, this makes reading data slow as the query joins multiple tables.</li> <li>Data Warehouse can have multiple star-schema, each based on a business-process such as sales tracking or shipments. Each star-schema represents a data-mart, this can serve the BI needs. Star-schema have fraction of table compared to 3NF. 15-20 star-schema can cover all LOBs of enterprise. BI users can easily query and join multiple star-schemas as they few tables.</li> <li>Star schemas can have denormalized dimensions for easy understanding and faster data retrieval and less complex queries.<ul> <li>Most important is to consider the level of detail, grain of data.</li> </ul> </li> <li>Both 3NF and Star-schema don't contradict but can work in layers with 3NF as foundation and star-schema as access and opttimized layer.</li> </ul>"},{"location":"2-Data-Engineering/data-architecture/#data-storage-solutions","title":"Data Storage Solutions","text":"<ul> <li>Data Lake - is dumped data with no purpose</li> <li>Staging Area is a dump from feeds. It simplfies cleaning and consolidation.</li> <li>Data Warehouse - data from different sources into central store to provide single source of truth on which BI and Analysts can rely.<ul> <li>OLAP vs OLTP - Compared to OLTP (transaction processing), warehousing is read oriented, for analytics workload OLAP.<ul> <li>read oriented, vs insert/update/delete</li> <li>denormalized for reads, fully normalized for consistency</li> <li>ETL batch updates, always up to date.</li> </ul> </li> <li>Big data warehousing handling petabytes in an distributed environment. Handle 3Vs, real time, no sql, petabytes? It is ETL but at industry level,</li> </ul> </li> <li>Data Mart - usually build for single purpose, for particualr LOBs, can be physically designed or implemented logically by creating views, materialized view or summary data in warehouse (they have an overlap). It mainly focuses on a subset of data instead of complete enterprise data. They can exist as<ul> <li>Island is right from source, can be inconsistent.</li> <li>Dependent is fed from warehouse, mostly consistent.</li> </ul> </li> <li>Operation Data Store - ODS gives data warehouses a place to get access to the most current data, which has not yet been loaded into the data warehouse. Usually current day data.</li> <li>Usually - Data Lake &gt; Data Warehouse &gt; Data Mart</li> <li>Data Warehousing, data mart build, database modeling, dimentional modeling, data modeling,  - they all have a common goal to improve data retrieval (select query optimized).</li> </ul> <p>Figure: Architecture of a Data Model (with optional \"Staging Area\" and \"Data Marts\")</p> <p></p> <pre><code>flowchart LR\nds1[(Ops Sys 1)] --&gt; sa[(Staging\\nArea)]\nds2[(Ops Sys 2)] --&gt; sa\nds3[Flat Files] --&gt; sa\nsa --&gt; wh[(Warehouse\\n\\nMeta Data\\nSummary Data\\nRaw Data)]\nwh --&gt; dm1[(Purchasing\\nData Mart)]\nwh --&gt; dm2[(Sales\\nData Mart)]\nwh --&gt; dm3[(Inventory\\nData Mart)]\nu1(Analysis Users)\nu2(Reporting Users)\nu3(Mining Users)\ndm1 --&gt; u1\ndm2 --&gt; u1\ndm1 --&gt; u2\ndm2 --&gt; u2\ndm2 --&gt; u3\ndm3 --&gt; u3</code></pre>"},{"location":"2-Data-Engineering/data-architecture/#build-a-data-warehouse","title":"Build a Data Warehouse","text":"<p>This defines process to turn architecture to system deliverable</p>"},{"location":"2-Data-Engineering/data-architecture/#logical-model","title":"Logical Model","text":"<p>In Data Modelling, Logical Model is conceptual (pen &amp; paper), focus on business needs and build subject-oriented <code>schema</code></p> <ul> <li>Data Gathering - Identify the things of importance, <code>entity</code> (data item, like user, book) and its properties <code>attributes</code> (columns; like name, dob).</li> <li>Entity-Relationship Modeling - Determine how entities are related to each other, <code>relationships</code>. Determine the unique identifier for each entity record, <code>primary key</code>. It applies to OLAP, OLTP, 3NF EDW, star and snowflake.</li> <li>Determine data <code>granularity</code>, week, day, month.</li> <li>Divide data into<ul> <li>facts - numeric, transactional data, fast changing. Mostly tall table with numeric data, datetime and contains forign keys  of dimaension table which combined make composite key as its primary key.<ul> <li>Summary fact tables contain aggregated facts.</li> </ul> </li> <li>dimensions - descriptive, slow changing, known as lookup tables or reference tables. Mostly wide. It may contain hierarchies. Eg, product, customer, time. Data is kept at lowest level of detail, it can be rolled up higher level of hierarchy.</li> </ul> </li> <li>Write down all dimension and facts required. Several distinct dimensions, combined with facts, enable you to answer business questions.</li> <li>Identify the Source Data - that will feed the data mart model, that is populate the facts and dimensions.</li> <li>Design your <code>schema</code> for data mart<ul> <li>Star Schema<ul> <li>it is simple, having fact in centre and dimensions around it, just like a star, where only one join establishes the relationship between the fact table and any one of the dimension tables.</li> </ul> </li> </ul> </li> <li>Your design should result in<ul> <li>set of entitis and attributes corresponding to fact and dimentions tables.</li> <li>a model/pipeline to move data from sources to mart as facts and dimensions.</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/data-architecture/#physical-model","title":"Physical Model","text":"<p>It implemets logical model, with variations based on system parameters like memory, disk, network and software type.</p>"},{"location":"2-Data-Engineering/data-python/","title":"SQL Operations in Python","text":""},{"location":"2-Data-Engineering/data-python/#database-connections-101","title":"Database Connections 101","text":"<ul> <li>Connection should not be left open, it should be open right after write and disposed once written. It can be open and closed multiple times but never left open</li> <li>Connection object should be completely separate from business logic.</li> <li><code>with</code> performs the cleanup activity automatically. \"Basically, if you have an object that you want to make sure it is cleaned once you are done with it or some kind of errors occur, you can define it as a context manager and <code>with</code> statement will call its <code>__enter__()</code> and <code>__exit__()</code> methods on entry to and exit from the with block.\"</li> <li>more connections here  (SQLAlchemy).</li> </ul>"},{"location":"2-Data-Engineering/data-python/#pyodbc","title":"PyODBC","text":"<p>Works with most databases but not well with MSSQL+Pandas</p> <pre><code>import pyodbc\n# MS SQL Server\nconnection_url = \"driver={SQL Server};server=000Server.somedomain.com/abcinc;database=SAMPLE_DB;Trusted_Connection=yes\"\nconnection_url = \"driver={SQL Server};server=000Server.somedomain.com/abcinc;database=SAMPLE_DB;Trusted_Connection=yes\"\n# MYSQL \nconnection_url = \"DRIVER={MySQL ODBC 3.51 Driver};SERVER=localhost;DATABASE=test;USER=venu;PASSWORD=venu;OPTION=3;\"\n# DSN\nconnection_url = \"dsn=\" + \"Your DSN Name\"\n## Teradata\nconnection_url = \"DRIVER={DRIVERNAME};DBCNAME={hostname};;UID={uid};PWD={pwd}\"\nconnection = pyodbc.connect(connection_url)\nsql = \"select top 10 * from [db].[schema].[table]\"\ncursor = connection.cursor().execute(sql)\n# list of column names\ncolumns = [column[0] for column in cursor.description]\nfor row in cursor.fetchall():\nprint(row) # row is object of class row\nresults.append(dict(zip(columns, row))) # builds list of dictionary\nconnection.close()\nfx_df = pd.read_sql(query, connection)\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#sqlalchemy-connection","title":"SQLAlchemy Connection","text":"<p>Works as connection engine as well as ORM</p> <pre><code>import sqlalchemy\nconnection_url = \"mssql+pyodbc://server_name\\schema_name/database_name?driver=SQL+Server\"\n## MS SQL\nconnection_url = \"mssql+pyodbc:///?odbc_connect=\"+urllib.parse.quote('driver={%s};server=%s;database=%s;Trusted_Connection=yes')\n## Postgres\nconnection_url = \"postgresql://user:pass@server:port/database\"\nengine = sqlalchemy.create_engine(connection_url, echo=False)\nconnection = engine.connect()\nsql = \"select top 10 * from [db].[schema].[table]\"\ncursor = connection.execute(sql)\nres = cursor.fetchall()    # list of rows \nconnection.close()\n# OR -- \nwith engine.connect() as connection:\nconnection.execute(\"UPDATE emp set flag=1\")\ndf.to_sql('table_name', con=engine, schema='dbo', if_exists='append', index=False)\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#flask_sqlalchemy","title":"Flask_sqlalchemy","text":"<p>Flask wrapper for sqlalchemy</p> <pre><code>from flask_sqlalchemy import SQLAlchemy\nconnection_url = \"mssql+pyodbc://server_name\\schema_name/database_name?driver=SQL+Server\"\napp.config['SQLALCHEMY_DATABASE_URI'] = connection_url\ndb = SQLAlchemy(app)\ndb.session.execute(sql).all() # list of rows\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#flask-sqlite-sqlalchemy","title":"Flask SQLite SQLAlchemy","text":"<pre><code>import os, sqlite3\nbasedir = os.path.abspath(os.path.dirname(__file__))\nconnection_url = 'sqlite:///' + os.path.join(basedir, 'data.sqlite')\n# then same as SQLAlchemy\n</code></pre> <ul> <li>Execution - from flask shell do <code>db.create_all()</code> - creates table with schema.</li> </ul>"},{"location":"2-Data-Engineering/data-python/#pandas","title":"Pandas","text":"<ul> <li>needs a connector to database like sqlalchemy or pyodbc</li> <li><code>df_txns = pd.read_sql(sql=sql, con=conn_dvs)</code></li> <li><code>df.to_sql('table_name', con=engine)</code> - sqlalchemy</li> </ul> <ul> <li>pd write has issues<ul> <li>pyodbc lets read but not write, <code>pyodbc==4.0.35</code></li> <li>sqlalchemy lets read and write but with version <code>SQLAlchemy==1.4.46</code> with <code>pandas==1.3.5</code> as on Feb-2023.</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/data-python/#sqlite","title":"SQLite","text":"<pre><code>import sqlite3\nconnection = sqlite3.connect('database_name')\ncursor = connection.cursor()\ncursor.execute(query)\nrows = cursor.fetchall()\nconnection.commit() # for non read tasks\nconnection.close()\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#mysql-connector-python","title":"mysql-connector-python","text":"<pre><code>import mysql.connector\nconnection = mysql.connector.connect(host=host_name,user=user_name,passwd=user_password)\ncursor = connection.cursor()\ncursor.execute(query)\nconnection.commit() # for non read tasks\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#sqlalchemy-orm","title":"SQLAlchemy ORM","text":"<ul> <li>Why? - When you\u2019re working in an object-oriented language like Python, it\u2019s often useful to think in terms of objects. It\u2019s possible to map the results returned by SQL queries to objects, but doing so works against the grain of how the database works. Sticking with the scalar results provided by SQL works against the grain of how Python developers work. This problem is known as object-relational impedance mismatch.</li> </ul> <ul> <li>What?<ul> <li>The ORM provided by SQLAlchemy sits between the database and Python program and transforms the data flow between the database engine and Python objects. SQLAlchemy allows you to think in terms of objects and still retain the powerful features of a database engine.</li> <li>It is ORM for Python, has two parts<ul> <li>CORE - can be used to manage SQL from python,</li> <li>ORM - can be used in Object oriented way to access SQL from python.</li> </ul> </li> </ul> </li> </ul> <ul> <li>ORMs allow applications to manage a database using high-level entities such as classes, objects and methods instead of tables and SQL. The job of the ORM is to translate the high-level operations into database commands.<ul> <li>It is an ORM not for one, but for many relational databases. SQLAlchemy supports a long list of database engines, including the popular MySQL, PostgreSQL and SQLite.</li> <li>The ORM translates Python classes to tables for relational databases and automatically converts Pythonic SQLAlchemy Expression Language to SQL statements</li> </ul> </li> </ul> <ul> <li>Mappings - There are two types of mapping<ul> <li>Declarative - new - more like oops</li> <li>Imperative - old - less like oops</li> </ul> </li> </ul> <p>Mappings</p> <ul> <li>There are two types of mapping<ul> <li>Declarative - new - more like oops</li> <li>Imperative - old - less like oops</li> </ul> </li> </ul> <p>Mappings</p> <ul> <li>There are two types of mapping<ul> <li>Declarative - new - more like oops</li> <li>Imperative - old - less like oops</li> </ul> </li> </ul> <pre><code>from sqlalchemy import Column, Integer, String, ForeignKey, Table\nfrom sqlalchemy.orm import relationship, backref\nfrom sqlalchemy.ext.declarative import declarative_base\nBase = declarative_base()\n## Instance of Table Class, creates many to many association\nauthor_publisher = Table(\n\"author_publisher\",\nBase.metadata,\nColumn(\"author_id\", Integer, ForeignKey(\"author.author_id\")),\nColumn(\"publisher_id\", Integer, ForeignKey(\"publisher.publisher_id\")),\n)\n## Inherits Base class\nclass Author(Base):\n__tablename__ = \"author\"\nauthor_id = Column(Integer, primary_key=True)\nfirst_name = Column(String)\nlast_name = Column(String)\nbooks = relationship(\"Book\", backref=backref(\"author\"))\npublishers = relationship(\n\"Publisher\", secondary=author_publisher, back_populates=\"authors\"\n)\n</code></pre> <ul> <li>Steps<ul> <li>create the association table model, <code>author_publisher</code></li> <li>define the class model, <code>Author</code> for <code>author</code> database table</li> <li>This uses SQLAlchemy ORM features, including <code>Table</code>, <code>ForeignKey</code>, <code>relationship</code>, and <code>backref</code>.</li> </ul> </li> </ul> <ul> <li>Links<ul> <li>https://realpython.com/python-sqlite-sqlalchemy/#working-with-sqlalchemy-and-python-objects</li> <li>Flask SQLAlchemy in Flask Notes</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/data-python/#pyodbc-manual-orm","title":"PyODBC Manual ORM","text":"<pre><code># Class of table\nclass Book:\ndef __init__(self, row):\n# row is db record\nself.id = row.id\nself.title = getattr(row, 'title', None)\nself.author = getattr(row, 'author', None)\nself.year = getattr(row, 'year', 1880) # default value\n# calculated column, instance method\ndef age(self):\n# return age of book\nreturn (2022 - self.year)\n@classmethod\ndef get_book_by_id(cls, id):\nsql = f'select * from table_name where id = {str(id)}'\ncursor = conn.cursor().execute(sql)\nobjs = []\nfor row in cursor.fetchall():\nobjs.append(Book(row))\nif len(objs) &gt; 0:\nreturn objs[0] # as sending 1\nreturn None\n@classmethod\ndef get_books(cls):\nsql = select_flows_sql + f' where email = \"?\"'        # optional where clause\ncursor = conn.cursor().execute(sql, session['email']) # where clause placeholder\nobjs = []\nfor row in cursor.fetchall():\nobjs.append(Book(row))      # instantiate obj\nif len(objs) &gt; 0:\nreturn objs                 # list of objects\nreturn None\nbook_obj = Book.get_book_by_id(21) # class method\nbook_obj.age() # instance method\nbook_objects = Book.get_books() # static method, no auto arg passed\n# class of table simple code to auto set to dictionary items\nclass Post:\ndef __init__(self, row):\nfor k, v in dictionary.items():\nsetattr(self, k, v)\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#pyodbc-etl","title":"PyODBC ETL","text":"<pre><code>import pandas as pd\nimport sqlite3\n# sources\nconn_source = pyodbc.connect('dsn=' + \"Your_DSN\")\nconn_target = sqlite3.connect('../app_v2/data-dev.sqlite')\n# Incremental Load: Find IDs already in target\ndf_target_ids = pd.read_sql(sql='select id from target_table', con=conn_target)\nids_before = df_target_ids[\"id\"].values\nrecords_before = len(df_target_ids)\nprint(f\"Records present: \"+str(records_before))\n# Build where clause tuple, eg, 'not in (a,..)'\nif len(ids_before) == 0:\nids_before_tuple = '(-1)'\nelif len(ids_before_tuple) == 1:\nids_before_tuple = \"(\"+ str(df_target_ids[\"id\"].values[0]) + \")\"\nelse:\nids_before_tuple = tuple(df_target_ids[\"id\"].values)\n# Extract new IDs from source\nsql = f'SELECT distinct id, email FROM source_table where id not in {ids_before_tuple}'\ndf_new_data = pd.read_sql(sql=sql, con=conn_source)\nprint(f\"Records to be added: \"+str(len(df_new_data)))\n# Load new Data to target\ndf_new_data.to_sql(name='target_table', con=conn_target, if_exists='append', index=False)\nfinal_responses = pd.read_sql(sql='select count(id) from target_table', con=conn_target).iloc[0,0]\nprint(f\"Records added: \"+str(final_responses-records_before))\n#assert len(df_new_data) == final_responses-records_before\n</code></pre>"},{"location":"2-Data-Engineering/data-python/#fail-proof-data-read","title":"Fail proof data read","text":"<pre><code>import pyodbc\nimport logging\nimport urllib\nimport pandas as pd\nimport time\nfrom config import config # has all variables defined\ndef get_connection_string(service):\n\"\"\"\n    Returns connection string for a service. All variables are picked from environment config file\n    :param service: [teradata, mssql]\n    :return: connection string\n    \"\"\"\nif service == 'teradata':\nreturn f\"DRIVER=Teradata;DBCNAME={config['database_host']};;UID={config['database_user']};PWD={urllib.parse.quote(config['database_password'])}\"\nelif service == 'mssql':\nreturn f\"driver={config['driver']};server={config['server']};database={config['database']};Trusted_Connection=yes\"\nelse:\nraise Exception('DB: No such connection available')\ndef sql_select_df(query, service):\n\"\"\"\n    Runs query and returns results as a Pandas DataFrame\n    :param query: SQL Query\n    :param service: [teradata, mssql]\n    :return: DataFrame\n    \"\"\"\ndf = None\ntry:\nconnection = pyodbc.connect(get_connection_string(service))\ntry:\nstart_time = time.time()\ndf = pd.read_sql(query, connection)\ntime_taken = time.time() - start_time\nlogger.info(f'sql_select_df - Records fetched: {len(df):,} ;  Time taken: {time_taken:,.5f} seconds.')\nexcept Exception as e:\nlogger.error(f'sql_select_df - Query failed!. Error \"{str(e)}\".')\nfinally:\nconnection.close()\nexcept Exception as e:\nlogger.error(f'sql_select_df - No connection to \"{service}\". Message: \"{str(e)}\"')\nreturn df\ndef sql_run_file(file, service):\n\"\"\"\n    Runs SQL Script stored in a file and returns the number of rows processed\n    :param file: file path\n    :param service: [teradata, mssql]\n    :return: number of rows processed\n    \"\"\"\nn_rows = 0\ntry:\nwith open(file, 'r') as f:\nquery = f.read()\nn_rows = sql_execute(query, service)\nexcept Exception as e:\nlogger.error(f'sql_run_file - Cannot read file at \"{file}\". Error: \"{str(e)}\"')\nreturn n_rows\ndef sql_execute(query, service, log_info=False, fail=True):\n\"\"\"\n    Runs SQL Script and returns the number of rows processed\n    :param service: teradata or mssql\n    :param query: sql query\n    :param log_info: log successful execution?\n    :param fail: exit execution?\n    :return: number of rows processed\n    \"\"\"\nn_rows = 0\ntry:\nconnection = pyodbc.connect(get_connection_string(service))\ncursor = connection.cursor()\ntry:\nstart_time = time.time()\ncursor.execute(query)\nn_rows = cursor.rowcount\ntime_taken = time.time() - start_time\nif log_info:\nlogger.info(f'sql_execute - Query executed in {time_taken:,.5f} seconds. Records processed: {n_rows:,}')\ncursor.commit()\ncursor.close()\nexcept Exception as e:\ncursor.rollback()\nlogger.error(f'sql_execute - Query failed!. Error \"{str(e)}\".')\nif fail:\nsys.exit(1)\nfinally:\nconnection.close()\nexcept pyodbc.OperationalError as e:\nlogger.error(f'sql_execute - No connection to \"{service}\". Message: \"{str(e)}\"')\nprint(f'sql_execute - Please check if server is running. No connection to \"{service}\".')\nif fail:\nsys.exit(1)\nexcept Exception as e:\nlogger.error(f'sql_execute - No connection to \"{service}\". Message: \"{str(e)}\"')\nreturn n_rows\n</code></pre>"},{"location":"2-Data-Engineering/data-science/","title":"Data Science","text":"<ul> <li>BERT<ul> <li>ML Framework for NLP. It helps computer to understand a language and context of text by using surrounding text.</li> <li>Bidirectional Encoder Representations from Transformers</li> </ul> </li> </ul> <ul> <li>Generative design is a technology in which 3D models are created and optimized by cloud computing and AI. A user sets up requirements for the model, such as manufacturing processes, loads, and constraints, and then the software offers designs that meet those requirements.</li> </ul>"},{"location":"2-Data-Engineering/data-science/#table-of-index-kaggle","title":"Table of Index Kaggle","text":"<p>Maths:</p> <ul> <li>Probability</li> <li>Statistics</li> <li>Statistics Advance - Distributions</li> </ul> <p>Data ETL EDA Wrangling</p> <ul> <li>Python Notes - Data Structures</li> <li>Pandas Notes - Series, DataFrame, Heirarchy</li> <li>Data Handling - Pre-Processing, EDA, Transformation</li> <li>Dimentionality Reduction - PCA, LDA, Kernel PCA</li> </ul> <p>Regression - supervised:</p> <ul> <li>Linear Regression</li> <li>Simple Linear Regression</li> <li>Multiple Linear Regression</li> <li>Polynomial Linear Regression</li> <li>Support Vector Regression</li> <li>Decision Tree Regression</li> <li>Random Forest Regression</li> </ul> <p>Classification - supervised:</p> <ul> <li>Logistic Regression - confusion matrix, accuracy, sigmoid, CAP Curve</li> <li>KNN - K Nearest Neighbour Classifier - Euclidean distance</li> <li>SVM - Support Vector Machines - Maximum Margin Hyperplane</li> <li>Kernel SVM - Map to Higher Dimention, Kernel Trick, Gaussian RBF Kernel</li> <li>Naive Bayes - Bayes Theorem</li> <li>Decision Tree Classifier</li> <li>Random Forest Classifier - entropy, ensemble learning</li> </ul> <p>Clustering - unsupervised:</p> <ul> <li>K-Means Clustering - wcss, choosing k-value, k-means++</li> <li>Hierarchical Clustering - Agglomerative, Dendrogram</li> </ul> <p>Association Rule - Unsupervised:</p> <ul> <li>Apriori Algorithm - market basket analysis, lift, support, confidence, todo</li> <li>Eclat (Part 5 todo)</li> <li>FP Growth</li> </ul> <p>Other Bonus Extra:</p> <ul> <li>Model Select</li> <li>Reinforcement Learning (Part 6 todo)<ul> <li>Upper Confidence Bound</li> <li>Thompson Sampling</li> </ul> </li> </ul> <p>NLP:</p> <ul> <li>Cleaning, stemming, nltk, bag of words, tokenization</li> </ul> <p>Deep Learning: (Part 8 todo)</p> <p>Dimentionality Reduction:</p> <ul> <li>PCA - max variance, unsupervised</li> <li>LDA - max class separation, supervised</li> <li>Kernel PCA - kernel trick on non-linearly separable dataset</li> <li>SVD</li> <li>GDA - Generalized Discriminant Analysis</li> </ul>"},{"location":"2-Data-Engineering/data-solutions/","title":"Data Solutions","text":"<p>Here are all the \"conceptual\" notes related to data soulutions, archirecture and engineering. It can have links to practical notes.</p>"},{"location":"2-Data-Engineering/data-solutions/#data-strategy","title":"Data Strategy","text":"<p>To meet medium or long term business objectives, many aspect of organisation need to work in harmony - all in same direction. Data Strategy underpins business strategy and sets agenda for IT delivery roadmap. Basically, it defines where and how data supports orgs critical business process. It includes data challenges and unlocks opportunities by using right strategy and solution in place, thus achieve the business objectives. Eg, if all tables have key to trace back?; all row have identifier; data is being captured; data can be tied up at all hierarchies and dimensions.</p> <p>Steps to build a Data Strategy</p> <ul> <li>understand the business objectives. Eg, how often are email responded. why the money is going?</li> <li>assess how data is stored and consumed in org.</li> <li>understand current data challenges. Eg, not being captured. isolated availability with no link up or down. non traceble data. stale data. not connected to pipeline or lake.<ul> <li>how can you collect data, apply data</li> </ul> </li> <li>work with business to define optimum target state to meet business objectives, incorporating<ul> <li>data architecture and engineering</li> <li>data management and operating model</li> <li>data analytics, reporting and visualization - or business intelligence</li> </ul> </li> <li>build a road map for data journey, define actionable data strategy.</li> </ul> <pre><code>flowchart LR\nA[(Current\\n Data State)] --&gt; C{Find Data\\n Challenges}\nB(Business Objectives) --&gt; C\nC --&gt; D{Data Strategy}\nD --&gt;|Roadmap| E[(Target\\nData State)] --&gt; F(Data-driven\\ndecision making)</code></pre>"},{"location":"2-Data-Engineering/data-solutions/#data-architecture","title":"Data Architecture","text":"<p>Now that you have a strategy with known challenges and a roadmap to target state, it is time to build the architecture and do the engineering work aligned to roadmap to rach the target state.</p> <p>Data Architecture defines the blueprint for managing data from collection to storage and transformation to consumption. It is base foundation to support business objectives. It is essential to determine the sharp and quick tools that solve the purpose.</p> <pre><code>flowchart LR\na[Storage / Warehousing] --&gt; b[Movement / ETL] --&gt; c[Analytics / Reporting]</code></pre> <p>What to Architect</p> <ul> <li>determine cloud architecture or on premise.</li> <li>if required how can data be scalable, avilable and fault tolerant</li> <li>big data architecture</li> </ul> <p>Parts of Data Architecture - Aim is to achieve below safely</p> <ul> <li>E - extract / connect - have automated connectors and access permissions, to sharepoint, salesforce, sharedrive, etc. Int and ext.</li> <li>L - load / store - all in one place, MSSQL, DVS, Hive, so you can build mart and combine.</li> <li>T - transform / transport - integrate, transform, clean, aggregate, filter. Determine the best tool to do the job. Python, SQL, Prep, Alteryx?</li> <li>P - present - right viz tool, dash, tableau. Keeping the end user in mind.</li> <li>Analogy - Load:HTML :: Transform:JavaScript :: Present:CSS</li> </ul>"},{"location":"2-Data-Engineering/data-solutions/#data-transformation","title":"Data Transformation","text":""},{"location":"2-Data-Engineering/data-solutions/#etl-data-pipeline","title":"ETL &amp; Data Pipeline","text":"<p>ETL - Data Pipeline - Help move data from source to target with transformations in between. Challenge and skill is to build an efficient, reliable and automate pipeline that can help connect sources to lake/warehouse/mart. Big Data pipelines. Batch and Event Driven or real-time.</p> <ul> <li>Big part of design of warehouse.</li> <li>usually a weekly or nightly batch job that updates data warehouse.</li> </ul>"},{"location":"2-Data-Engineering/data-solutions/#data-virtualization","title":"Data Virtualization","text":"<ul> <li>It is used to connect and query different data sources, transform it. It does not store or move the data. Query goes down to source systems.</li> <li>Eg, Tibco Data Virtualization.</li> <li>Link - Difference in ETL &amp; Virtualization</li> </ul>"},{"location":"2-Data-Engineering/data-solutions/#data-analytics-reporting-visualization","title":"Data Analytics, Reporting &amp; Visualization","text":"<p>Flat data, denormalized is best to query for visualization.</p> <p>Steps to follow</p> <ul> <li>understand<ul> <li>requirement gathering,</li> <li>data dicovery</li> </ul> </li> <li>design and develop<ul> <li>tool selection - correct tool for need, right tool for viz/reporting, tableau, Plotly, D3, OBIEE, self-serve;</li> <li>data modelling - reporting view prep, what needs to be shown should be a row of data, add hierarchy to roll up and down.</li> <li>story telling - art of making data easy to understand, animations, live?</li> <li>test - numbers help make decision</li> <li>distribution - mobile, pdf, interactive, embed (portal),</li> <li>actionable insight - (optional) let user do actions right from report. (write-back)</li> <li>usage analytics - (optional) but really useful in determining ROI</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/data-solutions/#links","title":"Links","text":"<ul> <li>Oracle - Data Warehousing Concepts</li> <li>Data Company - Dufrain</li> <li>Ralph Kimball - Data Warehousing and BI Author</li> </ul>"},{"location":"2-Data-Engineering/data-solutions/#todo","title":"ToDo","text":"<ul> <li> - link this with project management notes to have a road map to follow when starting a new data solutions project.</li> <li> - align https://careers.dufrain.co.uk/jobs/2225356-senior-data-engineer</li> <li> - Experience working with one or more of - Spark, Hadoop, Kafka, Snowflake, airflows</li> <li> - Experience building Data Modelling, ETL / ELT pipelines, Data Lakes, Data Warehousing, Master Data</li> <li> - A solid understanding of key processes in the engineering delivery cycle including Agile and DevOps, Git, APIs, and Data Pipelines.</li> </ul>"},{"location":"2-Data-Engineering/data-tools-frameworks/","title":"Data Tools","text":"<p>data processing tools, libraries and frameworks</p> <ul> <li>Apache Spark - large-scale data processing as pandas.<ul> <li>InMemory to avoid diskwrites slowness  of mapreduce</li> <li>Data Structure is RDDs</li> <li>Interactive analytics are faster, just like we do in Jupyter where next step is based on prev.</li> <li>Transformations - <code>filter()</code> map groupByKey union - give RDD</li> <li>Actions - count first collect reduce - give single result</li> <li>PySpark - Python API for spark, RDD as DataFrame so makes similar to Pandas.</li> </ul> </li> </ul> <ul> <li>Apache Beam - unified programming model to define and execute data processing pipelines, including ETL, batch and stream-processing.</li> </ul> <ul> <li>Apache Kafka - distributed event store and stream-processing platform</li> </ul> <ul> <li>Apache Flink - stream-processing and batch-processing framework</li> </ul> <ul> <li>Apache Storm - distributed stream-processing</li> </ul> <ul> <li>Apache Spark Streaming - distributed stream-processing. Extension of core framework.</li> </ul> <ul> <li>Apache Airflow - workflow management platform for data engineering pipelines</li> </ul> <ul> <li>Links<ul> <li>Medium - Stream Processing Framworks and differences</li> <li>IJB Job - DevOps Engg</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/databases/","title":"Databases &amp; SQL","text":"<p>all about databases, SQL only</p>"},{"location":"2-Data-Engineering/databases/#sqlite","title":"SQLite","text":"<ul> <li>It is a micro database that can work in memory or a saved in file, eg, <code>store.db</code> .</li> <li>Queries are same as any other SQL.</li> <li>It can be used in many ways, some are:<ul> <li>Python Program and DB Engine In memory</li> <li>Python Program and DB Engine as File</li> <li>SQLite installed as utility and access via shell, this is <code>sqlite3.exe</code> program.</li> <li>SQLite ODBC driver.</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/databases/#interaction","title":"Interaction","text":"<ul> <li>shell<ul> <li><code>sqlite3</code> opens a shell in command line, just like mysql shell. DB is in memory<ul> <li>to open a file, use <code>.open FILENAME</code> to open an existing database.</li> </ul> </li> <li><code>sqlite3 data.sqlite</code> to work on this file</li> <li><code>ctrl + z</code> enter to exit</li> </ul> </li> </ul> <ul> <li>DDL<ul> <li><code>.tables</code> to show all tables</li> <li><code>.schema orders</code> to check create statement</li> </ul> </li> </ul> <ul> <li>load CSV<ul> <li><code>.mode csv</code> and then <code>.import data.csv orders</code> loads csv to db, creates if not exists.</li> </ul> </li> </ul> <ul> <li>GUI SQLite Browser</li> </ul>"},{"location":"2-Data-Engineering/databases/#mysql","title":"MySQL","text":"<p>Installation:</p> <ul> <li><code>brew install mysql</code></li> </ul> <p>Start Server:</p> <ul> <li><code>brew services start mysql</code> - background mysql start</li> <li><code>mysql.server start</code> - no background</li> <li><code>mysql_secure_installation</code> - run this and set root pwd, etc.</li> <li><code>ps -ef | grep mysqld</code> process</li> </ul> <p>Login:</p> <ul> <li><code>mysql -u root -p</code> then enter password</li> </ul> <p>Queries:</p> <pre><code>show DATABASES;\ncreate user 'bob_me'@'localhost' identified with mysql_native_password by 'bob_pwd';\ncreate database bob_db;\ngrant all privileges on bob_db.* to 'bob_me'@'localhost';\n</code></pre> <p>Client - SequelPro:</p> <ul> <li>Connecting:<ul> <li>Standard</li> <li>Host: 127.0.0.1</li> <li>enter uername and password and connect.</li> </ul> </li> </ul> <p>Shutdown Server:</p> <ul> <li><code>mysql.server stop</code> - stops server</li> </ul> <p>Other Notes:</p> <ul> <li>Column and Table names are case-sensitive.</li> <li><code>mysqladmin</code> is also installed</li> </ul> <p>Trouble Shooting:</p> <ul> <li>If you see error in clients, eg Sequel Pro, it might not be ready yet for a new kind of user login, link.</li> <li>do <code>ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'newrootpassword';</code> then try loggin in.</li> </ul>"},{"location":"2-Data-Engineering/databases/#microsoft-sql-server","title":"Microsoft SQL Server","text":""},{"location":"2-Data-Engineering/databases/#mssql-snippets","title":"MSSQL Snippets","text":"<pre><code>-- Create and Insert\nSELECT FirstName, LastName\nINTO TestTable\nFROM Person.Contact\nWHERE EmailPromotion = 2\n-- Existing Table Append\nINSERT INTO TestTable\nSELECT FirstName, LastName\nFROM Person.Contact\nWHERE EmailPromotion = 2\n</code></pre>"},{"location":"2-Data-Engineering/databases/#redis","title":"Redis","text":"<ul> <li><code>redis-server</code> to start the server.</li> </ul>"},{"location":"2-Data-Engineering/etl_pipelines/","title":"ETL Pipelines","text":"<p>all about ETL pipeplines scheduling</p>"},{"location":"2-Data-Engineering/etl_pipelines/#parallel-data-processing","title":"Parallel Data Processing","text":"<ul> <li>Python multiprocessing Pool - low level native python code, expilictly implement prallel processing</li> <li>Python dask - library having multiprocessing out of box</li> <li>Hive - framework that lets extract data using SQL. Behind it converts to MapReduce job.</li> <li>Spark - Apache Spark is InMemory to avoid diskwrites slowness  of mapreduce</li> <li>Map Reduce - technique/algorithm</li> <li>Hadoop - framework</li> <li> move to bigData Notes</li> </ul>"},{"location":"2-Data-Engineering/etl_pipelines/#etl-pipeline","title":"ETL Pipeline","text":"<ul> <li>Simple - Using Pandas to read data, transform it and load is a pipeline. Doing this in distributed environment is big data pipeline.</li> <li>Distributed - Using PySpark read data from DB is extraction. Do transformation like groupBy or mean, join.</li> </ul> <ul> <li>Code organization - say in <code>etl_somejob.py</code><ul> <li>define extract functions. Eg: <code>def extract_table1_to_df():</code> that retrus df.</li> <li>define transform funcitons. Eg: <code>def transform_avg_score(df1,df2):</code> returns df.</li> <li>define load function. Eg: <code>def load_df_to_db(df):</code></li> <li> <p>finally to execute them</p> <pre><code>if __name__ == \"__main__\":\ndf_table1 = extract_table1_to_df()\ndf_score = transform_avg_score(df_table1)\nload_df_to_db(df_score)\n</code></pre> </li> </ul> </li> </ul> <ul> <li>Now you can use this file to run or schedule.</li> </ul>"},{"location":"2-Data-Engineering/etl_pipelines/#automation-scheduling-orchestrate","title":"Automation Scheduling Orchestrate","text":"<ul> <li> <p>DAG - Directed Acyclic Graph is used to represent collection of tasks in organized way to show dependecies and relationships. It has no cyclic link.</p> <pre><code>graph LR;\nA--&gt;B;\nB--&gt;D;\nB--&gt;C;\nC--&gt;E;</code></pre> </li> </ul> <ul> <li>Cron - Linux in build to schedule a job. Can't manage depndencies.</li> </ul> <ul> <li> <p>Apache Airflow</p> <ul> <li>Create DAGs in Python</li> <li>Define tasks of DAGs using Operators. Operators can operate various things like bash code, python code, StartCluster or SparkJob.</li> <li>Set up dependency of tasks - using <code>set_downstream()</code>. This will create relationships in jobs.</li> </ul> <ul> <li>configuration<ul> <li>make <code>mkdir airflow</code> dir</li> <li>export its location to variable <code>AIRFLOW_HOME</code></li> </ul> </li> <li>installation - <code>pip install airflow</code></li> <li>initiation<ul> <li><code>airflow db init</code> to generate airflow db, config and webserver files.</li> <li>make an admin user, code from docs.</li> </ul> </li> <li> <p>implementation</p> <ul> <li>define ETL tasks functions in <code>./airflow/dags/etl_tasks.py</code></li> </ul> <ul> <li>define <code>./airflow/dags/dags.py</code>, here<ul> <li>it will have airflow module implementation to schedule and execute tasks via DAG.</li> <li>import ETL tasks file as module.</li> <li>define execution function to run ETL tasks</li> <li>define DAG using DAG class.</li> <li>add config, like when to run, retries to try, gap in retries, email to send on faliure, and many other configrations as dictionary object and pas that to <code>default_args</code> param of <code>DAG</code> class.</li> <li>define ETL Task using <code>operator</code>. this executes the execution function.</li> </ul> </li> </ul> </li> </ul> <ul> <li>schedule - <code>airflow scheduler</code> to add dag to server</li> <li>monitor<ul> <li><code>airflow webserver</code> this starts flask webserver where you can look the jobs.</li> <li>view dags, srart/stop/pause jobs</li> </ul> </li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/etl_pipelines/#code-example-airflow-dag","title":"Code Example Airflow DAG","text":"<p>Following code shows snippet of basic DAG implementation</p> dags.py<pre><code># ``\nimport airflow\nfrom airflow.models import DAG # DAG class\nfrom airflow.operators.python_operator import PythonOperator # as we use Py\nfrom etl_tasks import *\ndef etl():\ndf_table1 = extract_table1_to_df()\ndf_score = transform_avg_score(df_table1)\nload_df_to_db(df_score)\n# define DAG with configs\ndag = DAG(dag_id=\"etl_ipeline\", \ndefault_args=default_args, \nschedule_interval=\"0 0 * * *\")\n# define ETL Task\netl_tasks = PythonOperator(task_id=\"etl_task\", python_callable=etl, dag=dag)\netl()\n</code></pre>"},{"location":"2-Data-Engineering/etl_pipelines/#links","title":"Links","text":"<ul> <li>LinkedIn Learning - Data Engineering Foundations</li> </ul>"},{"location":"2-Data-Engineering/python-data-wrangling/","title":"Python Data Wrangling","text":"<p>Pandas is a package in Python that can be used for data manipulation.</p>"},{"location":"2-Data-Engineering/python-data-wrangling/#what-is-data-manipulation","title":"What is Data Manipulation?","text":"<p>Data manipulations can be organized around six key verbs:</p> <ul> <li>arrange: order dataframe by index or variable or sort the data</li> <li>select: choose a specific variable or set of variables or select columns in data</li> <li>filter: subset a dataframe according to condition(s) in a variable(s) or select rows in data</li> <li>mutate: transform dataframe by adding new variables or add a calculated column</li> <li>group_by: create a grouped dataframe</li> <li>summarize: reduce variable to summary variable (e.g. mean)</li> </ul> <p>Here, variable is a column in data set.</p> <p>We'll cover how to perform above operations on a dataset using Pandas.</p>"},{"location":"2-Data-Engineering/python-data-wrangling/#quickest-data-in-pandas","title":"Quickest data in pandas","text":"<pre><code>text = '''colA colB\nJan 239\nFeb 234\n'''\nfrom io import StringIO\nimport pandas as pd\npd.read_csv(StringIO(text),delimiter=' ')\n</code></pre>"},{"location":"2-Data-Engineering/python-data-wrangling/#filter","title":"Filter","text":"<p>We can filter data to get a set of rows from complete dataset. It is similar to <code>WHERE</code> clause in SQL.</p>"},{"location":"2-Data-Engineering/python-data-wrangling/#doing-same-stuff-using-r","title":"Doing same stuff using R","text":"<p>R is also an excellent programming language for data manipulation. <code>dplyr</code> is a package in R that can be used to perform above operations.</p> <p>An excellent article by Ben, The 5 verbs of dplyr, can provide you more details on this.</p> <p>Another article that compares R and Python can be found here.</p> <p>Comparison of Pandas with SQL</p> <p>Pandas docs excellent details with examples.</p>"},{"location":"2-Data-Engineering/tableau/","title":"Tableau","text":"<p>Tableau is a data analysis and visualization tool.</p>"},{"location":"2-Data-Engineering/tableau/#date-calculations","title":"Date Calculations","text":"<p>Here are some basic common calculations that helo in making KPIs and easy working with dates to find YOYs and MOMs</p> <ul> <li>Month-Year to Business Date <code>DATEPARSE('yyyy-MM-dd',[Business Month]+'-01')</code></li> <li>Month-Year to Business Year - <code>Left([Business Month],4)</code></li> <li>Max Date - <code>{MAX([Business Date])}</code></li> </ul> <ul> <li>Monthly</li> </ul> <pre><code>IF ( DATEDIFF('month', [Business Date], [Max Date], 'monday') = 0  AND DAY([Business Date])&lt;=DAY([Max Date]))\nTHEN 'Current Month'\nELSEIF ( DATEDIFF('month', [Business Date], [Max Date], 'monday') = 1\n//AND\n//DAY([Business Date])&lt;=DAY([Max Date])\n)\nTHEN 'Last Month'\nELSEIF ( DATEDIFF('month', [Business Date], [Max Date], 'monday') = 12 // AND DAY([Business Date])&lt;=DAY([Max Date])\n)\nTHEN 'Last Year Month'\nEND\n</code></pre> <ul> <li>Rolling 13 months</li> </ul> <pre><code>[Business Date] &gt; DATEADD('month',-13,{MAX([Business Date])})\nand\n[Business Date] &lt;= {MAX([Business Date])}\n</code></pre> <ul> <li>yearly</li> </ul> <pre><code>IF ( DATEDIFF('year', [Business Date], [Max Date], 'monday') = 0   AND MONTH([Business Date])&lt;=MONTH([Max Date]))\nTHEN 'Current Year'\nELSEIF ( DATEDIFF('year', [Business Date], [Max Date], 'monday') = 1  AND ( (  MONTH([Business Date]) &lt;= MONTH([Max Date])  ) //OR \n//( \n// ( MONTH([Business Date])=MONTH([Max Date]) ) AND ( DAY([Business Date])&lt;=DAY([Max Date]) ) \n//)\n)\n)\nTHEN 'Last Year'\nEND\n</code></pre> <ul> <li>CM <code>SUM(IIF([Monthly]=='Current Month',[Closed Customers],NULL))</code></li> </ul> <ul> <li>MOM</li> </ul> <pre><code>(\nSUM(IIF ([Monthly] == 'Current Month',[Users],0)) - SUM(IIF ([Monthly] == 'Last Month',[Users],0) ) )\n/\nSUM(IIF ([Monthly] == 'Last Month',[Users],0))\n</code></pre> <ul> <li>MOM up <code>IF [Closed Customers MOM] &gt; 0 THEN \"\u25b2\" END</code></li> <li>MOM Donw <code>IF [Closed Customers MOM] &lt;= 0 THEN \"\u25bc\" END</code></li> </ul> <ul> <li>YOY</li> </ul> <pre><code>( SUM(IIF ([Yearly] == 'Current Year',[Closed Customers],0)) - SUM(IIF ([Yearly] == 'Last Year',[Closed Customers],0) ) )\n/\nSUM(IIF ([Yearly] == 'Last Year',[Closed Customers],0))\n</code></pre> <ul> <li>YOY Up <code>IF [Closed Customers YOY] &gt; 0 THEN \"\u25b2\" END</code></li> <li>YOY Donw <code>IF [Closed Customers YOY] &lt;= 0 THEN \"\u25bc\" END</code></li> <li>YTD <code>SUM(IIF([Yearly] == 'Current Year',[Closed Customers],0))</code></li> </ul> <p>KPI Format</p> <ul> <li>small arrows <code>0%\u202f \u2bc5; -0% \u2bc6; 0%\u2800\u2800;</code> \u2bc7 \u2bc8 \u2bc5 \u2bc6</li> <li>\u2b9c \u2b9e \u2b9d \u2b9f <code>0%\u202f \u2b9d; -0% \u2b9f; 0%\u2800\u2800;</code> \\(U+2800\\)</li> <li>\ud83e\udc44 \ud83e\udc46 \ud83e\udc45 \ud83e\udc47 <code>0%\u202f \ud83e\udc45; -0% \ud83e\udc47; 0%\u2800\u2800;</code></li> <li>more arrows - http://xahlee.info/comp/unicode_arrows.html</li> </ul> <p>TUG Austia - https://github.com/tableau/community-tableau-server-insights - readymade events</p> <p>Number Tweaks</p> <p>Number standardize between 0 and 1 per category for trend line colors</p> <pre><code>(\nSUM([Value ]) - WINDOW_MIN(SUM([Value ])) )\n/\n(\nWINDOW_MAX(SUM([Value ])) - WINDOW_MIN(SUM([Value ])) )\n</code></pre>"},{"location":"2-Data-Engineering/tableau/#tableau-js-embedd-api","title":"Tableau JS Embedd API","text":"<ul> <li>Everything starts by loading a <code>viz</code>, this can be a dashboard or a sheet. Viz gives you <code>workbook</code> and Async callback function.</li> <li><code>workbook</code> has <code>sheets</code>, but can have only one <code>activeSheet</code>, like active Tab. You can only do operations on activeSheet.</li> <li>Operations are <code>Async</code> and return a promise, so they can be chained.<ul> <li>Change Param  - <code>changeParameterValueAsync(\"param_name\", value)</code></li> <li>Change Filter - <code>applyFilterAsync(\"filter_name\", values, tableau.FilterUpdateType.REPLACE)</code></li> <li>Change ActiveSheet - <code>activateSheetAsync(\"sheet_name\")</code> this can be dashboard or sheet</li> <li>Get Data - <code>getSummaryDataAsync(data_options)</code> - returns table object with data and columns</li> </ul> </li> </ul> <p>Network calls are made when you call Async funcitons, else it is a JS execution only.</p> <p>Read Data:</p> <ul> <li>create sheet with all columns added to row pill.</li> <li>activate this sheet,</li> <li>then do <code>getData</code>,</li> <li>to skip chache, increment counter.</li> </ul> <p>Writeback:</p> <ul> <li>Add a proc as data source. Proc to have at least three inputs, Switch, Value and Counter.</li> <li>Create these params in workbook<ul> <li><code>switch</code><ul> <li>0 - no action</li> <li>1 - CREATE/insert</li> <li>2 - UPDATE</li> <li>3 - DELETE</li> </ul> </li> <li><code>psv</code> - pipe separated values</li> <li><code>counter</code> - increment it whenever you want tableu to skip cache and call database server.</li> </ul> </li> <li>Create sheet <code>exec_proc</code>, whenever this sheet is activated, it will execute proc depending on the three params above.</li> </ul> <pre><code>async function execProcTabeauAsync(switch,psv) {\nawait workbook.changeParameterValueAsync(\"psv\", psv);\nawait workbook.changeParameterValueAsync(\"counter\", ++counter);\nawait workbook.changeParameterValueAsync(\"switch\", switch);\nawait workbook.activateSheetAsync(\"exec_proc\");\nconsole.log('Action: ' + switch + '; Completed at: ' + new Date($.now()).toISOString());\nreturn await workbook.changeParameterValueAsync(\"switch\", 0);\n}\n</code></pre>"},{"location":"2-Data-Engineering/tableau/#writeback","title":"Writeback","text":"<p>Parameters Required</p> <ul> <li><code>w_mega_string</code></li> <li><code>w_increment</code></li> <li><code>w_action_switch</code></li> </ul> <ul> <li>For each field to write<ul> <li><code>reset_field1</code></li> </ul> </li> </ul> <p>Create New</p> <ul> <li>Add sheet <code>add_button</code>, use <code>blank_db</code> having text \"+ Add new record\"</li> <li>Add sheet to dashboard</li> <li>Add actions<ul> <li>go to <code>create_record</code> sheet</li> <li>reset <code>field</code></li> <li>set param <code>action_switch</code> to 0</li> </ul> </li> </ul>"},{"location":"2-Data-Engineering/tableau/#links","title":"Links","text":"<ul> <li>Data Structuring for Analysis - https://help.tableau.com/current/pro/desktop/en-us/data_structure_for_analysis.htm</li> <li>Linkedin - Writeback to MS SQL using Proc</li> </ul>"},{"location":"3-Management-%26-Strategy/ajile-sprint-scrum/","title":"Agile, Scrum and Sprints","text":"<p>all about agile, scrum, sprints</p> <ul> <li>Retrospective<ul> <li>What did we do well?</li> <li>What should we have done better?</li> <li>actions to take based on \"What should we have done better\"</li> <li>actions taken from last retro actions? else carry them</li> <li>Learnings<ul> <li>don't under estimate tasks</li> <li>keep buffer capacity for meetings/PR-requests</li> </ul> </li> </ul> </li> </ul> <ul> <li>Backlog Grooming / Refinement<ul> <li>Break stories into smaller tasks</li> <li>Tasks have \"Definition of Ready\" DoR - covers requirements coming into the sprint</li> <li>Tasks are prioritized, estimated</li> <li>Tasks may get assigned</li> <li>1-2 hour productive meeting</li> <li>link</li> </ul> </li> </ul> <ul> <li>Sprint Planning<ul> <li>Ahead of our sprint planning:<ul> <li>Please update your capacity for the next sprint. link</li> <li>Please create, estimate and assign tasks with \"definition of done\" DoD</li> <li>Update tasks in current sprint.</li> </ul> </li> <li>Meeting for 2-4 hours for 2 week sprint</li> <li>Know Memebers, their role, capacity and leaves. Ideally tabular.</li> <li>In Last Sprint<ul> <li>Ensure all tasks are updated - in review, done or whatever</li> <li>End the sprint and move all unfinished tasks to backlog or new sprint</li> </ul> </li> <li>Start &amp; End Date - know and update it</li> <li>Sprint Goal(s) - have predefined and refine at end</li> <li>Tasks to have<ul> <li>Acceptace Criteria</li> <li>Definition of Done - covers product coming out of the sprint</li> <li>Estimated and assigned</li> <li>Reestimate tasks carried forward</li> </ul> </li> </ul> </li> </ul> <p>Backlog Grooming vs Sprint Planning</p> <ul> <li>Scope - BG looks at entire project for months, SP looks at near future for weeks</li> <li>Grain - BG breaks into tasks, SP breaks in to sub-tasks</li> <li>Detail - BG adds DoR, SP adds DoD</li> </ul>"},{"location":"3-Management-%26-Strategy/ajile-sprint-scrum/#links","title":"Links","text":"<ul> <li>Your step-by-step guide to running a Sprint Planning meeting effectively</li> <li>Gantt Charts in PowerPoint - simple easy</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/","title":"Project Management","text":"<p>Project Management is balancing between \"the project scope\" and \"the time, resources and budget\" you have. Manage \"the time, resource and budget\" to cover \"the project scope\". It includes planning process like requirement gathering, planning, solution design, code, test, deploy. We need to break down the project into doable work tasks. Once broken, estimate them. Finally assign them to get started. It can include the steps below</p>"},{"location":"3-Management-%26-Strategy/project-management/#steps-for-end-to-end-project-management","title":"Steps for End to End Project Management","text":""},{"location":"3-Management-%26-Strategy/project-management/#1-initiation-and-ideation","title":"1 Initiation and Ideation","text":"<ul> <li>Business Requirement Gathering</li> <li>What are you solving and how will you solve it? The business use case.</li> <li>Define use case, scope and expectations. This is very high level and covers the business problem.</li> <li>Project should have a definite end - a product or a service. It should have definition of done.</li> <li>Above can result in <code>Business Requirements Document</code></li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#2-defining-goals-and-objectives","title":"2 Defining - Goals and Objectives","text":"<ul> <li>What needs to be done? How it can be done? Define the goal and objectives.</li> <li>Goal - should clearly and simply define a state considering most important factors.</li> <li>Objectives - they sould be specific, measurable, achievable, realistic and time-related. Documented. Also specify the category of aobjective:<ul> <li>qualitative - improve experience. measure by survey rating</li> <li>financial - inc revenue by 15%</li> <li>operational - reduce number of notifications</li> </ul> </li> <li>Definition of Done. This will help breaks down the problem into sub-tasks and defines what is expected.</li> <li>Above can shape the <code>High Level Document</code></li> <li>Identify the Stakeholders and in the document add their:<ul> <li>objectives requirements and interests</li> <li>contribution</li> <li>what are they concerned about</li> <li>their line mangers, eg, if you need somoeone from finance team then take approval from their line managers.</li> </ul> </li> <li>Be precise, take what matters and drop what doesn't. Clearly define what is in and out of scope, write it down.</li> <li>It can take several rounds with stakeholders to get correct objectives and scope.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#3-planning-choose-a-strategy","title":"3 Planning - Choose a Strategy","text":"<ul> <li>Brainstorm with group and let ideas flow in.</li> <li>Write possible options to achieve an objectives. Then pick one of the option that covers all scenarios and meets all objectives and goals.</li> <li>Considerations to be made<ul> <li>is the strategy feasible, achievable?</li> <li>are the risks acceptable: security, load balancing, new technologis challenges etc?</li> <li>culture - does it fit the org pattern?</li> </ul> </li> <li>above can shape <code>Low Level Document</code></li> <li>Get a F2F sign-off here, over email and treat it as approved.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#4-solution-design-modules-tasks-sub-tasks-deliverables","title":"4 Solution Design - Modules, Tasks, Sub-Tasks, Deliverables","text":"<ul> <li>Break the objectives/goals in to <code>modules</code>,  <code>technical work tasks</code> and <code>sub-tasks</code> using the strategy and define <code>deliverables</code>.</li> <li>Tasks - Add business understandings, definitions and calculations.<ul> <li>Sub-task - Add definition of done. Managable and doable tasks.</li> <li>Deliverables - Identify them, clearly and quantifiably measure them</li> </ul> </li> <li>Define Scenarios and map expectations - the above tasks should cover all scenarios and expectations.</li> <li>This sould define the <code>Software Design Document</code> can be planned on Jira and documented on Confluence.</li> <li>Take a technical sign-off and approval if required.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#5-delivery-plan-estimate-assign","title":"5 Delivery Plan - Estimate Assign","text":"<ul> <li>Arrange work tasks in sequence, link them with dependencies, add duration.</li> <li>Resource Allocation - assign the tasks to resources. These can be done in Jira. Look out for blockers and unavailability.</li> <li>Make a realistic schedule - include holidays, dependencies.</li> <li>Deadlines - Management can set a deadline, you need to adjust schedule to meet it. Add resource, or break into phase. Do phase analysis - define the MVP to deliver early. Do Phase II enhancements etc.</li> <li><code>Gantt Chart</code> - optional reporting.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#6-risk-assessment-clarify-assumptions","title":"6 Risk Assessment - Clarify Assumptions","text":"<ul> <li>Avoid risks that are based on assumptions, like someone will do the deployment, access would work.</li> <li>Will the business stop if solution is down? What if resource not available?</li> <li>What if data gets corrupt?</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#7-other-optional-documentsplans","title":"7 Other optional documents/plans","text":"<ul> <li>Budget - Add costs, include resources, softwares.</li> <li>Communication plan - scrums, weekly, daily</li> <li>Change Management Plan - approvals, what changes when, impact</li> <li>Procurement plan - to buy software, resources, contracting</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#8-execution-development","title":"8 Execution - Development","text":"<ul> <li>Write code and document it.</li> <li>Do pilot delivery - a quick delivery and test. If works, keep expanding by adding features.</li> <li>Monitoring and Controlling - evaluate and get it back on track if lagging or deviated.</li> <li>Keep unit testing the code.</li> <li><code>Deliverables</code> - code files, reports, documents. All should be in one place and version controlled.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#9-qa-prepration-testing","title":"9 QA Prepration - Testing","text":"<ul> <li>Make test cases and test scenarios as you go.</li> <li>Identify Testers from Stake Holders.</li> <li>Make a <code>bug tracker</code> where any one can report bugs and it can be tracked.</li> <li><code>QA Document</code> - add test cases and their results.</li> <li>Get a UAT Sign Off of the deliverables.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#10-deployment","title":"10 Deployment","text":"<ul> <li>Deploy in prod. Test it.</li> <li>Prod Env is secured and hence may require many access permissions. Please see this in advance.</li> <li>Change Management may be required here.</li> <li>Once deployed, do a Prod Testing.</li> <li>Finally release the product</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#11-handover-user-training-socialisation","title":"11 Handover - User Training Socialisation","text":"<ul> <li>Prepare a <code>Training Guide</code> - for end users. This can be video as well.</li> <li>Make a <code>Handover Document</code> - if this need to be handed over to maintenance team to work on manual tasks.</li> <li>Manual tasks - include scope, work required, frequency, risks etc.</li> <li>Contracts - get signed-off if required.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#best-practices","title":"Best Practices","text":"<ul> <li>Deliverables and Documentation - All files and documentation at one place and all have access. Confluencem, Jira Boards and Shared Drives.</li> <li>Estimation - Set clear goals. Manage Workload.</li> <li>Communication - 1-1 meetings weekly. Daily Updates.</li> <li>Change Management - if change is required in between, follow a change management procedure and redo all steps and sign offs.</li> <li>Reviews - Doc, deliverable. Continuous review helps.</li> <li>Opennes - Be open, let them choose tool, let them choose way, keep them foucsed. Trust them.</li> <li>Risk Management - each team member is accountable to explain risk in their task to entire team. Don't let people assume the work, ask them and clarify it.</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#documentation","title":"Documentation","text":"<p>Step 1: Plan the documentation</p> <p>Step 2: Prepare the document</p> <p>Great user documentation should include:</p> <ul> <li>Plain language</li> <li>Simplicity</li> <li>Visuals</li> <li>A focus on the problem</li> <li>A logical hierarchy and flow</li> <li>A table of contents</li> <li>Searchable content</li> <li>Accessible content</li> <li>Good design</li> <li>Feedback from real users</li> <li>Links to further resources</li> </ul> <p>Step 3: Test the document</p> <p>Step 4: Keep it upated.</p>"},{"location":"3-Management-%26-Strategy/project-management/#spinx","title":"Spinx","text":"<ul> <li>Sphinx is the de-facto documentation tool for Python.</li> <li>version controlled, sourced from repo</li> <li>read everywhere, confluence, wiki, PDF</li> <li>Also lets document functions and classes</li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#talk-product-strategy-systems-and-frameworks-with-sachin-rekhi","title":"Talk - Product Strategy, Systems, and Frameworks with Sachin Rekhi","text":"<ul> <li>Sachin built <code>LinkedIn Sales Navigator</code>, $200m in 1.5yr, 0-500 employee</li> <li>Learn to write and sell code.</li> <li>How to be in Product Management path?<ul> <li>Adjacent role, keep coding and start managing the product. Add values, show interest, then keep moving to product role.</li> <li>Be a domain expert, like expert in sales tech, expert in education-tech, med-tech, sports-tech.</li> </ul> </li> <li>Sales Navigator story<ul> <li>he built connected, personal CRM, it was acquired by linkedIn.</li> <li>showed delivering product quickly, initial traction, showed internal credibility in linkedin, then got the bigger and riskier bet.</li> <li>Credibility and Social-Capital is required to take new bigger opportunities.</li> <li>Share your aspirations with manager, but show credibility too for that.</li> </ul> </li> <li>Strategy to build a product - product should answer these quesitons, and in a compelling way<ul> <li>what is the problem you are solving? separate from solution? what is the pain? Exact knowledge helps</li> <li>who is the audience, as psecific as possible. understand exactly who the are, mroe specific more success</li> <li>value, benifit from solcution</li> <li>competitive, better than competitors, why? who will compete in long term and short term.</li> <li>growth strategy, how to get customers?</li> <li>buiness model, profit?</li> </ul> </li> <li>how to make it compelling?<ul> <li>does the problem <code>resonates with audience</code>?</li> <li>business model has <code>growth strategy</code>?</li> <li>have strong interplay in between these, specially when starting new product.</li> </ul> </li> <li>Growth Startegy<ul> <li>paid ads, then is customer giving that value, think of LTV, <code>lifetime value</code> or <code>customer acquisition cost</code>, CAC. Have greater LTV to afford CAC.</li> <li>product should be expensive enough to support sales team.</li> </ul> </li> <li>Framework / process for buy in (convincing)<ul> <li>get team of 8-10 engg, work as a venture</li> <li>do <code>prod research</code>, come with PPT, having screenshots and client feedback</li> <li>have detailed <code>compelling customer feedback</code>, is it compelling?</li> <li>have <code>convincing facts</code> for capitalists</li> <li>6 convincing style<ul> <li>framing - narrative in a way, set a context</li> <li>goal seek - align to their goals</li> <li>citation - ab tests, voice of customer</li> <li>narration - compelling story</li> <li>find which style will work</li> </ul> </li> </ul> </li> <li>Entrepreneur journey<ul> <li>idea of product came form office work<ul> <li>we dont have info we need, 90% info is not in wiki confluence, hence <code>notejoy</code></li> </ul> </li> <li><code>earned secrets</code>, give you start up ideas</li> </ul> </li> <li>Hurdles<ul> <li>fewer resources, no research team, less marketing team</li> <li>no client base, make your own customers, build growth strategy from day 1, share virally</li> </ul> </li> </ul>"},{"location":"3-Management-%26-Strategy/project-management/#links","title":"Links","text":"<ul> <li>Steps https://www.wrike.com/blog/foolproof-project-plan/</li> <li>Detailed https://www.smartsheet.com/content/software-project-management</li> <li>LinkedIn Learning - https://www.linkedin.com/learning/project-management-foundations-4</li> <li>PMP Certification https://www.pmi.org/certifications/project-management-pmp</li> <li> SAFe POPM</li> <li>TOGAF https://www.opengroup.org/togaf</li> </ul>"},{"location":"4-Functional-%26-Business/banking-notes/","title":"Banking and Finance","text":"<p>All about banking and finance</p>"},{"location":"4-Functional-%26-Business/banking-notes/#how-banks-make-money","title":"How Banks make money?","text":"<p>Banks makes money by following methods:</p> <ol> <li>Investment Banking: Most of the income Barclays make is by being an advisor to big corporations, government and individuals.</li> <li>Corporate Banking: It provides services for multinationals and large domestic corporate. It charges fee, interests for loans from these companies.</li> <li>By charging interest from borrowers.</li> <li>By charging various fees on services like,   a.  Account Fees: For different products in bank, it charges fee for maintenance and services.   b.  ATM fees: This is charged for ATM usage outside limit and when using other bank\u2019s ATM for services.   c.  Penalty charges: This can be for late credit card payment or missing a loan EMI.   d.  Commissions: They provide asset management for which brokers ask for commission.</li> <li>Merchant Service Charges: Barclays help merchants accept payments. For this bank charges fee for services. It also helps merchant by data analysis for this as well it charges other fees for value added services.</li> </ol>"},{"location":"4-Functional-%26-Business/banking-notes/#net-interest-margin-nim","title":"Net Interest Margin (NIM)","text":"<ul> <li>(Interest Earned) - (Interest Paid).</li> <li>NIM% = NIM / (Avg earning asset), where</li> <li>AEA = Average earning asset = (Assets at the beginning of the year + Assets at the end of the year) / 2.</li> <li>The difference between the interest income generated by banks  and the amount of interest paid out to their lenders (for example, deposits), relative to the amount of their (interest-earning) assets.</li> </ul>"},{"location":"4-Functional-%26-Business/banking-notes/#retail-banking-consumer-banking","title":"Retail banking (Consumer Banking)","text":"<ul> <li>Individual consumers can manage their money, take credit, and deposit their money</li> <li>Services include checking and savings accounts, mortgages, personal loans, credit cards, FD/RD.</li> </ul>"},{"location":"4-Functional-%26-Business/banking-notes/#income-tax","title":"Income TAX","text":"<ul> <li>Form 26as has information on FD interest</li> </ul>"},{"location":"4-Functional-%26-Business/banking-notes/#credit-risk-management","title":"Credit Risk Management","text":"<p>Credit risk management is the practice of mitigating losses by understanding the adequacy of a bank's capital and loan loss reserves at any given time \u2013 a process that has long been a challenge for financial institutions.</p>"},{"location":"5-Personal-Development/pd-courses/","title":"Personal Development Courses","text":""},{"location":"5-Personal-Development/pd-courses/#build-confidence-and-crush-doubt","title":"Build confidence and crush doubt","text":"<ul> <li>Start with belief and not talent. That is you can do it and not that you have talent to do it.</li> <li>build the confidence through repetition. Keep reminding.</li> <li>use physical clues to refocus. Like deep breath. Business suit.</li> <li>have affermations to yourself - you can code complex stuff, you can present to people clearly.</li> <li>build a grag sheet for yourself, you praise yourself. don't share this with others but keep reminding how good you are.</li> <li>draw energy from positive people, meet them. Like sunil mausaji, tony knock.</li> <li>Practice this as this is a skill, not one time read. You will shine and the people you lead will shine too.</li> <li>https://www.linkedin.com/learning/how-to-crush-self-doubt-and-build-self-confidence/</li> </ul>"},{"location":"6-Math-%26-Logic/probability/","title":"Probability","text":"<p>If an experiment is 'rolling 2 dice', then there are 6.6 = 36 outcomes. The possibility of outcome is the probability. (3,4) and (4,3) are two different events.</p> <p>Event is set of outcome of an experiment.</p> <p>Probability is a way to find likeliness of an event to happen. Permutation and combination are ways to count events and possibilities. Probability tells us:</p> <ul> <li>how likely event is going to happen.</li> <li>possibility of event that is fundamentally random.</li> <li>Quantifying the uncertainity.</li> </ul> <p>For example, if we flip a coin we can get either heads or tails. The possibility of heads is 50% and possibility ability of tails is 50%. So the probability of Heads is .5 and probability of tails is also .5, if it is a biased coin.</p> \\[ P(e) = \\frac{ Possibilities }{ Outcomes } \\] <p>Theoretical or Classical Probability</p> <ul> <li>It can be stated and seems fixed.</li> <li>For example flipping a coin.</li> </ul> <p>Experimental or Subjective Probability</p> <ul> <li>Finding an outcome based on past data and experience</li> <li>example prediction of the score. Probability gives a reasonable predictions about an outcome. It is highly likely but not hundred percent true.</li> </ul> <p>Simulation and Randomness</p> <ul> <li>We can use list of random numbers to simulate our experiment multiple times and average out to find confidence.</li> </ul> <p>Sample Space is collection of all possible outcomes of a random experiment. Hence, event can be any subset of sample space.</p> <p>Variable is anything whose value changes.</p> <p>Discrete variable is a variable whose value is calculated by counting. Eg, number of students in class, number of blue marbles in a jar, number of tails when flipping four coins.</p> <p>Continuous variable is a variable whose value is calculated by measuring. Eg, height of players in team, weight of students in class, time it takes to get to work</p> <p>Random variable is a variable whose possible values are outcomes of a random experiment. It is denoted usually X. P(X) is probability distribution of X, it tells values of X and its probability. Random variable can be continuous or discrete.</p> <p>Discrete random variable X has a countable number of possible values. Its probabilty distribution is histogram.</p> <p>Continuous random variable X takes all values in a given interval of numbers. The probability distribution of a continuous random variable is shown by a density curve. The probability that X is between an interval of numbers is the area under the density curve between the interval endpoints. The probability that a continuous random variable X is exactly equal to a number is zero.</p>"},{"location":"6-Math-%26-Logic/probability/#events-and-its-types","title":"Events and its Types","text":"<p>Every possible outcome of a variable is an event.</p> <p>Simple event</p> <ul> <li>described by a single characteristic.</li> <li>For eg, a day in January from all days in 2018.</li> <li>Complement of an event A (denoted A\u2019).<ul> <li>All events that are not part of event A.</li> <li>For eg, all days from 2018 that are not in January.</li> </ul> </li> </ul> <p>Joint event</p> <ul> <li>described by two or more characteristics.</li> <li>For eg, a day in January that is also a Wednesday from all days in 2018.</li> </ul> <p>Mutually Exclusive or Disjoint Sets</p> <ul> <li>cannot occur simultaneously.</li> <li>They have no intersection outcomes.</li> <li>For eg, A = day in Jan, B = day in Feb. A and B cannot occur simultaneously.<ul> <li>In this, P(A1 U A2 U A3...) = P(A1) + P(A2) + P(A3)...</li> <li>Also, P(A &amp; B) = 0.</li> </ul> </li> </ul> <p>Collectively Exhaustive Events</p> <ul> <li>One of the event must occur</li> <li>The set of events covers the entire sample space</li> <li>For eg, A = Weekday; B = Weekend; C = January; D = Spring;<ul> <li>Events A, B, C and D are collectively exhaustive (but not mutually exclusive \u2013 a weekday can be in January or in Spring).</li> <li>Events A and B are collectively exhaustive and also mutually exclusive.</li> </ul> </li> </ul> <p>Independent Events</p> <ul> <li>not dependent on each other. That is, occurrence of one does not affect occurrence of another event.</li> </ul> <p>Note: All mutually exclusive events are dependent but not all dependent events are mutually exclusive.</p>"},{"location":"6-Math-%26-Logic/probability/#addition-rule","title":"Addition Rule","text":"<p>Addition rule of probability.</p> \\[ P(A \\cup B ) = P(A) + P(B) -P(A \\cap B) \\] <p>if mutually exclusive, then \\(P(A \\cap B) = 0\\).</p> <p>And is intersection, or is union.</p> <p>For eg, P(Jan or Wed) = P(Jan) + P(Wed) - P(Jan and Wed) = 31/365 + 52/365 - 5/365 = 78/365</p>"},{"location":"6-Math-%26-Logic/probability/#multiplication-rule","title":"Multiplication Rule","text":"<p>For independent event, what happened in past event will have no effect on current event. For eg, P(HH) or P(at least 1H in 10 flips).</p> \\[ P(HH) = 0.5 \\times 0.5 \\] <p>P(at least 1H in 10 flips) = 1 - P(All T in 10 flips)</p> \\[ 1 - (0.5)^{10} = 1023 \\div 1024 = 99.9% \\]"},{"location":"6-Math-%26-Logic/probability/#marginal-or-unconditional-probability","title":"Marginal or Unconditional Probability","text":"<ul> <li>Simple probability like P(A) = 0.2, P(B) = 0.4</li> </ul>"},{"location":"6-Math-%26-Logic/probability/#joint-probability","title":"Joint Probability","text":"<ul> <li>P(A &amp; B) both events to happen simultanieously</li> </ul>"},{"location":"6-Math-%26-Logic/probability/#conditional-probability","title":"Conditional Probability","text":"<p>When we have to find a probability under a given condition.</p> <p>Dependent Events</p> <ul> <li>A|B is 'A happening after B' or 'conditional prob of A given that B has occurred'.</li> <li>B becomes the new sample space, because it's A given B. Hence,</li> </ul> \\[ P(A|B) = \\frac{P(A \\&amp; B)}{P(B)} \\] <p>Independent Events</p> <ul> <li>if independent (does not affect each other), then</li> </ul> \\[ P(A|B) = P(A) \\] <p>Important outcome:</p> <ul> <li>When finding  P(A &amp; B) we have to consider and analyse that whether A and B are dependent or not.</li> <li>Based on dependency, our P(A &amp; B) changes as follows:</li> </ul> <p>If dependent, the probability of A and B is:</p> \\[ P(A \\&amp; B) = P(A) \\times P(B|A) = P(B) \\times P(A|B) \\] <p>else</p> \\[ P(A \\&amp; B) = P(A) \\times P(B) \\] <p>because P(B|A) = P(B), occurrence of A has no effect on B.</p> <p>Probability of A or B</p> \\[ P(A \\space or \\space B) = P(A) + P(B) - P (A \\&amp; B) \\] <p>Add all the joint probability of colectively exhaustive and mutually exclusive events to get marginal probability of one event.</p> <p>eg, Consider industries and performance below.</p> <p>| Poor |Avg|Good|Marginal  ---|  small|0.02|0.07|0.01|0.1  medium|0.12|0.3|0.18|0.6  large|0.06|0.13|0.11|0.3 Marginal|0.2|0.5|0.3|1</p>"},{"location":"6-Math-%26-Logic/probability/#counting-events","title":"Counting Events","text":""},{"location":"6-Math-%26-Logic/probability/#permutation","title":"Permutation","text":"<p>Arrange \\(n\\) people in \\(k\\) seats. To count number of ways in which this can be done we use permutation.</p> <p>For eg, arrange 6 people in 3 seats, 6.5.4 = 6! / 3! = 120.</p> \\[ _nP_k = \\frac{n!}{(n - k)!} = n(n-1)... (k  times) \\] <p>Used when order matters and pick once (without replacement).</p> <p>For eg,</p> \\[ _{10}P_3 = 10.9.8 \\]"},{"location":"6-Math-%26-Logic/probability/#combinations","title":"Combinations","text":"\\[ _nC_k = \\binom{n}{k} = \\frac{_nP_k}{k!} = \\frac{n!}{k!(n - k)!} = \\frac{n(n-1)...[k \\space times]}{k!} \\] <p>We divide it by the number of ways in which k people can be arranged in k places, i.e, k! because ABCD and BCDA are same and we are counting this extra.</p> <p>Order doesn't matter, 123 = 312.</p> <p>For eg,</p> \\[ _{10}C_3 = \\frac{10.9.8}{3.2.1} \\]"},{"location":"6-Math-%26-Logic/probability/#approach-to-solve-a-problem","title":"Approach to solve a problem","text":"<p>We can take following approaches to solve a probability problem</p> <ol> <li> <p>use simple definition,     $$ P(e) = \\frac{events \\space possible}{sample \\space space} $$</p> </li> <li> <p>Make a Contingency Table with possibilities.</p> <ol> <li>To find P(A or B), use P(A)+ P(B) - P(A and B)</li> <li>To find P(A and B), simply use (joint event)/total.</li> <li>To find P(A|B), P(A and B) / P(B)</li> </ol> </li> <li> <p>Make a Decision Tree, use when question has \"after\".</p> <ol> <li>Find branches and outcomes</li> <li>Find effective value by multiplying with probabilities</li> <li>Roll back to find effective value at each branch.</li> </ol> </li> <li> <p>Use Venn Diagram when and/or is combined with not of a event.</p> </li> <li> <p>At least or at most, use</p> </li> </ol> \\[ P(at least/most) = 1 - P(e) \\] <p>Example</p> <p>Find number of ways to arrange 1 - 10 digits in 3 places,</p> <p>Repetition allowed, order matters = 10.10.10</p> <p>Repetition not allowed, order matters = Permutation = 10.9.8</p> <p>Repetition allowed, order doesn't matter =</p> \\[ \\frac{10.10.10}{3.2.1} \\] <p>Repetition not allowed, order doesn't matter = Combination =</p> \\[ \\frac{10.9.8}{3.2.1} \\] <p>References:</p> <ul> <li>Khan Academy.</li> <li>AMPBA - ISB</li> </ul>"},{"location":"7-Other/electronics-notes/","title":"Electronics &amp; IoT","text":"<p>Notes about IOT, Electronics etc.</p>"},{"location":"7-Other/electronics-notes/#volts-amps-ohms-watts-hours","title":"Volts Amps Ohms Watts Hours","text":"<p>Voltage (V) Volts - pressure of water, or how fast the electrons are moving. volt can be measured in parallel, stays same.</p> <p>Current (I) Amps - amount of water, or number of electrons moving. Amps can be measured in series, stays same. The current through the load depends on the load and not on the supply. 2A supply means it can support load upto 2A, means it has enough electrons to move current upto 2A, however, the current drawn from supply in a circuit depends on the resistance in it, it does not depend on the supply. Higher resistance is less electrons flowing thru, hence less Amps.</p> <p>Resistor (R) Ohm - can be added in series to resist current (drops volts), so that bulb doesn't blow. bands tell ohms.</p> \\[ V = I.R , Ohm's Law \\] <p>Power (P) Watts - Power or rate of energy transfer or used.</p> \\[ P = V.I = \\frac{V^2}{R} = I^2.R \\] <p>Que - Caculate resitance required to power less volt component (LED) from high volt battery. You need:</p> <ul> <li>fwd_voltage = electronic component = LED = 3.2 volts</li> <li>source_volt = battery used / supply = 9v</li> <li>amps = component amps = amps of LED = 24mA</li> </ul> <p>R = V / I , here find V remaining to be consumed by R, Amps remains same in series.</p> <p>R = (source_volt - fwd_volt) / Amps</p> <p>R = (9-3.2) / 0.024 = 240 ohms</p> <ul> <li>This resistor should be added in series to LED. Here, as in series, resistor is taking some volt and led is taking some volt.</li> </ul>"},{"location":"7-Other/electronics-notes/#how-current-flows-in-circuit","title":"How current flows in circuit?","text":"<ul> <li>current only flows when there is potential difference,</li> <li>current is drawn only when there is space for electrons to move, or the cricuit conducts.</li> <li>we can only change volts of source, but current drawn depends on load. we cannot provide high current.</li> <li>current is amount of electrons flowing, depends inversely on resistance in circuit.</li> <li>volts is pressure or how fast electrons are flowing.</li> <li>a load, say LED, can only allow few electrons to move through (current) and at some pressure/pace (volts). if we increase volts, it will burn.</li> <li>low resistance will allow more current to flow, hence more watts.</li> <li>high resistance allows less current to flow, in series it drops volts, or reduces pressure.</li> <li>in parallel current gets multiple routes to move, hence overall current increases and resistance drops.</li> <li>in series, resistances offer more restrictions hence less current and more resistance,</li> <li>Hence<ul> <li>Series, I is same, V is different</li> <li>Parallel, I is diff, V is same.</li> </ul> </li> <li>Example: A bulb, has resistance, this defines its volts and watts, say, 4V 1W for bike meter and 4v 20W for headlight. Volt can vary and hence Current and Watts will:<ul> <li>4V 1W =&gt; 16ohm (fixed), draws 0.25A</li> <li>now connect this to 12V source</li> <li>12V 16ohm =&gt; draws 0.75A, becomes 9W.</li> <li>this is why the bulb blows when connected to high volts.</li> </ul> </li> </ul> <p>Amp Hours - measures battery capacity, as in steady current flowing through one hour. 150Ah, inverter battery will give 15A for 10hours. A typical car battery with 12 volts rating has a capacity of 48 Ah. It means that when fully charged, the battery can deliver one amp for 48 hours, two amps for 24 hours and so on.</p>"},{"location":"7-Other/electronics-notes/#electonic-components","title":"Electonic Components","text":"<p>LEDs - bulb, usually added with resister. This give resistance to circuit. Longer leg is +ve.</p> <ul> <li>RGB has common anode and cathode LED. long to GND, light then cathode else anode.</li> <li>Control brightness by PWM - pulse width modulation.</li> <li>Mine is CC.</li> </ul> <p>Multimeter - measures volts, amps and resistance. Continuity, NPN and PNP, for AC and DC. When measuring AMPs do switch red com.</p> <p>Bread board - can be used for prototyping.</p> <p>Schematics is blueprint of a circuit.</p> <p>Potentiomenter is var resistor, or regulator.</p> <p>Capacitors - store chaege and act like battery</p> <ul> <li>unit is (F) Farads, and Volts it can handle.</li> <li>Prevents sudden start of motor, bulb, helps protect jerk in movements.</li> <li>ceramic have no polarity.</li> </ul> <p>Diodes, current in one direction, valve</p> <ul> <li>forward bias and reverse bias.</li> <li>They take volts from the circuit, cylinderical with silver strip, negative.</li> <li>Has volts drop, eg, 1.1v drop reduces volt by it. It eats volts in one direction.</li> <li>acts as protection for led which can accept current in one directions only.</li> <li>1N4148 diode can be used upto 4V, single diode</li> <li>1N4007 rectifier diode, used &lt;1000V. Most used.</li> </ul> <p>Complete circuit:</p> <ul> <li>resistor to reduce volts</li> <li>capacitor to fade out led, in parallel</li> <li>diode to prevent polarity</li> </ul> <p>Relays</p> <ul> <li>electronic switch, has electromagnet. another circuit makes switch operate. retangular box. its slow, so transistor was created.</li> <li>Types:<ul> <li>Electromechanical relay - has 5 terminals, 2 of electromagnet, 1 common and 1 Normally Open, 1 Normally Closed</li> <li>solid state relay</li> </ul> </li> </ul> <ul> <li>Relay Oscillator:<ul> <li>allows on-off loop, blinking light</li> <li>add capacitor in parallel</li> <li>make electromagnet go on and cut itself</li> <li>changing capacitor size will change frequency of on and off.</li> </ul> </li> </ul> <p>Transistor</p> <ul> <li>is base + cylindrical shaped.</li> <li>has 3 legs - base, collector and emmitter. Small +ve current in base completes the circuit.</li> <li>used for switching or amplifying.</li> <li>Types:<ul> <li>BJT - bipolar juction transistor - 2 types<ul> <li>NPN - emmiter out, +ve signal in base</li> <li>PNP - emitter in, -ve signal in base</li> </ul> </li> <li>MOSFET<ul> <li>used to switch or amplify voltages in circuits.</li> <li>3terminals, gate, drain and source.</li> <li>IRFZ24N - it blocks current until some volts is applied on gate. the more the volts on gate, more current it allows.</li> <li>A09N03N - MOsfet</li> </ul> </li> </ul> </li> <li>eg, to supply small current we add high resistor in series, this can be photo resistor to make day/night switch.</li> <li>models,<ul> <li>NPN - BC547, 2N3904</li> <li>PNP - BC557, 2N3906</li> </ul> </li> <li>2N2222 is a common NPN bipolar junction transistor (BJT) used for general purpose low-power amplifying or switching applications. It is designed for low to medium current, low power, medium voltage, and can operate at moderately high frequency.</li> </ul> <p>Integrated Cuircuits (IC):</p> <ul> <li>it has more than 1 circuit inside, can have componets like resistor, transistor or capacitor. called chip.</li> <li>save time, money, energy, space.</li> <li>types<ul> <li>Analogue/lienar IC - signal on gives cont output. eg, 7805, 555, LM386N</li> <li>Digital IC - no continuous output, but O/P is based on Logic Gates. eg, 7404 NOT Gate,  7408 AND Gate IC.</li> <li>Mixed IC -  .eg, ADC 0804, Analog to digital converter IC.</li> </ul> </li> <li>Forms - DIP, SMD, TO-220, eg,<ul> <li>ATMEGA328P - Programmabel IC</li> <li>ESP8266 - wifi programmable</li> </ul> </li> <li>555 timer IC is common,<ul> <li>contains more than 20 transistors + more components.</li> <li>8 pins, 8 is +ve, 1 -ve, 3 output.</li> <li>it has combination of logic to switch on and off.</li> <li>max load 200mA. if we power component more than this load the use mosfet.</li> </ul> </li> <li>Voltage regulator IC<ul> <li>used to control voltage, eg, give different volts to diff components.</li> <li>Types:<ul> <li>Linear volt regualtor - can only down volts, wasted volts as hear, to be used with heat sink. eg, 7805 - 5V, 7809 - 9V</li> <li>Switching volts regulator - wastes less energy, can down n up volts. eg, LM2678, LM2577.</li> </ul> </li> </ul> </li> </ul> <p>Transformer</p> <ul> <li>step down - 220v to 12v, mobile charger</li> <li>step up - inverter -</li> </ul> <p>Bridge Rectifier:</p> <ul> <li>Converts AC to DC</li> </ul> <p>MicroControllers:</p> <ul> <li>can be programmed to change current of output pins</li> <li>Arduino, tiny computer on IC.</li> <li>AtTiny85</li> </ul> <p>Logic Gates:</p> <ul> <li>XOR chip is IC with 14 pins for eg.</li> </ul> <p>Binary is number to base 2:</p> <ul> <li>8 bit computer can handle number till 8 bits.</li> <li>binary half adder is used to add two numbers.</li> <li>adders can be built using gates, AND XOR etc. which are ICs having pins.</li> <li>We can extrnd this to have full binday adder and subtractor to add 8 bits numbers.</li> </ul> <p>PCB - Printed Circut Board are circuits on mdf board with sigle or multi layer copper connections. Surface Mount Components SMC are electronic components soldered on top of PCB. Through Hole Components THC are passed through hole and soldered on back of plate. Pick-and-Place machine use SMT - surface mount technology to place SMD surface mount devices on PCBs, JUKI is the company. Altium is US based.</p> <p>RF Communication module - nRF24L01 -  Rs 60. for drones. can be used for transmission and receiver. single chip radio transceiver for the world wide 2.4 - 2.5 GHz ISM band.</p> <p>Gyro and Accelero - MPU-6050 is  6-axis, cost 50. Micro Electro-mechanical system (MEMS),  It helps us to measure velocity, orientation, acceleration, displacement and other motion like features, also measure temp, -40 to 85</p> <p>Bluetooth - HC-06 is slave bluetooth module.</p> <p>Veroboard is used for prototypying before pcb, its like breadboard.</p> <p>Magnetic Sensor - A3144 - detects magnet when close</p> <p>Touch Switch - TTP223 , rs. 20. - is a PCB with A/B modes.</p> <p>Time - DS3231 RTC Rs. 250, module Precise Real-Time Clock Module is a low-cost, extremely accurate I\u00b2C real-time clock (RTC) with an integrated temperature-compensated crystal oscillator (TCXO) and crystal. The device incorporates a battery input and maintains accurate timekeeping when the main power to the device is interrupted</p> <p>LED RGB ws2812b 5v led Strip is controllable via Arduino, we can specify color and brightness of every single LED.</p>"},{"location":"7-Other/electronics-notes/#tipsconcepts","title":"Tips/Concepts","text":"<ul> <li>Didode in parallel prevent volt volt reply on connct and disconnect.</li> <li>Capacitor in parallel prevent jerk and high volts reply. Reduces plasma.</li> <li>add 1kohm resistor in series to prevent damage by current.</li> <li>resistor could drop current however, the supply volt varies, to cover this use IC to for volt drop. To cover heat loss, and make efficient use 'DC-DC step-down buck converter'. 90% efficient. Ususally in car charger to convert 12v to 5v, more..</li> </ul>"},{"location":"7-Other/electronics-notes/#arduino-kit","title":"Arduino KIT","text":"<p>Arduino boards having microporcessor. single board computer. uno for begineers, nano for breadboard. Kit has related components. It is open source microcontroller. It comes original and compatible copies. Arduino nano is 125 each and can be used as processing unit.</p> <p>It has libraries same like python to do complex stuff. Install using library manager.</p> <p>LED with 220ohm</p> <ul> <li>12mA current, LED 2V, Resistor 2.7</li> </ul> <p>Active Buzzer makes sound. It has IC for sound, green circuit is passive, black is active. Active makes sound on current while passive needs square waves with 2K and 5K freq. So we can send high low signal to a pin, varying by a delay of 1 to 10 ms. THis will make sound with freq depending on delay. We can pass notes to passive buzzer and make play any song.</p> <p>Tilt Sensor are used to detect inclination or orientation. They are reliable, low-power, long- lasting and very inexpensive. Can tell arduino about on/off based on orientation, then based on that we can make another component operate, like making LED on/off.</p> <p>servo motor is a geared one, only capable of rotating 180 degrees and is commanded by transmitting electrical pulses from your Arduino. Brown wire is GND, Red is 5V, orange is signal. Signal can be position 0-180, this will make servo move that degree as quickly as possible, then we can delay.  Need servo lib.</p> <p>Ultrasonic sensor can measure distance, HC-SR04 is inexpensive and very easy to use. Need lib. capacity of 2cm to 400cm</p> <p>DHT11 Temperature and Humidity Sensor, The sensor includes a sensor of wet components and a temperature measurement device. It returns binary data string, which is the coverted by library to tell temp and humidity. has pin GND, Data and 5V,</p> <p>Analog Joystick Module is used to control components. 5 pins, GND, VCC +5, X, Y, SW Key. It has XY analog output which gives direction with magnitude. and key is digital.</p> <ul> <li>Key on press connects to GND. Todo: A pull-up resistor or pull-down resistor is a resistor used to ensure a known state for a signal. To get accurate readings from the Key/Select pin, it should be connected to VCC with a pull-up resistor, which we can do using the built in resistors on the UNO digital pins</li> <li>Range of X or Y is from 0-1024, mid value is approx 512.</li> <li>Switch is 1/0 pressed or free.</li> </ul> <p>IR Module using lib, we can program IR receiver.</p> <ul> <li>IR hexa decimal codes are required to interpret the OP.</li> <li>IR RECEIVER SENSOR - IR detectors are essentially small microchips with a photocell that are created to detect infrared light,</li> <li>They detect and send low signal else high 5v.</li> <li>3 pins, GND -, 5V, Signal. Signal send digitalvalues which are converted to HEX by library <code>case 0xFFA25D: Serial.println(\"CH-\"); break;</code>.</li> </ul> <p>LCD Display LCD1602</p> <ul> <li>16 pins<ul> <li>VSS: A pin that connects to ground</li> <li>VDD: A pin that connects to a +5V power supply</li> <li>VO: A pin that adjusts the contrast of LCD1602</li> <li>RS: A register select pin that controls where in the LCD\u2019s memory you are writing data: either the data register, which holds what is displayed on the screen, or an instruction register, which is where the LCD\u2019s controller looks for instructions on what to do next.</li> <li>R/W: A Read/Write pin that selects reading mode or writing mode</li> <li>E: An enabling pin that causes the LDC module to execute relevant instructions when supplied with low-level energy.</li> <li>D0-D7:Pins that read and write data</li> <li>A and K: Pins that control the LED backlight</li> </ul> </li> <li>The LCD display requires six UNO pins as digital outputs. Additionally, it needs 5V and GND connections.</li> <li>We need to set Potentiometer to control brightness of Letter (not backlit) and then reset Arduino to display.</li> </ul> <p>Thermistor is simply a thermal resistor - a resistor that changes its resistance according to the temperature. 100ohm or more per degree.</p> <p>74HC595 Shift Register</p> <ul> <li>The shift register is a kind of chip containing eight memory locations, with the values 1 or 0. We input the data using the 'Data' and 'Clock' pins of the chip to set these values on or off. 8 clock pins and 8 data pins. We can combine this with arduino analog PWN write to control brightness of LED.</li> <li>Serial to Parallel Converter - useful to power multiple LEDs from one output pin.</li> <li>Pin 1 of the chip is to the left of this notch. +5v</li> <li>Pin, Q0.</li> <li>right side is Q1-Q7 and ground at bottom</li> <li>Pin 14, 12 and 11 connect to UNO.</li> </ul> <p>Stepper Motor is an electromechanical device which converts electrical pulses into discrete mechanical movements. Used for movements and controlled with pulse of current. Has driver module.</p>"},{"location":"7-Other/electronics-notes/#small-projects-and-devices","title":"Small Projects and Devices","text":"<p>Electric Motor Speed Controller</p> <ul> <li>using 555 timer IC - IP 4.5v-16v, OP &lt;200mA. pin1 ground, pin8 +ve.</li> <li>Motor, 12V, 1.5A. It needs more current, so we use mosfet  to power 12v motor and use signal from 555.</li> <li>Mosfet - IRFZ24N - &lt;17A, &lt;55V - uses small current in gate pin1 to output more current from drain pin2. Source pin3 is ground. No current in gate, no flow of current. More volt in gate, more volts from drain.- Current to gate is given by 555 pin3. This volt is on/off pulse. this gives average volts and called Pulse Width Modulation.</li> <li>Add 1k ohm resistor in series b/w 555pin3 and mosfetpin1 to prevent 555 in case mosfet malfunctions and allows 12v to flow. Also add 1k ohm resistor in parallel to discharge this current. Need Explaination.</li> <li>When motor is turned off, it produces high volts to clear magnetic field, to prevent this add flyback diode 1N4007. parallel.</li> <li>ref - https://www.youtube.com/watch?v=UPTU6nYSaMo</li> </ul> <p>5V Regulator design</p> <ul> <li>Input is 9-12V with fluctuation, but output is constant 5v.</li> <li>use an IC LM7805, takes in random 9-12v outs 5v.</li> <li>add capacitor in 0.22uF cap, in parallel to smooth drops</li> <li>add 0.1uF ceramic cap, to smooth noise.</li> <li>10uf elector cap, and 0.1uF ceramic cap in OP to smooth out flow.</li> <li>add diode in IP to prevent polarity fault. schottky diode has less drop so add it.</li> <li>ref - https://www.youtube.com/watch?v=d-j0onzzuNQ</li> <li>this has isse of heat loss by 7805.</li> </ul> <p>DTH - Free Dish - Settop Box</p> <ul> <li>SMPS - 2658A1.PCB - 200 rs - converts 220v to 5v DC</li> </ul> <p>Fan Resistor 220v B1 R-783</p> <ul> <li>cap - 3.3uF 250V</li> <li>res - 1m in parallel</li> <li>res - 4.7ohm, 0.5w</li> <li>1p4t switch.</li> </ul> <ul> <li>SE 104j2A - capacitor, 100V 2A</li> <li>BT124 600E - Thyristors - TRIACs</li> <li>ref - https://www.youtube.com/watch?v=k4c3_yCfLWA</li> </ul> <p>diac triac light dimmer circuit</p> <ul> <li>triac - bt136</li> <li>diac - DB3</li> <li>capacitor - 104k 440v</li> <li>potentiomenter - 500k</li> <li>resistor - 10k</li> <li>ref<ul> <li>en https://www.youtube.com/watch?v=OmBu3emRdV8</li> <li>hi https://www.youtube.com/watch?v=C1qGVaGgGOo</li> </ul> </li> </ul> <p>Step-down buck converters</p> <ul> <li>reduces volts without wasting energy.</li> </ul> <p>WiFi Relay Switch</p> <ul> <li>ref - https://www.youtube.com/watch?v=TZnrHkjlgLk</li> </ul> <p>Malaysian Baloon</p> <ul> <li>6v, 40mA - working.</li> </ul> <p>Trimmer</p> <ul> <li>resistor - 100ohm 5%</li> </ul> <p>D Duke Adapter</p> <ul> <li>500mA or 0.5A at 12V = 6W max load.</li> </ul> <p>Balaji Adapter</p> <ul> <li>OP = 12V 2A = 24W max load.</li> </ul> <p>Lights LEDs</p> <ul> <li>MegaGold - 2.4W = 0.2A = 200mA. 10 lights with BalaJi Adapter.</li> <li>Car Music RGB - 0.23A at 12V = 2.76W</li> </ul> <p>2CH RC Remote Control 27MHz</p> <ul> <li>RC Remote Car</li> </ul>"},{"location":"7-Other/electronics-notes/#diy-notes","title":"DIY Notes","text":"<ul> <li>building material:<ul> <li>PVC sheets, PVC pipe to flat, PVC fanti.</li> <li>MDF boards</li> <li>Rubber sheets</li> </ul> </li> <li>tools:<ul> <li>Small Drill Bits</li> <li>Glue Gun</li> <li>Fevi Quick</li> </ul> </li> <li>Elec:<ul> <li>PCB Board, empty board</li> <li>Switches.</li> <li>Hot Glue Gun</li> </ul> </li> </ul>"},{"location":"7-Other/electronics-notes/#todo","title":"Todo","text":"<ul> <li>Add remote to symphony cooler</li> <li>Add mobile controlled Motor starter and water level monitor<ul> <li>Solar tank level monitor, wifi/rf to send signals.</li> <li>Relay to start motor.</li> </ul> </li> </ul>"},{"location":"7-Other/electronics-notes/#references","title":"References","text":"<ul> <li>Learn Beginner Electronics YouTube</li> <li>Multimeter Manual - https://www.petervis.com/meters/dt830d/dt830d-how-to-use-instructions.html</li> <li>https://quadstore.in/</li> <li>Water plants auto - https://www.electromaker.io/blog/article/elecrow-smart-plant-watering-system-using-arduino-uno-review-and-tutorial</li> <li>Channels:<ul> <li>Circuit Digest - https://www.youtube.com/channel/UCy3CUAIYgZdAOG9k3IPdLmw</li> <li>Manmohan Pal - https://www.youtube.com/c/ManmohanPal</li> <li>tech Ideas - https://www.youtube.com/channel/UCNtV2t2MX3qGkBSD_uRtCGg</li> <li>The engiuneering mindset - https://www.youtube.com/c/Theengineeringmindset</li> <li>Mega Electronics - https://www.youtube.com/channel/UCl9W8s1E1aXmODa_8fTSbhw</li> <li>DD ELectro Tech - https://www.youtube.com/user/Deba9681895487</li> </ul> </li> </ul>"},{"location":"8-Blog-%26-Articles/fake-data-using-faker/","title":"How to Create fake data using Faker","text":"<p>Auuming you are using flask in <code>app.py</code> and it has <code>db</code> and <code>Employee</code> as ORM</p>"},{"location":"8-Blog-%26-Articles/fake-data-using-faker/#create-fake-function","title":"Create Fake function","text":"<pre><code>import random\nimport sys\nfrom faker import Faker\nfrom app import db, Employee\nfrom datetime import datetime\ndef create_fake_employees(n):\n\"\"\"Generate fake employees.\"\"\"\nfaker = Faker()\nfor i in range(n):\nemployee = Employee(\ncreated_date = datetime.utcnow(),\ndepartment_id = faker.bothify(text='Dept_????-########'),\nmanager = faker.name(),\nteam = faker.name(),\nhr = faker.name(),\noffice_id = 'OFC_'+str(random.randint(20, 80)),\ntype = faker.random_choices(elements=('Perm', 'Contract', 'Temp'), length=1)[0],\nsalary = random.randint(3000000, 20000000))\ndb.session.add(employee)\ndb.session.commit()\nprint(f'Added {n} fake employees to the database.')\nif __name__ == '__main__':\nif len(sys.argv) &lt;= 1:\nprint('Pass the number of employees you want to create as an argument.')\nsys.exit(1)\ncreate_fake_employees(int(sys.argv[1]))\n</code></pre>"},{"location":"8-Blog-%26-Articles/fake-data-using-faker/#execution","title":"Execution","text":"<ul> <li><code>flask --app app.py shell</code></li> <li><code>from create_fake_employees import create_fake_employees</code></li> <li><code>create_fake_employees(10)</code></li> </ul>"},{"location":"8-Blog-%26-Articles/github-pages-jekyll/","title":"Jekyll on Github","text":"<p>Github Pages are static sites that can be hosted on GitHub for free. Github Pages use Jekyll (a Ruby Gem) to build static site from markdown files.</p> <ul> <li>Do not remove this line (it will not be displayed) {:toc}</li> </ul>"},{"location":"8-Blog-%26-Articles/github-pages-jekyll/#get-started-quick","title":"Get Started - Quick","text":"<p>Use 'Jekyll Now', it is flat 30 seconds blog setup. Follow the steps below:</p> <ul> <li>You can setup Jekyll on GitHub by forking Jekyll Now repository.</li> <li>The readme.md in above repository is a very good tutorial that you can follow and setup Jekyll on your GitHub account.</li> <li>Modify config files and github settings as stated in above readme.</li> <li>your blog is live</li> </ul> <p>With this you can use your time on writing post rather than other geeky stuff, but if you need to setup everything or if it is required your can follow setting Jekyll locally below.</p> <p>Now that blog is working, we need to write posts.</p>"},{"location":"8-Blog-%26-Articles/github-pages-jekyll/#add-posts-to-the-site","title":"Add Posts to the Site","text":"<p>Posts can be published in 3 ways:</p> <ol> <li> <p>Directly write on GitHub.com: This is fastest way and requires no setup. You can go to <code>_posts</code> folder on this repository and create new .md file.</p> </li> <li> <p>Local MD files You can use Sublime, atom or any other text editor on your local machine and the upload it to GitHub or use Git locally then commit and push to GitHub.</p> </li> <li> <p>Local Jekyll setup You can install Jekyll locally on your machine. This will require you to install Ruby as well. Then on localhost you can render your entire website (blog) and see changes. Then you can push it to GitHub.</p> </li> </ol>"},{"location":"8-Blog-%26-Articles/github-pages-jekyll/#jekyll-local-setup","title":"Jekyll local setup","text":"<ul> <li>You need to have ruby, gem, gcc and g++ installed. else do <code>brew install gem</code> and all.</li> <li>Then you need to install <code>gem install bundler jekyll</code></li> <li>Next, <code>gem install github-pages</code> installs all gems required by github pages, all of the dependancies you\u2019ll need, like: kramdown, jemoji, and jekyll-sitemap</li> <li><code>jekyll new my_blog</code> creates scaffold for a new site. This is all you need to do.</li> <li><code>jekyll build</code> builds</li> <li><code>jekyll serve</code> serves the site to localhost:4000.</li> <li>Detailed article on installing jekyll, here.</li> <li>Tutorial with all steps, KBRoman.</li> <li>Advanced features: If you need to extend the functionality of Jekyll posts then advanced tutorial can be found at here.</li> </ul> <p>Issues:</p> <ul> <li>If you see permission issue on Mac, run using <code>sudo</code>. This may occur as gem and ruby are already installed on mac but in Library folder which is not writable.</li> <li>If you want to run locally already existing site, then create a new temp blog then copy 'Gemfile' and 'Gemfile.lock'. The site root should have these files. They are required to provide all gems that Jekyll requires for proper functionality.</li> </ul>"},{"location":"8-Blog-%26-Articles/github-pages-jekyll/#deploy-to-github","title":"Deploy to Github","text":"<p>Github can further be used to host your projects site. This is kind of a sub-site/sub-domain of main site.</p> <p>My site: <code>myname.github.io/</code></p> <p>Project Site: <code>myname.github.io/abc_project/</code></p> <p>All projects repository come under gh-pages branch and not master.</p> <p>Creating a sub site is same as creating a main site.</p>"},{"location":"8-Blog-%26-Articles/github-pages-jekyll/#jekyll-notes","title":"Jekyll Notes","text":"<p>Jekyll is a Ruby library to make blog and pages site.</p> <p>_config.yml has all configuration variables.</p> <p>Posts are markdown files store under _posts folder</p> <p>Pages are markdown files in root location.</p> <p>_layouts have different .html files that define the layout for example: default, pages or posts. These can include other templates from _includes folder. They have {{ content }} which gets populated by file that uses this layout.</p> <p>For eg. 'default.html' can include 'meta.html'.</p> <p>'post.html' can use 'default.html' as layout. So all code in 'post.html' will populate {{ content }} in default.html</p> <p>some_post.md can use <code>post.html</code> as layout. So all markdown from this file will be populated to {{ content }} of 'post.html'.</p> <p>To list all categories in site</p> <p>Category returns two array items, first is category name and second is another array of posts.</p> <p>Categories in site:</p> <pre><code>{\\% for category in site.categories \\%}\n- {{ category[0] }}\n{\\% endfor \\%}\n</code></pre>"},{"location":"8-Blog-%26-Articles/hello-humans/","title":"Hello Humans","text":"<p>Here is my first post on GitHub using Jekyll and I turn to my last in twenties. Phew..! life passes fast.. isn't it?</p> <p>Well, time ticks at it's own pace. So much to learn and so less time. World is running and so are we. Run.. chase your dreams.. rise and shine.. but remember, we are humans blessed enough to enjoy mother earth. Life is a journey, enjoy all ups and downs.</p> <p>Here, I basically write notes of what I learn and what I do. This helps me refer back and keep a log of how I did something. I was saving my notes locally and randomly so thought of putting them onto GitHub to centralize them and make them available to the world.</p> <p>A few posts here might not be very well document or in polished manner as they are quick notes to refer back. However, I do include the most essential part and try not to break the flow in understanding a concept.</p> <p>Thanks for landing here. A quote from Steve Jobs' speech at Harvard:</p> <p>Stay Hungry.. Stay Foolish.. ;)</p> <p>Cheers...!</p>"},{"location":"8-Blog-%26-Articles/syntax-highlight-jekyll/","title":"How to add syntax highlighting to Jekyll Sites","text":"<p>Jekyll supports syntax highlighting by default using gem <code>rouge</code>. It can highlight 100 different language.</p> <p>You need to add one line in <code>config.yml</code></p> <pre><code>highlighter: rouge\n</code></pre> <p>and need to ensure that <code>rouge</code> gem is installed. If you have forked any Jekyll site then you can skip this step, else run:</p> <pre><code>gem install rouge\n</code></pre> <p>Themes: There are many themes available for syntax highlighting. They can be previewed here. They can be downloaded from here.</p> <p>I personally prefer Github flavoured theme which I downloaded from here.</p> <p>Once you have decided the theme then you can replace the file <code>_syntax-highlighting.scss</code> file located in <code>_scss</code> directory. Every Jekyll site must have this file by default.</p> <p>Please see below some of the use cases.</p> <p>Ruby:</p> <pre><code>require 'redcarpet'\nmarkdown = Redcarpet.new(\"Hello World!\")\nputs markdown.to_html\n</code></pre> <p>Python:</p> <pre><code>import numpy as np\nimport pandas as pd\ndf = pd.read_csv('employee.csv')\ndf.head()\n</code></pre> <p>HTML</p> <pre><code>&lt;head&gt;\n&lt;body&gt;\n    Hello..!\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/","title":"Mongo DB","text":"<p>all about no sql mongo-db, notes from certification prepration</p>"},{"location":"9-Drafts/mongodb-notes/#setup","title":"Setup","text":"<p><code>~/code/mogodb</code> - it is base for project setup and is imported to eclipse.</p> <ul> <li>added new softwares are /usr/local/mogodb, apache-maven.</li> <li>spark and front end framework, FreeMarker, is added as jar to project.</li> </ul> <ul> <li>Non relational JSON db</li> <li>Does not save in table, instead stored as JSON document.</li> <li>It does not support joins and sql.</li> <li>It does not support transactions.</li> <li>It supports indexes and secondary indexes.</li> </ul> <ul> <li>MongoD is the process which runs the mongoDB.</li> <li>Shell is js shell which connects via TCP to mongoD.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#java-driver-and-web-framework","title":"Java Driver and Web Framework","text":"<ul> <li>SparkJava and FreeMarker are framework which well use to interact with mongoDB.</li> </ul> <ul> <li>SparkJava is micro web fw to setup routes.</li> <li>FreeMarker is used for HTML views.</li> </ul> <ul> <li>runs under JVM</li> <li>all this talks to mongoDB via mongoDB java driver.</li> </ul> <ul> <li>@todo: Quick Introduction to the Mongo Shell - watch at home.</li> </ul> <ul> <li>mongod is server daemon and mongo is shell that connects to it .</li> <li>data is saved in /data/db by default</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#select-where-find","title":"Select &amp; Where <code>find()</code>","text":""},{"location":"9-Drafts/mongodb-notes/#using-findone-function","title":"Using findOne function","text":"<ul> <li>It takes first argument as document in which we have key and value.</li> <li>this acts as key = column, value = value like we give in where clause.</li> </ul> <ul> <li>the second argument to findOne is the document having keys as columns we want to see and value as true to see and false to skip.</li> </ul> <ul> <li>to use gr and lt we use a sub document in argument.</li> </ul> <ul> <li>eg. db.score.find ( { score : { $gt : 35 } } )</li> </ul> <ul> <li>db.score.find ( { score : { $gt : 35 , $lte : 60} , type : \"English\" } )</li> </ul> <ul> <li>where score &gt; 35 and score &lt;= 60 and type = \"English\";</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#introduction-to-find","title":"Introduction to find()","text":"<ul> <li>the result is returned in form of batches. say 20.</li> <li>to page through type it.</li> <li>cursor on server is open. it is closed in say 10 mins on the server.</li> <li>.pretty() makes result more readable.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#querying-using-field-selection","title":"Querying using field selection","text":"<ul> <li>the 1st arg is like where clause. filter the result on matching conditions.</li> <li>it accepts doc and that is matched for results.</li> </ul> <ul> <li>@Note: We can give key without quotes but the value has to be in quotes when writing a document.</li> </ul> <ul> <li>the 2nd arg takes what we want to see in results. by default the _id column is selected. it is analogous to select clause in rdbms.</li> </ul> <ul> <li>e.g.</li> <li> <p>db.scores.find({student:19,type:\"essay\"} , {score:true,_id:false})</p> </li> </ul>"},{"location":"9-Drafts/mongodb-notes/#querying-using-gt-and-lt","title":"Querying using $gt and $lt","text":"<ul> <li>e.g.</li> <li> <p>db.scores.find({ score: { $gt : 95  }  })</p> </li> <li> <p>db.scores.find({ score: { $gt : 95 , $lte: 96 }  })</p> </li> <li> <p>db.scores.find({ score: { $gt : 95 , $lte: 96 } , type:\"essay\"  })</p> </li> </ul>"},{"location":"9-Drafts/mongodb-notes/#inequalities-on-string","title":"Inequalities on String","text":"<ul> <li>We can use lt, gt, lte, gte but this gives result based on UTF sorting of alphabets.</li> <li>eg. { name : { $lte : \"D\" } } # it may produce absurd results as well.</li> </ul> <ul> <li>We have $type in which we match the datatype of a field. It accepts a number based on BSON type.</li> <li>e.g: name : { $type : 2 } - this gives names having string value</li> </ul> <ul> <li>We have $regex which accepts regular expressions.</li> </ul> <ul> <li>We have $exists, it accepts a key name. It returns only that document which has this key in it.</li> <li>e.g: db.emp.find ( { profession : { $exists : true } } )</li> <li>Nested content is not matched, only top level array element is matched.</li> </ul> <ul> <li>$all is is like a sub set of elements. all should be there but in any order</li> </ul> <ul> <li>$in is like any of it should match.</li> </ul> <ul> <li>We can use gt and lt in string Comparisons.</li> </ul> <pre><code>    &gt; db.people.find()\n{ \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"vaibhav\", \"age\" : 30 }\n{ \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n{ \"_id\" : ObjectId(\"57bfa58cdaf90e8c76d19cc8\"), \"name\" : \"rahul\" }\n{ \"_id\" : ObjectId(\"57bfa594daf90e8c76d19cc9\"), \"name\" : \"Kashish\" }\n{ \"_id\" : ObjectId(\"57bfa59bdaf90e8c76d19cca\"), \"name\" : \"Patnam\" }\n{ \"_id\" : ObjectId(\"57bfa5a3daf90e8c76d19ccb\"), \"name\" : \"Jaspreet\" }\n{ \"_id\" : ObjectId(\"57bfa5aadaf90e8c76d19ccc\"), \"name\" : \"Ankit\" }\n{ \"_id\" : ObjectId(\"57bfa5b1daf90e8c76d19ccd\"), \"name\" : \"Hardeep\" }\n{ \"_id\" : ObjectId(\"57bfa5bcdaf90e8c76d19cce\"), \"name\" : \"Anuj\" }\n{ \"_id\" : ObjectId(\"57bfa5c0daf90e8c76d19ccf\"), \"name\" : \"Arjun\" }\n&gt; db.people.find({name:{$lt:\"D\"}})\n{ \"_id\" : ObjectId(\"57bfa5aadaf90e8c76d19ccc\"), \"name\" : \"Ankit\" }\n{ \"_id\" : ObjectId(\"57bfa5bcdaf90e8c76d19cce\"), \"name\" : \"Anuj\" }\n{ \"_id\" : ObjectId(\"57bfa5c0daf90e8c76d19ccf\"), \"name\" : \"Arjun\" }\n&gt; db.people.find({name:{$gt:\"D\",$lt:\"M\"}})\n{ \"_id\" : ObjectId(\"57bfa594daf90e8c76d19cc9\"), \"name\" : \"Kashish\" }\n{ \"_id\" : ObjectId(\"57bfa5a3daf90e8c76d19ccb\"), \"name\" : \"Jaspreet\" }\n{ \"_id\" : ObjectId(\"57bfa5b1daf90e8c76d19ccd\"), \"name\" : \"Hardeep\" }\n</code></pre> <ul> <li>In mongodb the name field can have numeric value as well. But with above query we will get only the result we got. name:42 for eg will not be retrieved.</li> <li>hence mongodb Comparison operator donot cross the data type boundary.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#using-regex-exists-and-type","title":"Using $regex, $exists and $type","text":"<ul> <li>exists is used to find if a certain filed is present in the document.</li> <li>type is used to find doc having value of particular type say string or number. the type code can be found from bson.org.</li> <li>regex is used to match regular expressions.</li> </ul> <pre><code>    &gt; db.people.find({age:{$exists:false}})\n{ \"_id\" : ObjectId(\"57bfa58cdaf90e8c76d19cc8\"), \"name\" : \"rahul\" }\n{ \"_id\" : ObjectId(\"57bfa594daf90e8c76d19cc9\"), \"name\" : \"Kashish\" }\n{ \"_id\" : ObjectId(\"57bfa59bdaf90e8c76d19cca\"), \"name\" : \"Patnam\" }\n{ \"_id\" : ObjectId(\"57bfa5a3daf90e8c76d19ccb\"), \"name\" : \"Jaspreet\" }\n{ \"_id\" : ObjectId(\"57bfa5aadaf90e8c76d19ccc\"), \"name\" : \"Ankit\" }\n{ \"_id\" : ObjectId(\"57bfa5b1daf90e8c76d19ccd\"), \"name\" : \"Hardeep\" }\n{ \"_id\" : ObjectId(\"57bfa5bcdaf90e8c76d19cce\"), \"name\" : \"Anuj\" }\n{ \"_id\" : ObjectId(\"57bfa5c0daf90e8c76d19ccf\"), \"name\" : \"Arjun\" }\n{ \"_id\" : ObjectId(\"57bfa78fdaf90e8c76d19cd0\"), \"name\" : 42 }\n&gt; db.people.find({age:{$exists:true}})\n{ \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"vaibhav\", \"age\" : 30 }\n{ \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n&gt; db.people.find({name:{$type:2}}) //2 is code for string\n{ \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"vaibhav\", \"age\" : 30 }\n{ \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n{ \"_id\" : ObjectId(\"57bfa58cdaf90e8c76d19cc8\"), \"name\" : \"rahul\" }\n{ \"_id\" : ObjectId(\"57bfa594daf90e8c76d19cc9\"), \"name\" : \"Kashish\" }\n{ \"_id\" : ObjectId(\"57bfa59bdaf90e8c76d19cca\"), \"name\" : \"Patnam\" }\n{ \"_id\" : ObjectId(\"57bfa5a3daf90e8c76d19ccb\"), \"name\" : \"Jaspreet\" }\n{ \"_id\" : ObjectId(\"57bfa5aadaf90e8c76d19ccc\"), \"name\" : \"Ankit\" }\n{ \"_id\" : ObjectId(\"57bfa5b1daf90e8c76d19ccd\"), \"name\" : \"Hardeep\" }\n{ \"_id\" : ObjectId(\"57bfa5bcdaf90e8c76d19cce\"), \"name\" : \"Anuj\" }\n{ \"_id\" : ObjectId(\"57bfa5c0daf90e8c76d19ccf\"), \"name\" : \"Arjun\" }\n&gt; db.people.find({name:{ $regex: \"a\"  }}) // all that have a somewhere\n{ \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"vaibhav\", \"age\" : 30 }\n{ \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n{ \"_id\" : ObjectId(\"57bfa58cdaf90e8c76d19cc8\"), \"name\" : \"rahul\" }\n{ \"_id\" : ObjectId(\"57bfa594daf90e8c76d19cc9\"), \"name\" : \"Kashish\" }\n{ \"_id\" : ObjectId(\"57bfa59bdaf90e8c76d19cca\"), \"name\" : \"Patnam\" }\n{ \"_id\" : ObjectId(\"57bfa5a3daf90e8c76d19ccb\"), \"name\" : \"Jaspreet\" }\n{ \"_id\" : ObjectId(\"57bfa5b1daf90e8c76d19ccd\"), \"name\" : \"Hardeep\" }\n&gt; db.people.find({name:{ $regex: \"e$\"  }}) //ends with e\n&gt; db.people.find({name:{ $regex: \"a$\"  }}) //ends with a\n{ \"_id\" : ObjectId(\"57bfa59bdaf90e8c76d19cca\"), \"name\" : \"Patnam\" }\n&gt; db.people.find({name:{ $regex: \"^A\"  }}) //begins with A\n{ \"_id\" : ObjectId(\"57bfa5aadaf90e8c76d19ccc\"), \"name\" : \"Ankit\" }\n{ \"_id\" : ObjectId(\"57bfa5bcdaf90e8c76d19cce\"), \"name\" : \"Anuj\" }\n{ \"_id\" : ObjectId(\"57bfa5c0daf90e8c76d19ccf\"), \"name\" : \"Arjun\" }\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#using-or","title":"Using $or","text":"<ul> <li>$or takes in an array of documents and combines them with or conditions.</li> </ul> <ul> <li>when the value is array in document and we specify it to match in find, then only the outer array is looked in.</li> <li>no recursion occurs or inner depth arrays are matched.</li> </ul> <ul> <li>MongoDB has no sql language. Instead it has functions that have arguments passes to them.</li> </ul> <pre><code>    &gt; db.people.find({ $or : [ {name:{$regex:\"e\"}} , { age : { $exists:true } } ] });\n{ \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"vaibhav\", \"age\" : 30 }\n{ \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n{ \"_id\" : ObjectId(\"57bfa5a3daf90e8c76d19ccb\"), \"name\" : \"Jaspreet\" }\n{ \"_id\" : ObjectId(\"57bfa5b1daf90e8c76d19ccd\"), \"name\" : \"Hardeep\" }\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#using-and","title":"Using $and","text":"<ul> <li>Same as we use $or.</li> </ul> <pre><code>    &gt; db.people.find({ $and : [ {name:{$regex:\"a\"}} , { name : { $gt:\"K\" } } ] });\n{ \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"vaibhav\", \"age\" : 30 }\n{ \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n{ \"_id\" : ObjectId(\"57bfa58cdaf90e8c76d19cc8\"), \"name\" : \"rahul\" }\n{ \"_id\" : ObjectId(\"57bfa594daf90e8c76d19cc9\"), \"name\" : \"Kashish\" }\n{ \"_id\" : ObjectId(\"57bfa59bdaf90e8c76d19cca\"), \"name\" : \"Patnam\" }\n&gt; db.people.find( {name:{$regex:\"a\"}, name : { $gt:\"K\" } } );\n</code></pre> <ul> <li>This query also gives same result as the above one. And this more efficient as well.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#querying-inside-arrays","title":"Querying inside Arrays","text":"<ul> <li>MongoDB has polymorphic find. It also evaluates for matching array elements.</li> </ul> <pre><code>    &gt; db.accounts.find().pretty();\n{ \"_id\" : ObjectId(\"57bff4973df8f8d7306e7918\") }\n{\n\"_id\" : ObjectId(\"57bff4d93df8f8d7306e7919\"),\n\"name\" : \"vaibhav\",\n\"favorites\" : [\n\"ice cream\",\n\"beer\"\n]\n}\n{\n\"_id\" : ObjectId(\"57bff5043df8f8d7306e791a\"),\n\"name\" : \"Neeraj\",\n\"favorites\" : [\n\"beer\",\n\"Spring Roll\"\n]\n}\n&gt; db.accounts.find({favorites:\"beer\"});\n{ \"_id\" : ObjectId(\"57bff4d93df8f8d7306e7919\"), \"name\" : \"vaibhav\", \"favorites\"\n: [ \"ice cream\", \"beer\" ] }\n{ \"_id\" : ObjectId(\"57bff5043df8f8d7306e791a\"), \"name\" : \"Neeraj\", \"favorites\" :\n[ \"beer\", \"Spring Roll\" ] }\n&gt;\n</code></pre> <ul> <li>Here nested contents are not matched. Only first level is looked into.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#using-in-and-all","title":"Using $in and $all","text":"<ul> <li>The $all operator matches all the elements that are specified with elements present inside the array.</li> </ul> <pre><code>    db.accounts.find({favorites : {$all : [ \"beer\", \"cheeze\" ]} })\n</code></pre> <ul> <li>The $in operator is used to filter results by having value in the values specified in $in array.</li> </ul> <pre><code>    &gt; db.accounts.find({name: {$in: [\"Sahiba\",\"Neeraj\"]}});\n{ \"_id\" : ObjectId(\"57bff5043df8f8d7306e791a\"), \"name\" : \"Neeraj\", \"favorites\" :\n[ \"beer\", \"Spring Roll\" ] }\n{ \"_id\" : ObjectId(\"57c017fc3df8f8d7306e791b\"), \"name\" : \"Sahiba\", \"favorites\" :\n[ \"beer\", \"Momo\", \"cheeze\" ] }\n&gt;\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#queries-with-dot-notation","title":"Queries with dot notation","text":"<ul> <li>to match nested documents, if we specify document in nested way then it is mactched exactly.</li> <li>we cannot match one key value. Not even in reversed order.</li> </ul> <pre><code>    {\n\"_id\" : ObjectId(\"57c06919daf90e8c76d19cd2\"),\n\"name\" : \"Rahul\",\n\"email\" : {\n\"work\" : \"rahul@info.com\",\n\"personal\" : \"rgw@live.in\"\n}\n}\n</code></pre> <ul> <li>to find with email we have to pass exact email doc in find clause.</li> <li>Even the order of work and personal needs to be same.</li> </ul> <ul> <li>To query one part of doc,</li> </ul> <pre><code>    &gt; db.users.find({\"email.work\":\"rahul@info.com\"});\n{ \"_id\" : ObjectId(\"57c06919daf90e8c76d19cd2\"), \"name\" : \"Rahul\", \"email\" : { \"work\" : \"rahul@info.com\", \"personal\" : \"rgw@live.in\" } }\n&gt;\n</code></pre> <ul> <li>if we use . notation then we can match on value.</li> <li>e.g. email : <code>{ work: \"abc\", personal: \"xyz\"}</code></li> </ul> <ul> <li>then email.work : \"abc\" - this fetches and gives result, while</li> <li>email : { work: \"abc\" } - this will not match as personal is also there in doc and byte by byte match will fail.</li> </ul> <ul> <li>Suppose a simple e-commerce product catalog called catalog with documents that look like this:</li> </ul> <pre><code>    { product : \"Super Duper-o-phonic\",\nprice : 100000000000,\nreviews : [ { user : \"fred\", comment : \"Great!\" , rating : 5 },\n{ user : \"tom\" , comment : \"I agree with Fred, somewhat!\" , rating : 4 } ],\n... }\n</code></pre> <ul> <li>Write a query that finds all products that cost more than 10,000 and that have a rating of 5 or better.</li> </ul> <ul> <li>Ans:</li> </ul> <pre><code>    db.catalog.find(\n{\n\"price\" : {\"$gt\" : 10000},\n\"reviews.rating\" : {\"$gte\" : 5}\n}\n);\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#querying-cursors","title":"Querying, Cursors","text":"<ul> <li>cur = db.sb.find();</li> <li>cur.next(); - returns next doc</li> <li>cur.hasNext(); - true if there is next doc</li> <li>cur.sort({name:-1}) - sorts by descending name order</li> <li>cur.limit(5) - limits result set to 5, database only returns 5 docs.</li> <li>cur.sort({name:-1}).limit(5) - can be combined this way.</li> <li>cur.sort({name:-1}).limit(5).skip(2) - this sorts, skips 2 and shows 3 results. this sequence is followed by db engine,</li> <li>the sort, skip and limit is sent to db and performed on server, not on cursor in the memory.</li> </ul> <ul> <li>limit and sort are processed on server side and not in memory on client side.</li> </ul> <p>Q. When can you change the behavior of a cursor, by applying a sort, skip, or limit to it? A. This can be done at any point before the first document is called and before you''ve checked to see if it is empty.</p>"},{"location":"9-Drafts/mongodb-notes/#counting-results","title":"Counting Results","text":"<pre><code>    db.abc.count();\ndb.abc.count({age : 34}); - arguments accepted are same as find();\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#updates","title":"Updates","text":"<ul> <li>its accepts two arguments, one is analogous to where clause like we pass in find command.</li> <li>The second argument is what we want to replace in the found doc. All the key:value in second arg replaces all the existing key:value in document except the _id field.</li> <li>It basically replaces wholosole document but it is dangerous.</li> <li>it replaces completely.</li> </ul> <pre><code>    &gt; db.people.update({name:\"Rahul\"},{name:\"Rahul\",age:32});\nWriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#set-unset-inc","title":"Set, Unset, Inc","text":"<ul> <li>We can use update with $set to change only a particular key:value.</li> <li>e.g. db.people.update({name:Vaibhav},{$set : {  key:value, age:30 }})</li> </ul> <ul> <li>if the field does not exist then it will be added.</li> </ul> <ul> <li>db.people.update({ name:\"Vaibhav\"}, { $inc : { \"age\" : 1 }}); - this increases age by 1, if it age does not exist then it is crated as age:1.</li> </ul> <ul> <li>e.g.     &gt; db.people.update({name:\"vaibhav\"},{$set : { \"name\":\"Vaibhav\" } });     WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#unset-command","title":"$unset Command","text":"<ul> <li>it is used to remove a particular key value from a document.</li> </ul> <p>```js db.people.update({key:value},{$unset,{key:1}});     the second key value is removed from document. <pre><code>```js\n    &gt; db.people.update({name:\"Rahul\"},{$unset:{age:1}})\n    WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n    &gt; db.people.find();\n    { \"_id\" : ObjectId(\"57befca2daf90e8c76d1910e\"), \"name\" : \"Vaibhav\", \"age\" : 30 }\n    { \"_id\" : ObjectId(\"57befdbddaf90e8c76d1910f\"), \"name\" : \"neeraj\", \"age\" : 31 }\n    { \"_id\" : ObjectId(\"57bfa58cdaf90e8c76d19cc8\"), \"name\" : \"Rahul\" }\n\n    &gt; db.people.update({name:\"Rahul\"},{$unset:{age:-1}})\n    this also removes the age from the document.\n</code></pre></p>"},{"location":"9-Drafts/mongodb-notes/#using-push-pop-pull-pullall-addtoset","title":"Using $push, $pop, $pull, $pullAll, $addToSet","text":"<ul> <li>a:[1,2,3,4,5] - is and array key value</li> <li>.update({find},{$set:{\"a.2\":5}}) - updates third value in array to 5.</li> <li>$push:{a:10} - add 10 in array.</li> <li>$pop:{a:1} - removes right most element.</li> <li>$pop:{a:-1} - removes left most element.</li> <li>$pushAll:{a:[3,54,23,5]} - pushes 4 more element to the array. It duplicates element even if it exists.</li> <li>same way we have pull and pullAll operators.</li> <li>$addToSet - add element to array if it does not exist. It does not dupicate a value.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#upserts","title":"Upserts","text":"<ul> <li>Updates if record exists else inserts. So if matching values are found then it updates. else it inserts.</li> <li>e.g. db.people.update({name:\"Rahul\"}, {$set: {age:28}} , { upsert : true } );</li> <li>The last argument tells shell to insert if name:Rahul is not in the collection.</li> <li>If the matching condition is not enought to find a particular result then also mongodb will insert the new doc.</li> </ul> <pre><code>    &gt; db.people.update({age:{$gt:50}},{name:\"Sunny\"},{upsert:true})\nWriteResult({\n\"nMatched\" : 0,\n\"nUpserted\" : 1,\n\"nModified\" : 0,\n\"_id\" : ObjectId(\"57c169edc1fc9c52ee7d6103\")\n})\nThis insers a new document to the collection:\n{ \"_id\" : ObjectId(\"57c169edc1fc9c52ee7d6103\"), \"name\" : \"Sunny\" }\n</code></pre> <ul> <li>it can be used when we need to mix data from someother collection and we are not sure if the doc exists or not.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#multi-update","title":"Multi-Update","text":"<ul> <li>by default update command only update a single record even if first argument provides more than one result.</li> <li>to update multiple rows provide 3rd argument as { multi : true }</li> <li>e.g. db.people.update( {}, {$set : { title: \"Dr\" }} , { multi : true } ) # this matches every doc because of find {}.</li> </ul> <ul> <li>this happens because MongoDB provides single thread to write operation.</li> <li>if multiple operations are performed on single document then it is mutually shared and one process updates and waits for other to</li> <li>update and so on.</li> </ul> <ul> <li>In multi-update there is pause and yield mechanism that follow. The multi update updates say 4 doc and then  pause to allow other write operation to occur on the document. then again picks the doc and updates other 4 doc.</li> <li>it allows other readers and writers to operator.</li> <li>mongodb does not allow isolated transaction while these multi updates are occurring.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#remove","title":"Remove","text":"<ul> <li>first argument is same as find, the document should be passed. Must pass a doc, else all doc will be removed.</li> <li>{name: {$gt : \"M\"}} - all after m are removed.</li> </ul> <ul> <li>e.g.</li> <li> <p>db.people.remove({name:\"Anuj\"});</p> </li> <li>WriteResult({ \"nRemoved\" : 1 })</li> </ul> <ul> <li>blank removes all the records one by one.</li> <li>contrary to drop.</li> <li>db.coll.drop();</li> <li>which removes all doc at</li> </ul> <ul> <li>drop is faster and also removes other data associated with the collection.</li> </ul> <ul> <li>by remove the indexes are not removed, while drop removes the indexes as well.</li> <li>also in remove a write or read operation may see a collection with half removed records. this does not happen in case of drop.</li> <li>also in here one doc is not half removed. it is isolated and atomic to a particular read write operation.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#java-driver","title":"Java driver","text":"<ul> <li>Add dependecy in pom.xml, it adds necessary jars</li> <li>create db connection client,</li> <li>db connection handle,</li> <li>provide db name.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#java-driver-representing-documents","title":"Java Driver: Representing Documents","text":"<ul> <li>We can represent docs using BSON Document class.</li> <li>we can append to the object as many doc as we want.</li> <li>it accepts different data types as well.</li> <li>Document class has helper functions like getString(), getInteger() that convert the object to particular data tyoe and then return the value.</li> </ul> <ul> <li>$or takes in an array of documents and combines them with or conditions.</li> </ul> <ul> <li>when the value is array in document and we specify it to match in find, then only the outer array is looked in.</li> <li>no recursion occurs or inner depth arrays are matched.</li> </ul> <ul> <li>projection is used to include and exclude coloumns.</li> </ul> <pre><code>    col.find(doc)\n.projection(doc)\n.sort(doc)\n.skip(20)\n.limit(10)\n.into(doc);\n</code></pre> <ul> <li>each of above doc can be replaced by builders.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#update-and-replace","title":"Update and replace","text":"<ul> <li>replaceOne, update is used to update the information.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#delete","title":"delete","text":"<ul> <li>deleteOne()</li> <li>deleteMany()</li> <li>find takes filter as document to provide where clause functionality.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#blog-internals","title":"Blog, internals","text":"<ul> <li>DAO is Data Access Object</li> <li>it is java class to access data of various objects. like user, session, blog etc.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#session-management","title":"session management","text":"<ul> <li>get signup</li> <li>result is singup page</li> <li>post details</li> <li>valid then writes to users, sessions table table, store cookie, redirects to welcome page</li> <li>sessions table holds new session.</li> </ul> <ul> <li>the id value in cookie in browser is same what we store in session collection.</li> </ul> <p>Week 2 ends</p> <p>Week 3 begins: Schema Design</p>"},{"location":"9-Drafts/mongodb-notes/#schema-design","title":"Schema Design","text":"<ul> <li>can keep in 3rd normal form.</li> <li>but in mongo keep in application read form.</li> <li>organise to suit application data access pattern.</li> <li>imp fatc</li> <li>pre joins/embed</li> <li>no join</li> <li>no constraints</li> <li>atomic operations but no transaction</li> <li>no declared schema, but has a similar struct in a collection,</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#transaction-in-mongodb","title":"Transaction in MongoDB","text":"<ul> <li>we have atomicity possible in MongoDB</li> <li>we can achieve Transaction by making the whole Transaction in one doc only, instead of in multiple docs using join.</li> <li>MongoDB will make sure that doc is locked and is seen only after an update.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#one-to-one","title":"One to One","text":"<ul> <li>eny one can embed in other,</li> <li>should avoid embedding if doc size grows more than 16mb</li> <li>or to avoid bulk sizing.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#one-to-many","title":"One to many","text":"<ul> <li>there should be two collections with link in id.</li> <li>in case of, \"One to Few\", the few ones should be embedded into the one.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#many-to-many","title":"Many to Many","text":"<ul> <li>have to embedd into each other as array of IDs,</li> <li>for some reasons can be embedded as well.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#benefits-of-embedding","title":"Benefits of embedding","text":"<ul> <li>High latency and high bandwidth of disk.</li> <li>so if disk spins once then we can quickly get data.</li> <li>but for one spin it takes time.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#trees","title":"Trees","text":"<ul> <li>To represent trees, add ancestors, complete list with hierarchies.</li> </ul> <p>week 3 ends, week 4</p>"},{"location":"9-Drafts/mongodb-notes/#performace","title":"Performace","text":"<p>Performace can be increased by storage engine. from 3.0 we have pluggable storage engines.</p>"},{"location":"9-Drafts/mongodb-notes/#storage-engines-introduction","title":"Storage Engines: Introduction","text":"<p>Engine allows mongodb to talk to disks:</p> <ul> <li>Mongo has pluggabel storage engines form 3.0;</li> <li>it decides what ot keep in mem and wht in disk. Since disks are slow.</li> <li>it doesnt effect communication bw servers.</li> </ul> <p>MMAP:</p> <ul> <li>Asks to read data form memory in a page. If not found then data is brought from disk.</li> <li>multile reader single writer lock</li> <li>collection le=vl locking is done.</li> <li>only one write in 1 collection</li> <li>multile writers can happen in diff coll</li> <li>in place update occurs but if size excceeds then collection is moved to a differnt place.</li> <li>so power of two sizes is used in whcih a collection is kept in mem with more size as required to grow doc.</li> <li>os makes decision for managing in mem and in disk, db does not deciede.</li> <li>the minimum record space in MongoDB 3.0 is 32 bytes.</li> <li>MMAPv1 automatically allocates power-of-two-sized documents when new documents are inserted</li> <li>MMAPv1 is built on top of the mmap system call that maps files into memory</li> </ul> <p>WiredTiger:</p> <ul> <li>It is faster</li> <li>document lvl concurrency</li> <li>lock free, optimistic concurrency</li> <li>two writes cannot happen 2gthr.</li> <li>100gb data file is brought in mem in pages.</li> <li>WT manages what can be in mem and wht can be in disk,</li> <li>in mem not compressed, in disk it is compressed.</li> <li>compresses data of doc and indexes.</li> <li>no inplace update.</li> <li>writes the data to new place. and  frees old one.</li> <li>marks old as unused and creates new.</li> <li>this allows doc lvl concurrency.</li> <li>overall faster. <code>mongod -dbpath WT -storageEngine WiredTiger</code></li> </ul> <ul> <li>new dir is required to change engine bcz it cannot read other eni=gine memory. <code>mongod -dbpath new_dir -storageEngine WiredTiger</code></li> </ul>"},{"location":"9-Drafts/mongodb-notes/#indexes","title":"indexes","text":"<ul> <li>when a collection is stored in a disk it is stored in random order.</li> <li>to find all like name = some. the scan all doc. can be million.</li> <li>this determines speed and performace.</li> </ul> <ul> <li>index is ordered set of thing,</li> </ul> <ul> <li>may be alphabetically sorted. it has pointer to physical location.</li> </ul> <ul> <li>it uses binaray search and it will take log(2) to provide the doc.</li> </ul> <ul> <li>index can be for combinarion. like naem, hair color.</li> <li>then index entry is combinarion of cols.</li> </ul> <ul> <li>it can be used for just.</li> <li>name</li> <li>name, hairColor,</li> <li>name, hairColor, DOB</li> </ul> <ul> <li>but not</li> <li>hairColor</li> <li>or DOB.</li> </ul> <ul> <li>if we change anything on doc. then bTree is updated. so writes will be slower.</li> <li>reads will be much faster.</li> </ul> <ul> <li>insert all data and then create index.</li> </ul> <ul> <li>index uses disc space too. so cant be crated for all keys,</li> </ul> <ul> <li>so 10 million reocrds can be indexed for faster reads and redice disc IO.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#creating-indexes","title":"Creating Indexes","text":"<ul> <li>10 million students with score of 4 exams.</li> </ul> <ul> <li>explain commands tells what db is doing when we query.</li> </ul> <ul> <li>db.students.explain.find({student_id:5});</li> </ul> <ul> <li>in winning plan:<ul> <li>doing a collection scan/</li> <li>findOne is faster,</li> </ul> </li> </ul> <ul> <li>db.students.createIndex({student_id:1}); - student id ascending.</li> <li>it takes a while to create an index.</li> </ul> <ul> <li>now the queries are nice and fast.</li> </ul> <ul> <li>now on explain the winning plan shows that</li> <li>it uses indexName student_id.</li> </ul> <ul> <li>db.students.explain(true).find({student_id:5});</li> <li>this executes and tells docs scanned as well.</li> <li>it gives execution stages.</li> </ul> <ul> <li>compound index:<ul> <li>db.students.explain.find({student_id:1, class_id:-1});</li> <li>this sorts the index as stated.</li> </ul> </li> </ul>"},{"location":"9-Drafts/mongodb-notes/#discovering-and-deleting-indexes","title":"Discovering and deleting indexes","text":"<ul> <li>db.students.getIndexes(); - lists indexes</li> <li>db.students.dropIndex({student_id:1}); - deletes index.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#multikey-indexes","title":"multiKey Indexes","text":"<ul> <li>these are created on arrays.</li> <li>if we have arrays liek tags.</li> <li>then index can be created for all elements in array.</li> <li>we cant combine two arrays index.</li> <li>arrays cna be combined with a single value column.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#dot-notaton-and-multi-key-index","title":"Dot Notaton and multi key index","text":"<ul> <li>to reach indide an array or embedded doc.</li> </ul> <ul> <li>to create index on array elemnt.</li> </ul> <ul> <li>db.students.createIndex({'scores.score':1});</li> <li>this takes a long time and created an index.</li> <li>it is multi key index.</li> </ul> <ul> <li>find scores.score $gt 99 with explain</li> </ul> <ul> <li>show s winningplan with index being used.</li> </ul> <ul> <li>find ppl with exam score above 99.</li> </ul> <ul> <li>db.students.find({'scores': {\\(elemMatch: {type:'exam', score:{\\)gt:99.9}}}});</li> </ul> <ul> <li>it matches for element with match at least one.</li> </ul> <ul> <li>but if we run it with explain the we see that in winnig plan:</li> </ul> <ul> <li>it finds score 99.8 to inf</li> <li>then finds docs with type exam, so it examined all document.</li> </ul> <ul> <li>so all docs were examined.</li> </ul> <ul> <li>we can make a mistake by using AND operator because it doesnot gurantee the correct result.</li> <li>explain output tell more.</li> <li>next stage in winning plan better explains.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#index-creation-options-unique","title":"Index Creation Options, Unique","text":"<p>- - no two docs can have same key if it is indexed.</p> <ul> <li>we can make a unique index.</li> </ul> <ul> <li>db.stuff.createIndex({thing:1}, {unique:true});</li> </ul> <ul> <li>this makes things column unique.</li> <li>and if the data has duplicate values then we cannot create the unique index. we get an error.</li> </ul> <ul> <li>we get duplicate key error if we inset dulplicate value.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#sparse-indexes","title":"Sparse Indexes","text":"<ul> <li>ti can be used when index key is missing in doc.</li> <li>so id we have c in few docs.</li> <li>then  unique index will be created on thise that have c value and rest will be left inseted of having null causing unique to break.</li> </ul> <ul> <li>so to create a unique index on phone numbers we can make sparse index.</li> </ul> <ul> <li>db.employees.createIndex({cell:1},{unique:true, sparse:true});</li> <li>this will make an index on and will neglect nulls.</li> </ul> <ul> <li>check using getIndexes.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#background-index-creation","title":"Background Index Creation","text":"<ul> <li>foreground is fast</li> <li>blocks all readers and writes.</li> <li>so cannot do on prod server.</li> </ul> <ul> <li>in Background</li> <li>it is slower</li> <li>dont block r/w.</li> </ul> <ul> <li>to work on replica set working set, take one out and create index on one and then rotate around to create on all. without performace bounty.</li> </ul> <ul> <li>db.students.createIndex({'scores.score':1}, {background:true});</li> <li>this will not create a r/w lock in collection.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#using-explain","title":"Using Explain","text":"<ul> <li>it does not bring data to clientt].</li> <li>it is used to see whats gonna happen.</li> </ul> <ul> <li>from 3.0 explain changed</li> <li>explain returns and explainable object.</li> <li>we can see find, updatem remove, aggregate but not</li> <li>insert.</li> </ul> <ul> <li>db.foo.explain().find()</li> <li>.update() - etc..</li> </ul> <ul> <li>we can see things like docs scanned ,  n returned</li> <li>indexes used etc.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#explain-verbosity","title":"Explain verbosity","text":"<p>- - query Planner is default. - we have execution stats and - allPlans Execution.</p> <ul> <li>these are level of output.</li> </ul> <ul> <li>var exp =  db.example.explain(\"executionStats\");</li> <li>exp.find({a: 17, b:57});</li> </ul> <ul> <li>it gives winning plan, query planner.</li> <li>in executionstats we get</li> <li>nReturned,</li> <li>executionTimeMillis.</li> <li>in each stage we ger doc returned,</li> </ul> <ul> <li>index is bound to min and max.</li> </ul> <ul> <li>index showuld be created to be used.</li> <li>all query should use atleast one index.</li> </ul> <ul> <li>so the index which is never used is waste</li> <li>and query which is not using atleast one index should be optimized.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#covered-queries","title":"Covered queries","text":"<ul> <li>query which can be looked from index only without examining the documents is called covered query.</li> </ul> <ul> <li>so if we have i,j,k as keys and we have index on them as well.</li> <li>and if we find (  { i:25, j:87} )</li> <li>then it will use index adn also use the docs.</li> <li>docs are used because we need _id filed as well/</li> <li>which is not in index and is picked from the docs.</li> <li>so avoid fetching _id and get faster results.</li> </ul> <ul> <li>also, we need to project exactly what we need and what we don;t</li> <li>if we say _id:0</li> <li>then too the docs will be scanned.</li> </ul> <ul> <li>mongodb examines docs</li> <li>we should specify which column we need and also make _id:0 to not show ID.</li> <li>then mongodb looks lesser docs. it may only look indexes</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#when-is-an-index-used-choosing-an-index","title":"When is an index used, choosing an index","text":"<ul> <li>cooses index.</li> <li>created query plans for selected.</li> <li>then the fastest plan is picked.</li> <li>winning is :</li> <li>returned all, or</li> <li>returned a threshhold sorted.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#index-sizes","title":"Index Sizes","text":"<ul> <li>we should pay attension on size of indexes</li> <li>index should fit into memory (ram) for better performace</li> <li>index size depends on storage engines</li> <li>In fact, the index size can be considerably smaller (at the cost of some CPU space) in WiredTiger with --wiredTigerIndexPrefixCompression enabled.</li> <li>size can be seen using stat command.</li> <li>e.g. db.students.stats();</li> <li>db.students.totalIndexSize();</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#number-of-index-entries-cardinality","title":"Number of Index Entries, Cardinality","text":"<ul> <li>It depends on the type of values on which index is being created.</li> <li>regular index is 1:1</li> <li>sparse index, having nulls or other values may have values less than docs</li> <li>multikey index, is one that can be on array or orther collection. it has values more than index. significantly larger.</li> <li>so on update the entire tag collection need to be built again on the disk.</li> </ul> <p>--following is not revised.</p>"},{"location":"9-Drafts/mongodb-notes/#geospatial-index","title":"Geospatial Index","text":"<ul> <li>These index 2d and 3d location indexes.</li> <li>e.g.</li> <li>'location':[x,y]</li> <li>ensureIndex({\"location\":'2d',type:1});</li> <li>find({location:{$near:[x,y]}});</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#geospatial-spherical-index","title":"Geospatial Spherical Index","text":"<ul> <li>this index is called 2dsphere index.</li> <li>it is used to represent the earth lat and longitudes.</li> </ul> <ul> <li>e.g.</li> </ul> <pre><code>db.places.find({\nlocation:{\n$near: {\n$geometry: {\ntype: \"Point\",\ncoordiantes :[-125.256, 37.1521]\n},\n$maxDistance:2000\n}\n}\n}).pretty();\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#text-index","title":"Text Index","text":"<ul> <li>these are used to create index on text.</li> <li>if we normally pass a word in find then it will match that word completely in the document. if whole set of words match a value.</li> <li>but if we make a text index on that key. then we can find using the index find.</li> </ul> <pre><code>db.coll.createIndex({\"words\":'text'});\ndb.coll.find({$text:{$search:'dog'}});\n</code></pre> <ul> <li>it searches in logical or operator.</li> <li>that is it matches single words in the index.</li> </ul> <ul> <li>we can rank them as well using score</li> </ul> <ul> <li>e.g.</li> </ul> <pre><code>db.coll.find({$text:{$search:\"some text here\"}}, {score:{$meta: 'textScore'}}).sort({score:{$meta:'textScore'}});\n</code></pre> <p>-- following is revised.</p>"},{"location":"9-Drafts/mongodb-notes/#efficiency-of-indexes-used","title":"Efficiency of indexes used","text":"<ul> <li>Goal is to make r/w faster.</li> <li>selectivity - minimize records c=scanned.</li> <li>sorts - how sorts are handeled.</li> <li>Examinig and making indexes fast:</li> </ul> <pre><code>db.students.find({student_id:{$gt:500000}, class_id:54}).sort({student_id:1}).hint({class_id:1}).explain(\"executionstats\");\n</code></pre> <ul> <li>so in the above case 20k docs were returned but 80k docs were examined.</li> <li>to inc the efficiency we can porvide hint() to mongodb.</li> </ul> <ul> <li>we can pass index name to it so that it can use the index.</li> <li>passing the hint() after find() reduced the nScanned and made result faster.</li> </ul> <pre><code>db.grades.find({\n\"score\":{$gte:65}\n}).sort({\"score\":1});\n</code></pre> <ul> <li>we should try to eliminate as much part of collection as possible and then further fetch the docs.</li> <li>so index should also be created in a way that first it helps in eliminating the max part and then it should sort or filter other values.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#logging-slow-queries","title":"Logging slow queries","text":"<ul> <li>to debug we can profile whats slow in our app.</li> <li>mongo logs slow queries abive 100 ms</li> <li>it comes on the mongoD log screen.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#profiling","title":"Profiling","text":"<ul> <li>writes to system profile.<ul> <li>0 off.</li> <li>1 log slow queries.</li> <li>2 log all queries.</li> </ul> </li> <li>logs to system.profile.</li> </ul> <ul> <li>2 for debugging and see traffic.</li> </ul> <ul> <li> <p>mongod --profile 1 --slowms 2</p> </li> <li>it will log slow queries taking more than 2 ms.</li> </ul> <p><code>db.system.profile.find({ns:/school.students}).sort({ts:1}).pretty();</code></p> <ul> <li>this gives all quries logged sorted by timestamp.</li> </ul> <p><code>db.system.profile.find({millis:{$gt:1}}).sort({ts:1}).pretty();</code></p> <ul> <li>this gives all queries taking more than a ms.</li> </ul> <pre><code>db.getProfilingLevel()\ndb.setProfilingLevel(1,4) // level and ms.\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#mongostat-command","title":"MongoStat command","text":"<ul> <li>like ioStat command in unix.</li> <li>gives 1sec info about ins, upd etc.</li> </ul> <ul> <li>:~ mongostat</li> <li>this is run on cmd. this gives all stats.<p>e.g.</p> </li> </ul> <pre><code>&gt;mongostat\ninsert query update delete getmore command % dirty % used flushes vsize   res qr|qw ar|aw netIn netOut conn                      time\n*0    *0     *0     *0       0     1|0     0.0    0.0       0  2.5G 24.0M   0|0   0|0   79b    17k    1 2016-08-29T16:13:25+05:30\n*0    *0     *0     *0       0     1|0     0.0    0.0       0  2.5G 24.0M   0|0   0|0   79b    17k    1 2016-08-29T16:13:26+05:30\n*0    *0     *0     *0       0     1|0     0.0    0.0       0  2.5G 24.0M   0|0   0|0   79b    17k    1 2016-08-29T16:13:27+05:30\n*0    *0     *0     *0       0     1|0     0.0    0.0       0  2.5G 24.0M   0|0   0|0   79b    17k    1 2016-08-29T16:13:28+05:30\n</code></pre> <p>these are pretty obvi.</p>"},{"location":"9-Drafts/mongodb-notes/#mongotop","title":"mongotop","text":"<p>- - it is same as unix top command. - it gives a high level view of where mongo is spending its time.</p> <ul> <li>it tell db on which time is spent most. it tells read time and write time.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#sharding","title":"Sharding","text":"<ul> <li>Splitting large collection into multiple servers.</li> <li>when we cannot get performace from a single server then we can shard.</li> <li>mongos is mongo shard that connects to shards.</li> <li>mongod has replicas.</li> <li>app talks to router, mongos.</li> <li>mongos talks to mongod on each server.</li> </ul> <ul> <li>when u can;t get performace from one server.</li> </ul> <ul> <li>insert must include shard key. should be aware fo shard key for collection</li> </ul> <ul> <li>for update if there is no shard key then the request will be broadcasted.</li> <li>multi update is broadcasted.</li> </ul> <ul> <li>update, remove and find are broadcasted to all shard.</li> </ul> <p>Week 5</p>"},{"location":"9-Drafts/mongodb-notes/#aggregation-pipeline","title":"Aggregation pipeline","text":"<p>Same as we pass in unix thru pipe.</p> <pre><code>    $project    - reshape   - 1:1\n$match      - filter    - n:1\n$group      - aggregate - n:1\n$sort       - sort      - 1:1\n$skip       - skips     - n:1\n$limit      - limits    - n:1\n$unwind     - denormalize 1:n\n$out        - output    - 1:1\n</code></pre> <p>we will using all these.</p>"},{"location":"9-Drafts/mongodb-notes/#simple-agg-example-exlained","title":"Simple agg example exlained","text":"<pre><code>    db.products.aggregate([\n{$group:\n{\n_id : \"$manufacturer\",\nnProd: { $sum : 1 }\n}\n}\n]);\n</code></pre> <p>This will group by manufacturer and find number of products.</p>"},{"location":"9-Drafts/mongodb-notes/#compound-grouping","title":"Compound Grouping","text":"<p>group by more than a key.</p> <pre><code>    db.products.aggregate([\n{$group:\n{\n_id : {\n\"manufacturer\" : \"$manufacturer\",\n\"category\" : \"$category\" } ,\nnProd: { $sum : 1 }\n}\n}\n]);\n</code></pre> <p>Note: the _id in mongoDB can be a document as well.</p>"},{"location":"9-Drafts/mongodb-notes/#aggregation-expressions-overview","title":"Aggregation expressions overview","text":"<ul> <li>$sum - sum or count</li> <li>$avg</li> <li>$min</li> <li>$max</li> <li>$push - builds arrays.</li> <li>$addToSet - does not duplicates.</li> <li>$first - sort the doc and then find first from group</li> <li>$last - same but last.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#sum","title":"sum","text":"<pre><code>    db.products.aggregate([\n{$group:\n{\n_id : { \"maker\" : \"$manufacturer\" },\nSum_Prices : { $sum : \"$price\" }\n}\n}\n]);\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#avg","title":"avg","text":"<pre><code>    db.zips.aggregate([\n{ $group : {\n\"_id\" : \"$state\",\n\"avg_pop\" : { \"$avg\" : \"$pop\" }\n}\n}\n]);\n</code></pre> <p>this groups by state and finds avg of population.</p>"},{"location":"9-Drafts/mongodb-notes/#addtoset","title":"addToSet","text":"<pre><code>    db.zips.aggregate([{\n$group:{\n\"_id\":\"$city\",\n\"postal_codes\":{\"$addToSet\":\"$_id\"}\n}\n}]);\n</code></pre> <ul> <li>ids are postalcodes, what it does is, it adds all postalcodes to new</li> <li>key postal_codes and groups by city.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#max","title":"max","text":"<pre><code>    db.zips.aggregate([{\n$group:{\n\"_id\":\"$state\",\n\"max_pop\":{\"$max\":\"$pop\"}\n}\n}]);\n</code></pre> <ul> <li>this groups by state and finds maximum population.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#group-stages","title":"Group stages","text":"<p>Pass result through pipe line.</p> <pre><code>    db.fun.aggregate([\n{$group:{\n_id:{a:\"$a\", b:\"$b\"},\nc:{$max:\"$c\"}\n}\n},\n{$group:{\n_id:\"$_id.a\",\nc:{$min:\"$c\"}\n}\n}\n])\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#projections","title":"Projections","text":"<ul> <li>we can:<ul> <li>remove key</li> <li>add new keys</li> <li>reshape keys</li> <li>use func:<ul> <li>$toUpper</li> <li>$toLower</li> <li>$add</li> <li>$multiply</li> </ul> </li> </ul> </li> </ul> <p>-we can show results as we want to by some operations on the values of keys.</p> <pre><code>    db.products.aggregate([\n{$project:\n{\n_id:0,\n'maker':{ $toLower: \"$manufacturer\" },\n'details' : {\n'category' : \"$category\" ,\n'price' : { \"$multiply\" : [\"$price\",10] }\n},\n'item' : '$name'\n}\n}\n]);\n// below in wrong query:\ndb.zips.aggregate([{\n$project:{\n_id:0,\ncity:{$toLower:$city}, //wrong! $city has to be in \"\" . for _id as well\npop:1,\nstate:1,\nzip:$_id\n}\n}]);\n// correct:\ndb.zips.aggregate([{\n$project:{\n_id:0,\ncity:{$toLower:\"$city\"},\npop:1,\nstate:1,\nzip:\"$_id\"\n}\n}]);\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#match","title":"Match","text":"<p>filter, if matches doc is pushed to pipeline. pre aggregate the filter.</p> <p>e.g. filter state CA, and then do the stuff.</p> <pre><code>    db.zips.aggregate([\n{$match:{\nstate:\"CA\"\n}\n},\n{ $group : { _id:\"$city\",\npopulation:{$sum:\"$pop\"},\nzip_codes: { $addToSet : \"$_id\"}\n}\n},\n{ $project : {\n_id:0,\ncity: \"$_id\" ,\npopulation:1,\nzip_codes:1,\n}\n}\n]);\n</code></pre> <p>Note: One thing to note about $match (and $sort) is that they can use indexes, but only if done at the beginning of the aggregation pipeline.</p>"},{"location":"9-Drafts/mongodb-notes/#sort-skip-limit","title":"Sort, Skip, Limit","text":"<ul> <li>it is disk and memory based.</li> <li>it can be done before and after grouping.</li> </ul> <pre><code>    db.zips.aggregate([\n{$match:{\nstate:\"NY\"\n}\n},\n{ $group : { _id:\"$city\",\npopulation:{$sum:\"$pop\"}\n}\n},\n{ $project : {\n_id:0,\ncity: \"$_id\" ,\npopulation:1\n}\n},\n{ $sort: {\npopulation: -1\n}\n},\n{ $skip: 4 },\n{ $limit: 5}\n]);\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#first-and-last","title":"First and Last","text":"<pre><code>    db.zips.aggregate([\n{ $group : { _id:{state:\"$state\", city:\"$city\"},\npopulation:{$sum:\"$pop\"}\n}\n},\n{ $sort: {\n\"_id.state\":1,\n\"population\":-1\n}\n},\n/## group by state, get first city */\n{ $group:{\n_id: \"$_id.state\",\ncity : { $first : \"$_id.city\" },\npopulation : {$first:\"population\"}\n}\n},\n{$sort:{\n_id:1\n}\n};\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#limitations-of-the-aggregation-framework","title":"Limitations of the Aggregation Framework","text":"<p>100 mb limit for pipeline. 16 mb limit for python.</p> <p>in sharded system when we group by then aggregation query goes to each shard. then when we require all data, then all data goes to primary shard. so same level of scalability is not found which can be found in map reduce jobs in Hadoop.</p> <p>Week 6 :</p>"},{"location":"9-Drafts/mongodb-notes/#application-engineering","title":"APPLICATION ENGINEERING","text":"<p>durability, that data is on disk fault taulerance, what happens on crash. sharding, distribution across servers.</p>"},{"location":"9-Drafts/mongodb-notes/#write-concern","title":"Write Concern","text":"<p>DB writes pages to memory. thse are written to disk, depending on mem pressure,</p> <p>journal is log of every single thing happening on db. writes to journal as well. when journal is written then data is actually written on disk.</p> <p>When a data is persistent. we have two values that govern this, one is W and other is J.</p> <p>w=1 denotes that data is written, it can be written to memnory or to disk but no surity of it,</p> <p>j means weather or not we wait for journal to be written to disk before we continue.</p> <p>by default, j= false and w=1. j=true is that data in journal is written to disk. this gives surity that the data is persistent now.</p> <p>the operation performed in MongoDB is on memory and not on disk. (fast) journal is written periodically.</p> <p>if server crashed we may loose data. (w came back but journal is not written) disk is 100 to 1000 times slower.</p> <p>by default w=1, j=false. this means we;ll wait for write to be acknowledged but not journal to be written this is fast. lil vulnerable.</p> <p>w=1.j=true can be done by driver at db or coll level. slow. vulnerability is removed.</p> <p>w=0 is not recommended. and the write is not acknowledged.</p> <p>in replicated env we have other values of w that have significance.</p>"},{"location":"9-Drafts/mongodb-notes/#network-errors","title":"Network Errors","text":"<p>we might not get response from server about write when write happened but n/w error occured.</p> <p>in case of insert we can try again with same _id and can at max get duplicate key error.</p> <p>in update problem occurs. so for $inc we cannot determine that update occured or not.</p> <p>to avoid update we can convert update to insert. delete and insert.</p>"},{"location":"9-Drafts/mongodb-notes/#introduction-to-replication","title":"Introduction to Replication","text":"<p>availability and fault toleracne. (in case of fire.) all are mongod. replicates asynchronously to sec. sec elect, strict majority. data written to p will be asynchronously will be written to s. when p goes down then election occurs. by majority the s becomes p. then s becomes p and later when p comes up it comes as s.</p> <p>by default we have 3 replications.</p>"},{"location":"9-Drafts/mongodb-notes/#replica-set-elections","title":"Replica Set Elections","text":"<p>type of nodes: regular - arbiter (voting) - to vote in case of even nodes. delayed/regular - disaster recovery, can be an hr behind, can;t become primary node. priority 0 hidden - can;t be primary. used for analytics. p=0.</p>"},{"location":"9-Drafts/mongodb-notes/#write-consistency","title":"Write Consistency","text":"<p>write will goto p reads can goto s as well. but may be stale data. lag is not determined as sync is asynchronous.</p>"},{"location":"9-Drafts/mongodb-notes/#creating-a-replica-set","title":"Creating a Replica Set","text":"<p>in real we keep on diff phy servers. in our case we make on one server with diff dir and diff ports. 3 mondod instances are started.</p> <p>replSet rs1 : this tells that they belong to one replica set.</p> <p>mkdir -p /data/rs1 /data/rs2 /data/rs3 mongod --replSet m101 --logpath \"1.log\" --dbpath /data/rs1 --port 27017 --oplogSize 64 --fork --smallfiles mongod --replSet m101 --logpath \"2.log\" --dbpath /data/rs2 --port 27018 --oplogSize 64 --smallfiles --fork mongod --replSet m101 --logpath \"3.log\" --dbpath /data/rs3 --port 27019 --oplogSize 64 --smallfiles --fork</p> <p>To run a mongod process as a daemon (i.e. fork), and write its output to a log file, use the --fork and --logpath options.</p> <p>we also need to tie them together so that they can work in sync,</p> <p>we need to config and tell that all are associated with each other.</p> <p>config = { _id: \"m101\", members:[ {_id : 0, host : \"localhost:27017\"}, { _id : 1, host : \"localhost:27018\"}, {_id : 2, host : \"localhost:27019\"} ] };</p> <p>rs.initiate(config); rs.status();</p> <p>After starting mongod s and then tying them together we start a client using: mongo --port 27018 we don;t get a normal port. rs1.SECONDARY&gt; rs.status();</p> <p>we get above. and the result is: all nodes status. a big doc. sec, pri, sec. all nodes info comes.</p> <p>we cannot write on secondary.</p> <p>we then move to primary and insert a doc. then goto sec and find the same collection. we can't query sec'. we set</p> <p>rs.slaveOk(); then we can read form s.</p>"},{"location":"9-Drafts/mongodb-notes/#replica-set-internals","title":"Replica Set Internals","text":"<p>the replica sets have oplog. this is a log of change. the primary writes all to oplog. the secondary reads the oplog from primary and makes changes to primary.</p> <p>to see oplog on primary</p> <p>use local show collections oplog.rs is one we need. it has detail of insert just performed.</p> <p>now do: $ ps -ef | grep mongod the find process id of mongod primary/ $ kill 60494 this will bring down the primary.</p> <p>then secondary becomes primary. rs.status() shows the down server as not reachable.</p> <ul> <li>Failover and Rollback</li> <li>When p fails and secondary takes its place.</li> <li>now s may be behind and does not have some writes.</li> <li>the p gets back as s in some time.</li> <li>then p syncs with secondary to take new writes and realises that it has extra writes.</li> <li>it then rollsback those writes and saves to a file.</li> <li>this is failover and Rollback.</li> </ul> <ul> <li>Connecting to a Replica Set from the Java Driver</li> </ul> <ul> <li>When Bad Things Happen to Good Nodes</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#write-concern-revisited","title":"Write Concern Revisited","text":"<ul> <li>concerns which arise when we write to hard disk.</li> <li>w and j are the properties that govern how write will work.</li> <li>setting w=1 will wait for primary node to respond to acknowledgement of write.</li> <li>w=2 will wait for primary as well as secondary.</li> <li>w=3 will wait for 3 to respond.</li> <li>j=1 will wait for primary to write the journal to the disk.</li> <li>how long we wait is, is called wtimeout. it can be set in drivers.</li> <li>these 3, w,j and wtimeout define write concern.</li> <li>these can be set in connection, collection driver or when defining replica set.</li> <li>w:majority is used to wait until majority acknowledges the write.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#read-preferences","title":"Read Preferences","text":"<ul> <li>we usually read and write to the primary but we can set it to read from the secondary as well.</li> <li>it can be set to:</li> <li>primary - read only from primary</li> <li>primary preferred - if not available then read from secondary</li> <li>secondary - only rotate among secondaries</li> <li>secondary preferred - if not available then primary</li> <li>Nearest - sends to nearest one.</li> <li>tags - sends to tagged node.</li> <li>we can configure program to connect to secondary.</li> <li>then we can fail primary by</li> <li>rs.stepDown()</li> <li>then also the read continues with on secondary without faliure.</li> </ul> <pre><code>import pymongo\nimport time\nread_pref = pymongo.read_preferences.ReadPreference.SECONDARY\nc = pymongo.MongoClient(host=[\"mongodb://localhost:27017\",\n\"mongodb://localhost:27018\",\n\"mongodb://localhost:27019\"],\nread_preference=read_pref)\ndb = c.m101\nthings = db.things\nfor i in range(1000):\ndoc = things.find_one({'_id':i})\nprint \"Found doc \", doc\ntime.sleep(.1)\nduring execution if we stepDown primary. the read continues.\n</code></pre>"},{"location":"9-Drafts/mongodb-notes/#sharding-and-replication","title":"Sharding and Replication","text":""},{"location":"9-Drafts/mongodb-notes/#review-of-implications-of-replication","title":"Review of Implications of Replication","text":"<ul> <li>seed lists - this is info and responsibility of driver to elect primary, keep all nodes data and keep track of them all.</li> <li>write concern - concern that w,j and wtimeout determine.</li> <li>read Preferences - how we set the reads.</li> <li>errors can happen - event after replications, errors can happen and will continue to happen because of n/w failure, h/w failure etc. for this knowledge of data and where it goes in application is necessary.</li> </ul> <p>One thing to remember is that the driver will check, upon attempting to write, whether or not its write concern is valid. It will error if, for example, w=4 but there are 3 data-bearing replica set members. This will happen quickly in both the Java and pymongo drivers. Reading with an invalid readPreference will take longer, but will also result in an error. Be aware, though, that this behavior can vary a little between drivers and between versions.</p>"},{"location":"9-Drafts/mongodb-notes/#introduction-to-sharding","title":"Introduction to Sharding","text":"<ul> <li>horizontal scalabiling.</li> <li>Shard are dbs distributed.</li> <li>each shards can have replicas. these are different hosts.</li> <li>so shard s1 can have 3 replicas. R0. so s1-s5 will have 15 hosts. (5*3).</li> <li>router is calles mongos.</li> <li>it does sometimes range based sharding.</li> <li>so on Querying mongos knows where that particaular order_id will fall.</li> <li>it conncects quesries to diff hosts.</li> <li>we use range based distribution.</li> <li>done on the basis of shard key, may be order_id.</li> <li>mongos for certain order no. will send to particaular chuck.</li> <li>these chunks lives on particular shards.</li> <li>all replicas in shards are mondgod.</li> <li>If shard key is not in knowledge of mongos then the request is sent to all shards.</li> <li>As of MongoDB 2.4, we also offer hash-based sharding, which offers a more even distribution of data as a function of shard key, at the expense of worse - performance for range-based queries.</li> <li>Sharding is at db level.</li> <li>MongoS are stateless and can easily be replicated.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#building-a-sharded-environment","title":"Building a sharded environment","text":"<ul> <li>this more of a DBA task.</li> <li>we can setup 3 shards having 3 replicas in each.</li> <li>we ll  have a mongos server connected to app. it listens to port number 27017 which is default.</li> <li>the other relicas use non standard ports as these are all on same pc (hosts) and act as different hosts.</li> <li>then we have config server (3). these have information about the shards.</li> <li>so data is broken into chunks.</li> <li>sharding can be done on</li> <li>range based - it uses a range on say some id</li> <li>hash based - is uses hash algorithm to shard the data.</li> </ul> <ul> <li>below is the script to start a sharded system on local computer.</li> <li>our mongo will connect to mongos and not mongo d.</li> <li>the sh.status() gives data of sharded system.</li> </ul>"},{"location":"9-Drafts/mongodb-notes/#implications-of-sharding","title":"Implications of sharding","text":"<p>every doc shud hav shard key and it is immutable (it can;t be changed). index is req for shard key index should start with shard key if multiKey. in update, either shard key should be there or mulli update should be true. for update shard key has to be specified. else it is sent to all nodes.</p> <p>no unique index can be set unless it is part of shard key. reason for no unique is that it doesn;t know about other shards. we should choose shard key as one that we are going to use in most of our query as a key,</p>"},{"location":"9-Drafts/mongodb-notes/#sharding-and-replication_1","title":"Sharding and replication","text":"<p>they both are usually done togther. mongos connects to pimary of replica mainly for failover within shard, mongos reconnects. write concers are still there. j true or w majority are still there. they apply to each node. availability and concerns still apply.</p>"},{"location":"9-Drafts/mongodb-notes/#choosing-a-shard-key","title":"Choosing a shard key","text":"<p>it shud have sufficient cardinality (variety of values.) so that it can be put in all shards hotspoting (all requests going to one single place) shud be avoided. so inserts should be such that the inserts goto different shards e.g so username can be used as shard key. it gives nice parallelism.</p> <p>hotspoting in writes should be avoided. anything that is monotonously increasing should be avoided in shards there are $minKey and $maxKey and values within it goes into the shard. when any value is greater than highest value of $maxKey then it always goes to the highest chunk, so all inserts will goto one shard only. sharding on (vendor,order_date) is pretty well as we get lot of cardinallity.</p>"},{"location":"9-Drafts/mongodb-notes/#snippets","title":"Snippets","text":"<pre><code>### clean everything up\necho \"killing mongod and mongos\"\nkillall mongod\nkillall mongos\necho \"removing data files\"\nrm -rf /data/config\nrm -rf /data/shard*\n\n### start a replica set and tell it that it will be shard0\necho \"starting servers for shard 0\"\nmkdir -p /data/shard0/rs0 /data/shard0/rs1 /data/shard0/rs2\nmongod --replSet s0 --logpath \"s0-r0.log\" --dbpath /data/shard0/rs0 --port 37017 --fork --shardsvr --smallfiles\nmongod --replSet s0 --logpath \"s0-r1.log\" --dbpath /data/shard0/rs1 --port 37018 --fork --shardsvr --smallfiles\nmongod --replSet s0 --logpath \"s0-r2.log\" --dbpath /data/shard0/rs2 --port 37019 --fork --shardsvr --smallfiles\n\nsleep 5\n### connect to one server and initiate the set\necho \"Configuring s0 replica set\"\nmongo --port 37017 &lt;&lt; 'EOF'\nconfig = { _id: \"s0\", members:[\n{_id : 0, host : \"localhost:37017\" },\n{ _id : 1, host : \"localhost:37018\" },\n{_id : 2, host : \"localhost:37019\" }]};\nrs.initiate(config)\nEOF\n### start a replicate set and tell it that it will be a shard1\necho \"starting servers for shard 1\"\nmkdir -p /data/shard1/rs0 /data/shard1/rs1 /data/shard1/rs2\nmongod --replSet s1 --logpath \"s1-r0.log\" --dbpath /data/shard1/rs0 --port 47017 --fork --shardsvr --smallfiles\nmongod --replSet s1 --logpath \"s1-r1.log\" --dbpath /data/shard1/rs1 --port 47018 --fork --shardsvr --smallfiles\nmongod --replSet s1 --logpath \"s1-r2.log\" --dbpath /data/shard1/rs2 --port 47019 --fork --shardsvr --smallfiles\n\nsleep 5\necho \"Configuring s1 replica set\"\nmongo --port 47017 &lt;&lt; 'EOF'\nconfig = { _id: \"s1\", members:[\n{_id : 0, host : \"localhost:47017\" },\n{ _id : 1, host : \"localhost:47018\" },\n{_id : 2, host : \"localhost:47019\" }]};\nrs.initiate(config)\nEOF\n### start a replicate set and tell it that it will be a shard2\necho \"starting servers for shard 2\"\nmkdir -p /data/shard2/rs0 /data/shard2/rs1 /data/shard2/rs2\nmongod --replSet s2 --logpath \"s2-r0.log\" --dbpath /data/shard2/rs0 --port 57017 --fork --shardsvr --smallfiles\nmongod --replSet s2 --logpath \"s2-r1.log\" --dbpath /data/shard2/rs1 --port 57018 --fork --shardsvr --smallfiles\nmongod --replSet s2 --logpath \"s2-r2.log\" --dbpath /data/shard2/rs2 --port 57019 --fork --shardsvr --smallfiles\n\nsleep 5\necho \"Configuring s2 replica set\"\nmongo --port 57017 &lt;&lt; 'EOF'\nconfig = { _id: \"s2\", members:[\n{_id : 0, host : \"localhost:57017\" },\n{ _id : 1, host : \"localhost:57018\" },\n{_id : 2, host : \"localhost:57019\" }]};\nrs.initiate(config)\nEOF\n### now start 3 config servers\necho \"Starting config servers\"\nmkdir -p /data/config/config-a /data/config/config-b /data/config/config-c\nmongod --logpath \"cfg-a.log\" --dbpath /data/config/config-a --port 57040 --fork --configsvr --smallfiles\nmongod --logpath \"cfg-b.log\" --dbpath /data/config/config-b --port 57041 --fork --configsvr --smallfiles\nmongod --logpath \"cfg-c.log\" --dbpath /data/config/config-c --port 57042 --fork --configsvr --smallfiles\n\n### now start the mongos on a standard port\nmongos --logpath \"mongos-1.log\" --configdb localhost:57040,localhost:57041,localhost:57042 --fork\necho \"Waiting 60 seconds for the replica sets to fully come online\"\nsleep 60\necho \"Connnecting to mongos and enabling sharding\"\n### add shards and enable sharding on the test db\nmongo &lt;&lt;'EOF'\ndb.adminCommand( { addshard : \"s0/\"+\"localhost:37017\" } );\ndb.adminCommand( { addshard : \"s1/\"+\"localhost:47017\" } );\ndb.adminCommand( { addshard : \"s2/\"+\"localhost:57017\" } );\ndb.adminCommand({enableSharding: \"school\"})\ndb.adminCommand({shardCollection: \"school.students\", key: {student_id:1}});\nEOF\n</code></pre>"},{"location":"9-Drafts/notepad/","title":"Notepad","text":"<p>Staging area - Start with H1, later move to <code>term-notes.md</code></p>"},{"location":"9-Drafts/notepad/#android-notes","title":"Android Notes","text":"<p>ADB is utility to interact with android phone. It can install/uninstall apks. change connections etc.  All commands here, adb shell.</p> <p>Enable Developer Options &gt; USB Debugging</p> <p>adb must be installed on your mac/pc.</p> <p>Uninstall blotwares</p> <ul> <li><code>adb devices</code> see your device</li> <li><code>adb shell</code> enter phone shell</li> <li><code>pm uninstall -k --user 0 com.mipay.wallet.in</code> to use pm is pkg mgr, and uninstall an app.</li> </ul> <p>References:</p> <ul> <li>https://forum.xda-developers.com/t/uninstall-system-apps-without-root-vivo-bloatware.3817230/</li> <li>https://technastic.com/vivo-bloatware-preinstalled-apps-list/</li> </ul>"},{"location":"9-Drafts/notepad/#easy-soft-sys","title":"Easy Soft Sys","text":"<p>Color Pallet:</p> <ul> <li>Blue - #00a1e7, rgb(0,161,231) https://www.colorhexa.com/00a1e7</li> <li>Grey - #3f3f3f, rgb()</li> <li>Orange - #e74600, rgb(231,70,0)</li> </ul> <p>Font: Gill Sans Nova Extra Condensed Bold</p>"},{"location":"9-Drafts/notepad/#bookdown","title":"Bookdown","text":"<p>Quick getting started.</p> <p>Steps:</p> <ul> <li><code>mkdir bookdown</code></li> <li><code>cd bookdown/</code></li> <li><code>git clone https://github.com/seankross/bookdown-start</code></li> <li><code>cd bookdown-start/</code></li> <li><code>r</code></li> <li><code>bookdown::render_book(\"index.Rmd\")</code></li> </ul> <ul> <li>all <code># heading 1</code> are chapters.</li> <li>Add <code>Part I</code> before a chapter to make it part in a book, <code># (PART) Data Science {-}</code></li> <li><code>&gt; options(bookdown.render.file_scope = FALSE);</code> to use parts in diff directories.</li> </ul> <p>To support GitHub flavoured MarkDowm, you need to add the following line to <code>_output.yml</code> file:</p> <p><code>md_extensions: +lists_without_preceding_blankline+pipe_tables+raw_html+emoji</code></p> <p>Working on a book:</p> <ul> <li>All mds are in <code>./data_science</code> folder.</li> <li>All images are in <code>./images</code> folder.</li> <li>Add new md file to <code>./_bookdown.yml</code> file. It also has index order.</li> <li>To build and run:<ul> <li><code>r</code></li> <li><code>bookdown::render_book(\"index.Rmd\")</code></li> <li>new site availabe at <code>./docs/index.html</code></li> <li><code>quit()</code> to exit R shell</li> </ul> </li> </ul> <p>References:</p> <ul> <li>Bookdown cookbook</li> <li>Bookdown</li> <li>Rafalab dsbook</li> <li>Rafalab book source github.</li> <li>Bookdown data science notes book</li> <li>Python Visualizations in bookdown</li> <li>Using Python Environments</li> <li>Show plotly html js in Rmarkdown stackoverflow</li> <li>code options cheat sheet</li> <li>publishing on github</li> <li>pandoc markdown formats.</li> </ul>"},{"location":"9-Drafts/notepad/#digital-marketing-notes","title":"Digital Marketing Notes","text":"<p>Instagram page earning:</p> <ul> <li>original images</li> <li>regular posting</li> </ul> <p>Instagram Bot:</p> <ul> <li>Scrapper - https://towardsdatascience.com/increase-your-instagram-followers-with-a-simple-python-bot-fde048dce20d#:~:text=Open%20a%20browser%20and%20login,users%20you%20followed%20using%20the</li> <li>Post - https://www.youtube.com/watch?v=vnfhv1E1dU4</li> </ul>"},{"location":"9-Drafts/notepad/#tableau","title":"Tableau","text":""},{"location":"9-Drafts/notepad/#writeback-in-tableau","title":"Writeback in Tableau","text":"<pre><code>## Mega String\n\"( '\"\n+[CC interaction_ID]\n+\"', '\"\n+[CC Status]\n+\"', '\"+[CC Note]+\"', '\"+USERNAME()+\"' )\"\n## HideInsert\n[CC W InsertRun] = 0\n## HideReset\n[CC W InsertRun] = 4\n## IncrementAdd\n[CC W Incrementer]+1\n## zero\n0\n## One\n1\n## Blank\n\"\"\n## sheet reset\nSaved successfully!\nGo To Flow View \u2b9e\n## Seet Sumbit\nSubmit \u2b9f\n## CC Submitted\nWriteback proc source\n## Actions on form\nselect - reset - go to - next\nselect - reset - set - insertrun to 0\nselect - submit - set - cc mega string\nselect - submit - set - increment to +1\nselect - submit - set - insetRun 1\n## actions on table sheet\nselect - table - set - insertRun 1\nselect - table - set - string blank\nselect - table - set - id to row selected\n</code></pre>"},{"location":"9-Drafts/notepad/#plotly-d3-vizs","title":"Plotly D3 Vizs","text":"<ul> <li>poltly built on top of D3</li> <li>python api uses plotly.js</li> </ul> <p>Plotly Library:</p> <ul> <li>data - result of go.chartType(x=, y=, others=....)</li> <li>layout - title, axis, annotations<ul> <li>has param <code>updatemenus</code></li> <li>There are four possible update methods:<ul> <li>\"restyle\": modify data or data attributes</li> <li>\"relayout\": modify layout attributes</li> <li>\"update\": modify data and layout attributes</li> <li>\"animate\": start or pause an animation</li> </ul> </li> </ul> </li> <li>frames: used for animations<ul> <li>we can add different frames to a chart</li> <li>this can be used to produce the animations</li> <li>Example can be found here.</li> </ul> </li> <li>figure - final object combining data and layout.</li> </ul> <p>Dash is putting and linking many plotly charts together.</p> <p>Other plotly products</p> <p>Dash:</p> <ul> <li>Dash is Python framework for building analytical web applications.</li> <li>It is built on Flask, Plotly.js and React.js</li> <li>Just like flask, we define <code>app = dash.Dash()</code> and then at end <code>app.run_server()</code></li> <li>We can create complete site with links.</li> <li>It has intractable story.</li> </ul> <p>Chart Studio</p> <ul> <li>is like Tableau web edit and public.</li> <li>Can create and host data, charts and dashboards.</li> <li>can explore other people's work.</li> <li>charts are interactable and linked together.</li> <li>can be reverse engineered.</li> <li>can host notebooks as well.</li> </ul> <p>ObservableHQ:</p> <ul> <li>Live, web edit, d3 notebooks.</li> <li>markdown and JS blocks</li> <li>lots of d3 features. like counts, action buttons etc</li> <li>can make dasboard as well.</li> </ul> <p>References:</p> <ul> <li>How and why I used Plotly (instead of D3)</li> <li>4 interactive Sankey diagrams made in Python</li> </ul>"},{"location":"9-Drafts/notepad/#d3","title":"D3","text":"<p>Add D3 library. Then specific module.</p> <ul> <li>it is collection of module that work together</li> <li>data is bounded to the selections, it join-by-index</li> <li>By default, the data join happens by index: the first element is bound to the first datum, and so on. Thus, either the enter or exit selection will be empty, or both. If there are more data than elements, the extra data are in the enter selection. And if there are fewer data than elements, the extra elements are in the exit selection.</li> <li>selectAll() data() enter() append() - to add elements, SDEA. https://observablehq.com/@d3/d3-hierarchy?collection=@d3/d3-hierarchy</li> </ul>"},{"location":"9-Drafts/notepad/#youtube-channel-notes","title":"YouTube Channel Notes","text":"<p>Start creating a web of terms , make understand each thing, chamkao cheezo ko. makeit understnad to 6yr old guy start from docs, make reading a habit, start taking notes. math teacher lessongs, i see, i do, i ... small age learn, big understand, then decision.</p> <p>Follow:</p> <ul> <li>miguel grinberg - https://twitter.com/miguelgrinberg</li> <li>Claudio Bernasconi - https://twitter.com/CHBernasconiC</li> </ul>"}]}